{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding sparse word vectors into high-but-lower-dimensional dense space\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/parrt/playdl/blob/master/mnist/notebooks/word-embeddings.ipynb)\n",
    "\n",
    "Word vectors are simple but the vocabulary size can make word vectors extremely long; high dimensionality. And they are very sparse, mostly zeros.\n",
    "\n",
    "Word embeddings, on the other hand, embed that massive dimensional space into a smaller, dense space. For example, [GloVE](https://nlp.stanford.edu/projects/glove/) has pre-trained word embeddings of various sizes such as 50 and 300 dimensions. Unlike word vectors, we need to do some training to compute embeddings. I've used pre-trained word-to-embedding dictionaries to good effect, but we can also train and embedding specific to our task as part of our model, using an embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting random but dense not sparse word vectors\n",
    "\n",
    "In [word-vectors](word-vectors.ipynb), we created sparse vectors representing words. When added together, these create bag of words (BOW) representations of documents. We can just turn on the particular position of a word in the vector if that word is present in the document. \n",
    "\n",
    "If we are passing words individually to a recurrent neural network (RNN), then these sparse vectors can get pretty big. If there are 20,000 words in the dictionary, we might have vectors of size 20,000. What we need is a dense representation that still gives us unique representations of each word.  (We also used to the hash trick also to try to shrink the size of the sparse vectors, but they are still sparse.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample tweets from my twitter inbox with added text for experimentation\n",
    "samples = [\n",
    "    \"\"\"Tesla Motors has nothing to do with this tweet.\n",
    "    On those rare occasions when I really, really need to reduce the\n",
    "    size of a file I use \"xz -9\". Today I found out about the \"extreme\" setting\n",
    "    and \"xz -e9\" squeezed files down another 15% or so. It is not exactly quick,\n",
    "    but that doesn't really matter in such cases!\"\"\",\n",
    "    \n",
    "    \"\"\"Securities and exchange commission has nothing to do with this tweet.\n",
    "    Do grad students get paid a lot? No. But do we at least have solid\n",
    "    job security? Also, no. But are we at least ensured a stress-free work\n",
    "    environment with a healthy work-life balance? Still, also no.\"\"\",\n",
    "\n",
    "    \"\"\"A design process hyperfocused on A/B testing can result in dark patterns even\n",
    "    if that’s not the intent. That’s because most A/B tests are based on metrics\n",
    "    that are relevant to the company’s bottom line, even if they result in harm to users.\"\"\"\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "words = tokenizer.word_index.keys() # get tokenized words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not using a hash function but instead dense factors, we need a dictionary to keep track of the word to vector mapping. But, we can create vectors of any length and get very little chance of collision. For example, even with a single floating-point number between 0 and 1, with our 96 words in the vocabulary, there's almost no chance of collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashwords(words, dimensionality = 4):\n",
    "    return {w:np.random.random(size=dimensionality) for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', array([0.74813393, 0.15237295, 0.95414246, 0.6658087 ])),\n",
       " ('to', array([0.76290396, 0.64180381, 0.53569385, 0.16594362])),\n",
       " ('do', array([0.66534492, 0.39515198, 0.54270866, 0.48688513])),\n",
       " ('the', array([0.86020141, 0.53697074, 0.45104853, 0.5343488 ])),\n",
       " ('with', array([0.85016867, 0.86766001, 0.18249972, 0.88276414])),\n",
       " ('on', array([0.51417153, 0.129233  , 0.89874536, 0.48375021])),\n",
       " ('i', array([0.52733252, 0.68938374, 0.42720063, 0.39019705])),\n",
       " ('really', array([0.5014101 , 0.75332849, 0.88166986, 0.98835455])),\n",
       " ('but', array([0.41445748, 0.46236684, 0.27051044, 0.7635591 ])),\n",
       " ('in', array([0.3168832 , 0.20908108, 0.97965266, 0.27142978]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = hashwords(words, dimensionality=4)\n",
    "list(index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 collisions between dense word vectors\n"
     ]
    }
   ],
   "source": [
    "ncollisions = len(index) - len(set([tuple(a) for a in index.values()]))\n",
    "print(f\"There were {ncollisions} collisions between dense word vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we only use dimensionality=1, then we are right back to label encoding, just with a floating-point number instead of an integer. We need at least a dimensionality of two.\n",
    "\n",
    "What happens if we need to send an entire document not just a single word into a model? We need a continuous bag of words (CBOW), which is easy for one hot encoding.  We just turn on all relevant word-columns. For dense vectors, we either need to concatenate them together or sum or average them into a single vector. If documents are different length, then concatenating them doesn't work because models typically require fixed length input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "Those vectors are dense but there is literally no meaning to the values in the vector positions. Two similar words are in no way similar in some kind of semantic space. We are not helping the model very much. \n",
    "\n",
    "The key idea for improvement is \"*You shall know a word by the company it keeps.*\" ([John Firth](https://en.wikipedia.org/wiki/John_Rupert_Firth), 1957).  Here is a [nice paper on GloVe](https://nlp.stanford.edu/pubs/glove.pdf).  I think this was the [word2vec paper that got word vectors started](https://arxiv.org/pdf/1301.3781.pdf).\n",
    "\n",
    "BTW, this also works for embedding of other things like movies/users (from the netflix challenge) and [airlines](https://djcordhose.github.io/ml-workshop/2019-embeddings.html). If we want to get dense vectors for airline names, we need some mechanism to indicate similarity between airlines so that, rather than random dense factors, we can get dense vectors where airlines are somehow close to each other in some appropriate dense space.\n",
    "\n",
    "### skip-gram\n",
    "\n",
    "If we see the word `New`, very likely `York` will follow. If we see the word `bear`, it's likely that `brown`, `black`, or `grizzly` would proceed `bear`. The words `network` is unlikely to precede or follow `bear` in close proximity. We can train a neural network to respond to a word with word probabilities that could occur in a neighborhood, before or after.\n",
    "\n",
    "The training for the network is x = one-hot word vector for a single word and y = vector of probabilities of appearing in the neighborhood for all words. If there are 1000 words in our vocabulary then each x and y will be vectors of length 1000.\n",
    "\n",
    "### CBOW\n",
    "\n",
    "Or, we can train a CBOW representation of the neighborhood (a few words on either side) to recognize the center word.\n",
    "\n",
    "In either case, the weights of the single hidden layer represent the word embeddings.\n",
    "\n",
    "In either case, we are using a sliding window that moves over the words in a document. Global information about co-occurrence of words is not used.  Apparently a huge amount of data is required to avoid overfitting and training is expensive, given the explosion of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe\n",
    "\n",
    "The [GloVe](https://nlp.stanford.edu/pubs/glove.pdf) approach uses a word co-occurrence matrix and I think is a little easier to understand.  If there are 1000 words in the vocabulary, then the co-occurrence matrix is 1000 x 1000. The entry at i,j is how often words i and j co-occur in the corpus. They have a more complicated model to solve I think than word2vec, but creating the cooccurrence matrix seems easier and smaller than the sliding window training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homebrew embeddings\n",
    "\n",
    "The [fastai book chapter 8](https://github.com/fastai/fastbook/blob/master/08_collab.ipynb) has an example using user-movie-ratings from [MovieLens](https://grouplens.org/datasets/movielens/).  I will grab [a small subset](http://files.grouplens.org/datasets/movielens/ml-latest-small.zip) and put into `data` subdir:\n",
    "\n",
    "```\n",
    "data/ml-latest-small\n",
    "├── README.txt\n",
    "├── links.csv\n",
    "├── movies.csv\n",
    "├── ratings.csv\n",
    "└── tags.csv\n",
    "```\n",
    "\n",
    "\"*Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).*\" The `ratings.csv` file looks like:\n",
    "\n",
    "```\n",
    "userId,movieId,rating,timestamp\n",
    "1,1,4.0,964982703\n",
    "1,3,4.0,964981247\n",
    "1,6,4.0,964982224\n",
    "1,47,5.0,964983815\n",
    "...\n",
    "```\n",
    "\n",
    "And, in case we are curious, `movies.csv` has:\n",
    "\n",
    "```\n",
    "movieId,title,genres\n",
    "1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\n",
    "2,Jumanji (1995),Adventure|Children|Fantasy\n",
    "3,Grumpier Old Men (1995),Comedy|Romance\n",
    "...\n",
    "```\n",
    "\n",
    "Though I think the task will be simply to match up userId and movieId to create an embedding. There are about 100,000 entries in this small set, but we can grab a tiny subset of those just to see what we are dealing with at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>492</td>\n",
       "      <td>761</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>391</td>\n",
       "      <td>1748</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>357</td>\n",
       "      <td>4069</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>2028</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0     325      296     5.0\n",
       "1     492      761     4.0\n",
       "2     391     1748     5.0\n",
       "3     357     4069     2.0\n",
       "4      57     2028     5.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "\n",
    "def load(n = 10):\n",
    "    df_ratings = pd.read_csv('data/ml-latest-small/ratings.csv')\n",
    "    df_ratings = df_ratings.drop('timestamp', axis=1)\n",
    "    df_ratings = df_ratings.sample(n=n).reset_index(drop=True)\n",
    "    return df_ratings\n",
    "\n",
    "df_ratings = load(n=10)\n",
    "df_ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than deal with arbitrarily large integers representing the various IDs, let's compress that down to unique but adjacent integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       5        2     5.0\n",
       "1       9        4     4.0\n",
       "2       8        6     5.0\n",
       "3       7        9     2.0\n",
       "4       2        7     5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catencoders = {}\n",
    "def compress_cats(df, colname):\n",
    "    df[colname] = df[colname].astype('category').cat.as_ordered()\n",
    "    catencoders[colname] = df[colname].cat.categories\n",
    "    df[colname] = df[colname].cat.codes + 1\n",
    "    \n",
    "compress_cats(df_ratings, \"userId\")\n",
    "compress_cats(df_ratings, \"movieId\")\n",
    "df_ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusers = len(df_ratings.groupby('userId').count())\n",
    "nmovies = len(df_ratings.groupby('movieId').count())\n",
    "(nusers,nmovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map movie to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try mapping users to movies with a neural network. Presumably people self filter the movies they watch and so there could be information that will tell us about users and/or movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import models, layers, callbacks, optimizers\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 596, 3638)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = load(n=10000)\n",
    "compress_cats(df_ratings, \"userId\")\n",
    "compress_cats(df_ratings, \"movieId\")\n",
    "nusers = len(df_ratings.groupby('userId').count())\n",
    "nmovies = len(df_ratings.groupby('movieId').count())\n",
    "n = len(df_ratings)\n",
    "n, nusers, nmovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3638), (10000,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(df_ratings['movieId'])\n",
    "y = df_ratings['userId'] #pd.get_dummies(df_ratings['userId'])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3629</th>\n",
       "      <th>3630</th>\n",
       "      <th>3631</th>\n",
       "      <th>3632</th>\n",
       "      <th>3633</th>\n",
       "      <th>3634</th>\n",
       "      <th>3635</th>\n",
       "      <th>3636</th>\n",
       "      <th>3637</th>\n",
       "      <th>3638</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3638 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...  3629  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   3630  3631  3632  3633  3634  3635  3636  3637  3638  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[3 rows x 3638 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    367\n",
       "1    304\n",
       "2    576\n",
       "Name: userId, dtype: int16"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = 20\n",
    "layer2 = 200\n",
    "batch_size = 50\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(layer1, name='embedding', input_dim=nmovies, activation='relu')) # input_shape=(n,nmovies)\n",
    "model.add(layers.Dense(layer2, activation='relu'))\n",
    "model.add(layers.Dense(nusers+1, activation='softmax'))\n",
    "\n",
    "opt = optimizers.RMSprop()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a851a9af0d403a82a8c955a3bcb691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=50.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keras validation accuracy 0.3346\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X, y,\n",
    "                    shuffle=True,\n",
    "                    epochs=50,\n",
    "                    validation_split=0.10,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)]\n",
    "                    )\n",
    "\n",
    "y_pred = model.predict(X.values.reshape(-1,nmovies))\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "val_accur = accuracy_score(y, y_pred)\n",
    "print(\"Keras validation accuracy\", val_accur)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "accur = history.history['accuracy']\n",
    "plt.plot(accur, label='train_accuracy')\n",
    "val_accur = history.history['val_accuracy']\n",
    "plt.plot(val_accur, label='valid_accuracy')\n",
    "# plt.xlim(0, 200)\n",
    "# plt.ylim(0.5, 1.02)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation error is terrible, but [Oliver](http://www.zeigermann.eu/) says we care about training error for getting embeddings since we won't be using the predictions.  In his example, he only has about 10% accuracy so I'm going to consider roughly 30% quite good. :)\n",
    "\n",
    "[Here](https://djcordhose.github.io/ml-workshop/2019-embeddings.html#/17), Oliver explains how to get the embeddings out. These are the outputs from the first constrained layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19, -0.18, -0.17, ...,  0.21, -0.18,  0.09],\n",
       "       [-0.09,  0.3 , -0.05, ...,  0.14,  0.05, -0.1 ],\n",
       "       [-0.11,  0.17, -0.11, ..., -0.07,  0.28,  0.03],\n",
       "       ...,\n",
       "       [ 0.03, -0.03,  0.03, ...,  0.01, -0.03, -0.02],\n",
       "       [-0.05,  0.17, -0.17, ..., -0.17, -0.25,  0.14],\n",
       "       [-0.02,  0.19, -0.13, ..., -0.17, -0.25,  0.14]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = model.get_layer('embedding')\n",
    "w, b = embedding_layer.get_weights()\n",
    "w.shape\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3629</th>\n",
       "      <th>3630</th>\n",
       "      <th>3631</th>\n",
       "      <th>3632</th>\n",
       "      <th>3633</th>\n",
       "      <th>3634</th>\n",
       "      <th>3635</th>\n",
       "      <th>3636</th>\n",
       "      <th>3637</th>\n",
       "      <th>3638</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3638 rows × 3638 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1     2     3     4     5     6     7     8     9     10    ...  3629  \\\n",
       "0        1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1        0     1     0     0     0     0     0     0     0     0  ...     0   \n",
       "2        0     0     1     0     0     0     0     0     0     0  ...     0   \n",
       "3        0     0     0     1     0     0     0     0     0     0  ...     0   \n",
       "4        0     0     0     0     1     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "3633     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3634     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3635     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3636     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3637     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      3630  3631  3632  3633  3634  3635  3636  3637  3638  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "3633     0     0     0     0     1     0     0     0     0  \n",
       "3634     0     0     0     0     0     1     0     0     0  \n",
       "3635     0     0     0     0     0     0     1     0     0  \n",
       "3636     0     0     0     0     0     0     0     1     0  \n",
       "3637     0     0     0     0     0     0     0     0     1  \n",
       "\n",
       "[3638 rows x 3638 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_movieIds = np.unique(df_ratings['movieId'])\n",
    "uniq_movieIds = pd.get_dummies(uniq_movieIds)\n",
    "uniq_movieIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3638, 3638), (3638, 20), (20,))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_movieIds.shape, w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the weight matrix is the transpose of what I would expect. For example, I like the convention of a row being the weights of a single neuron. Since I have 20 neurons, I would expect 20 rows, but still we can just reverse the operators of the dot product. The following should give us the output of the embedding layer:  take the dot product of every input movie one-hot and multiply times the weight vector then add the bias. Note: The dot product is really just selecting the ith row of w for one-hot turned on at position i.  A row in w is the set of weights across neurons for a particular feature, a word in our case. That gives us a vector in 20-space where each dimension is some semantic meaning we got from a neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3638, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01,  0.13,  0.07, ...,  0.38,  0.17,  0.22],\n",
       "       [ 0.09,  0.6 ,  0.19, ...,  0.31,  0.4 ,  0.03],\n",
       "       [ 0.08,  0.47,  0.13, ...,  0.1 ,  0.63,  0.17],\n",
       "       ...,\n",
       "       [ 0.21,  0.28,  0.27, ...,  0.18,  0.32,  0.12],\n",
       "       [ 0.13,  0.48,  0.07, ..., -0.  ,  0.1 ,  0.27],\n",
       "       [ 0.16,  0.49,  0.11, ..., -0.  ,  0.1 ,  0.27]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embeddings = np.dot(uniq_movieIds, w) + b\n",
    "print(movie_embeddings.shape)\n",
    "movie_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title                                       genres\n",
       "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2    Jumanji (1995)                   Adventure|Children|Fantasy"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies = pd.read_csv('data/ml-latest-small/movies.csv')\n",
    "df_movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "      <td>2111</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Man with Two Brains, The (1983)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>377</td>\n",
       "      <td>2111</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Man with Two Brains, The (1983)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>144</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Brothers McMullen, The (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Brothers McMullen, The (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>340</td>\n",
       "      <td>144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Brothers McMullen, The (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7421</td>\n",
       "      <td>357</td>\n",
       "      <td>731</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Heaven's Prisoners (1996)</td>\n",
       "      <td>Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7422</td>\n",
       "      <td>463</td>\n",
       "      <td>2116</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Lord of the Rings, The (1978)</td>\n",
       "      <td>Adventure|Animation|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7423</td>\n",
       "      <td>180</td>\n",
       "      <td>778</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Trainspotting (1996)</td>\n",
       "      <td>Comedy|Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7424</td>\n",
       "      <td>582</td>\n",
       "      <td>2696</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Dinner Game, The (Dîner de cons, Le) (1998)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7425</td>\n",
       "      <td>212</td>\n",
       "      <td>1019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20,000 Leagues Under the Sea (1954)</td>\n",
       "      <td>Adventure|Drama|Sci-Fi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7426 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId  rating                                        title  \\\n",
       "0        367     2111     4.5              Man with Two Brains, The (1983)   \n",
       "1        377     2111     3.5              Man with Two Brains, The (1983)   \n",
       "2        304      144     4.0                Brothers McMullen, The (1995)   \n",
       "3        105      144     3.0                Brothers McMullen, The (1995)   \n",
       "4        340      144     3.0                Brothers McMullen, The (1995)   \n",
       "...      ...      ...     ...                                          ...   \n",
       "7421     357      731     4.0                    Heaven's Prisoners (1996)   \n",
       "7422     463     2116     4.0                Lord of the Rings, The (1978)   \n",
       "7423     180      778     3.0                         Trainspotting (1996)   \n",
       "7424     582     2696     4.0  Dinner Game, The (Dîner de cons, Le) (1998)   \n",
       "7425     212     1019     1.0          20,000 Leagues Under the Sea (1954)   \n",
       "\n",
       "                                    genres  \n",
       "0                                   Comedy  \n",
       "1                                   Comedy  \n",
       "2                                   Comedy  \n",
       "3                                   Comedy  \n",
       "4                                   Comedy  \n",
       "...                                    ...  \n",
       "7421                        Crime|Thriller  \n",
       "7422  Adventure|Animation|Children|Fantasy  \n",
       "7423                    Comedy|Crime|Drama  \n",
       "7424                                Comedy  \n",
       "7425                Adventure|Drama|Sci-Fi  \n",
       "\n",
       "[7426 rows x 5 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.merge(df_movies, on='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie+user -> rating\n",
    "\n",
    "Ok, Let's try to map both the movie and the user to a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 600, 3624)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = load(n=10000)\n",
    "compress_cats(df_ratings, \"userId\")\n",
    "compress_cats(df_ratings, \"movieId\")\n",
    "nusers = len(df_ratings.groupby('userId').count())\n",
    "nmovies = len(df_ratings.groupby('movieId').count())\n",
    "n = len(df_ratings)\n",
    "n, nusers, nmovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 4224), (10000,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([pd.get_dummies(df_ratings['movieId']),\n",
    "               pd.get_dummies(df_ratings['userId'])], axis=1)\n",
    "y = df_ratings['rating'] #pd.get_dummies(df_ratings['userId'])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452f4e02470445f996e14b294a5e7c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=20.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV9Z3/8dfnZg9ZgBABw46IrAoiaq1brVadFm3rAnVaa23tTGtr7XSx09aq0+nYZWY6tlpHraO1tG5dxP6wrlhnrFrBDUFBVgkIhC0khOyf3x/fk3AJSbiE3HsD9/18PO7jnu2e87knN+dzvt/vOd9j7o6IiGSuWLoDEBGR9FIiEBHJcEoEIiIZTolARCTDKRGIiGQ4JQIRkQyXtERgZneb2WYze7OL+WZmt5jZCjN7w8ymJysWERHpWjJLBPcA53Yz/zxgXPS6CvhFEmMREZEuJC0RuPtzwLZuFrkA+JUHLwL9zWxosuIREZHOZadx2xXAurjxymjaex0XNLOrCKUG+vXrd/wxxxyTkgBFRA4XixYt2uLu5Z3NS2cisE6mddrfhbvfAdwBMGPGDF+4cGEy4xIROeyY2dqu5qXzqqFKYHjc+DBgQ5piERHJWOlMBPOAT0VXD50EVLv7PtVCIiKSXEmrGjKz3wJnAIPMrBL4HpAD4O63A/OB84EVQB1wRbJiERGRriUtEbj7nP3Md+CLydq+iIgkRncWi4hkOCUCEZEMp0QgIpLhlAhERDKcEoGISIZTIhARyXAZkwgWV1Zz64IV6Q5DRKTPyZhE8Lc12/jx48vYvLM+3aGIiPQpGZMIplSUArB4fXWaIxER6VsyJhFMOrIEMyUCEZGOMiYR9MvLZsygfrypRCAispeMSQQAU4f1V4lARKSDjEoEkytK2bSzgc01ajAWEWmTUYmgrcFY1UMiIntkVCJoazB+o1KJQESkTUYlAjUYi4jsK6MSAYTqITUYi4jskXGJQA3GIiJ7y7hEoAZjEZG9ZVwimFRRGu4wrtyZ7lBERPqEjEsERXnZjB7UT+0EIiKRjEsEEKqHVDUkIhJkbCLYuLOeqpqGdIciIpJ2GZkIJqvBWESkXUYmgklHlgDqklpEBDI0ERTn5zBGDcYiIkCGJgII1UOqGhIRSXIiMLNzzWyZma0ws+s6mT/SzJ42szfM7FkzG5bMeOJNqSjlvep6ttSqwVhEMlvSEoGZZQG3AucBE4E5Zjaxw2I/AX7l7lOBm4B/S1Y8HU0ZpmcYi4hAcksEM4EV7r7K3RuB+4ELOiwzEXg6Gl7QyfykaWswflNdUotIhktmIqgA1sWNV0bT4r0OfDwa/ihQbGZlSYypnRqMRUSCZCYC62Sadxj/GnC6mb0KnA6sB5r3WZHZVWa20MwWVlVV9VqAajAWEUluIqgEhseNDwM2xC/g7hvc/WPuPg34djRtnyOzu9/h7jPcfUZ5eXmvBTilopQN1fVsVYOxiGSwZCaCl4FxZjbazHKB2cC8+AXMbJCZtcXwLeDuJMazj7Y7jFU9JCKZLGmJwN2bgauBx4G3gAfdfYmZ3WRms6LFzgCWmdlyYDDwr8mKpzOTKqIGYyUCEclg2clcubvPB+Z3mHZ93PDDwMPJjKE7Jfk56pJaRDJext5Z3CY0GOshNSKSuTI+EUypKGH9jt1qMBaRjJXxiUANxiKS6ZQI9GwCEclwGZ8ISvJzGFVWqBKBiGSsjE8EoAZjEclsSgSEO4zX79jNtl2N6Q5FRCTllAgIiQDUYCwimUmJAJikBmMRyWBKBEBpQQ4jywpZrGcTiEgGUiKITKkoVdWQiGQkJYJIW4PxdjUYi0iGUSKIqMFYRDKVEkFkkhKBiGQoJYJIW4OxrhwSkUyjRBBnshqMRSQDKRHEmVJRSuV2NRiLSGZRIojT1mD85gaVCkQkcygRxJl8pBqMRSTzKBHEKS3MYcRANRiLSGbpMhGY2TFxw3kd5p2UzKDSSXcYi0im6a5E8Ju44Rc6zLstCbH0CZMrSlm3bTc76tRgLCKZobtEYF0MdzZ+2GhvMNaDakQkQ3SXCLyL4c7GDxuTK0oANRiLSObI7mbeMDO7hXD23zZMNF6R9MjSpH9hLsMHFrB4/Y50hyIikhLdJYKvxw0v7DCv4/hhRQ3GIpJJukwE7n5vZ9PNLB/4SNIi6gMmV5Qyf/FGdtQ10r8wN93hiIgkVUL3EZhZlpmdZ2a/AtYClyY3rPSaWtEfUIOxiGSGbhOBmZ1mZrcDa4DPAucAo939okRWbmbnmtkyM1thZtd1Mn+EmS0ws1fN7A0zO78H36HXqcFYRDJJdzeUVQI3A88DE93948Bud69LZMVmlgXcCpwHTATmmNnEDot9B3jQ3acBs+kj9ye0NRjrDmMRyQTdlQh+R7g66FLgI2bWjwO7bHQmsMLdV7l7I3A/cEGHZRwoiYZLgQ0HsP6kUoOxiGSKLhOBu18DjAL+AzgTWA6Um9klZlaUwLorgHVx45Xse9npDcDfR6WP+cCXOluRmV1lZgvNbGFVVVUCmz54kytKeXdbHdV1TSnZnohIunTbRuDBM+7+OUJSuAy4kNBmsD+d3X3csUQxB7jH3YcB5wP3mdk+Mbn7He4+w91nlJeXJ7Dpg6cuqUUkUyTc+6i7N7n7PHf/BDA8gY9UdlhuGPtW/VwJPBit/wUgHxiUaEzJpC6pRSRTdHkfgZm9sZ/PTt3P/JeBcWY2GlhPaAz+RIdl3gXOAu4xswmERJCaup/9GNAvl2EDCpQIROSw192dxa2EqpzfAI8Cuw9kxe7ebGZXA48DWcDd7r7EzG4CFrr7POCfgDvN7NpoW5929z7Tj9GUilJdOSQih73u7iw+LnomwRxCMlgavT/h7s2JrNzd5xMageOnXR83vBQ4pQdxp8TkilIee3Mj1bubKC3ISXc4IiJJsb/G4rfd/XvuPp1QKvgVcG1KIusD2hqMl6hUICKHsf3dWVxhZv9kZv8H/D0hCfwiJZH1AW2JQO0EInI4666x+C9AMeGqnk8D26JZuWY20N23dfXZw8WAfrlU9FeDsfQBLU2w9nkY+X7I6q5pT+TAdfeLGklowP08cFXcdIumj0liXH2GGowl7Wo3w0NXwNr/g3HnwEX/A3mJ3NMpkpju7iwe5e6jo9eYuNdod8+IJAAwZVgpa7bWsbNedxhLGlQuhP8+HdYvghlXwoqn4J6/C8lBpJckfENZpprc/gxjlQokxRbdA/9zHmTlwJVPwIf/A2b/FrYsh7s+CFveSXeEianbBi//Eh74e1jwA1j3N2htSXdUEkeVjfsxJS4RvG9sn7jpWQ53zQ0w/2vwyq9g7Fnw8bugcGCYN/5c+PSfYO4l8MuzYc4DMOLE9MbbmabdsOwxeOPBUIppbYKSCnj7/8Fffgj5/WHsmXDUB8N3LBma7ogzmhLBfgxsbzDWQ2p6rLkBnvsJvPEAjHo/TPoYjDk9nOnK3qor4cFPhaqgU78GZ/4zxLL2XqbiePjsk/Dri+BXs0KimNAHHhrY2gKrnwsH/7cehcYaKB4KJ34epl4KQ6bA7u2w6llY8XRIEEv+ED57xCQ46qyQGEacBNl5af0qmcYSuZHXzAYARxLuLl7j7q3JDqwrM2bM8IULU/vI5H+4bxHLNtWw4GtnpHS7va61FWIprg2sXAiPfBGq3oaRp8DGN6GhGgoGwsQLYPLHwvSOB7tMtPp/4aFPh8T50dthwoe7X37XVvjtpWEfn/cjOPGq7pdPBnd473VY/BAsfhhqN0JeCUyYBVMvCYm/q7+tO2xeGhLCiqdg7Quh5JDTD0afGpLCUWfBwIxpkkwqM1vk7jM6m9fd5aOlwBcJdxbnEvoAygcGm9mLwG3uviAJ8fY5U4aV8uclG9lZ30RJ/iF4Frvm/+DZm2HtX+H4y+H0b0LxkORus7EOnv0BvHBrOCv8xENw9DnhILfiaXjzd+HMcdH/QNFgmPTRUFIYdkLvJ6vGOqh6C2o2wujT+94VN+5hPz15PZQdBbPnwqBx+/9cvzL41Dz43Wfhsa9D9Tr44I2pSfbb18AbD8HiB0ObRSwnXNE09RI4+kOQU7D/dZjB4Enhdco10FALa/43Ki08Ccv/HJYbOGZPFdLIkyG/NKlfLRN1WSIwsycJdxI/6u47Osw7HvgksNjdf5n0KOOko0Twl+VVXH733/jN5048tNoJ1v41NM6t+d9wsB11Kiz9I2TlwslfhPd9GfJL9r+eA7XmeZh3NWxbBcdfAWff1Pl2GuvgncdDUlj+BLQ0QOlwmHQhTP44DD0uHCwS5Q473oVNS6LXm+G1dSXtPaDnlcBxl8EJn4VBR/XK1z0ojbtg3pfCPpgwCy68DfKKD2wdrS3w2Dfg5bvCfrvwF8mpWtm1FZb8Ppz9r3spTBvxPph6MUy8cE87Rm/ZunJPFdKa/4WmOsBg8ORQfTTiJBhxMpR2fMyJdKa7EkFCVUN9SToSwbZdjUz/lyf55/OP4arTxqZ02z2y9gV49t9g9V+g3xHw/mthxhXhLG3rSnjm++EfumAgnPZ1OOHK3jlwNNTAUzeEA9KAUTDrZzD6tMQ+W78zNC4u+X34529tggGjw4Ft8sdhcIennDbUwua3YNPiuAP/EmiIa8sZMDqcbQ6ZEt7ziuHVX8OSP4b1j/0AzLwqnMmmo2pq68pwJU3V23DW9XDKVw4s8cVzh+f/C576XrjpbPZcKOh/8DE21cPyx+D1B8JZemszlE8IB/8pF0P/EQe/jUQ0N8C7L0avF6DyZWisDfNKR+ydGMqPSX0V6CGgx4kgqh46l/BkMSc8T+DxjiWEVOpxInDv+T8ZcMrNzzB95AB+Nmdaj9eRdO++FKpjVj0L/crDgWXGZyC3cN9lN7wKT34vJIv+I+DM74R/7J7+A614Ch79SmjsPOkL8IFvQ26/nq2rbhu8/Sd48/chPm8N/9xjP7DnjH/76j3L55XsqWIYPDm8jpjQdRVQ7WZYdC8svBtqNoTvf8JnYdone/+stivLH4fffS7s74vuDt+tN7zxEPzxH0MV02UPQf9EHh3SQWtrONi+cT8seSS06RQNgSkXwbGzw/49iP+lXtHSHEp7bYnh3RegdlOYl18Kw+MSw5HTICc/vfE27Ybq9VBUnraqrR4lAjP7FPA94AnC8wQgPFzmbOBGd/9VEmLdrx4ngkX3wPO3hB/FkdOgYjoMmZpwffHn71vIso01PPNPZxCLpfmfoKN1L4cEsPIZKBwU6ltPuDKxA/HKZ0JC2PgGDJ4CH7whNNAl+o++ezs8/m14bS4MGg8X/ByGzzyYb7O32ip465GQFNa9tOcsf/BkGDI5DJcO79mBqaUpXM74tzvDXbvZ+eFgd8Ln4Mjjeu87xGtthed+HEpsQ6bApb+GASN7dxurn4P7Lwt//8seCttJxJZ34PX7Q9tN9buh0XbCR+DYS0PbSl9u0HcP7RbtieFF2LIszMvKhSOnh8tsB4wObVYlQ6H4SCgs673SQ0sz7FgbSnrbVsLWFdFrVWi/aaueLBoC5UfDoKPD/0zbcPHQpCbYniaCZcCJnbQPDABecvejez3SBPQ4ESx/Al65N5wJ72zLawbl48OPpC1BDJncaUPXrQtW8OPHl5GXHWP4wEJGDixkRFkhIwYWMrKskBED+zF8YAF52VmhimTb6lBHvm1VOHvdtjocNMuOCgevIyaG6o7+o3r+Q6xcGA4oK54KP+hTrglntgd6Jt7aGqpknvmX8M806tTQ6Djs+O4/99af4P99FXZtgfd/BU77RnLPvA6yVNetTUvh5TvDgbCpDobNDNVGEy+A7Nze2cbuHfCHz4dG0GPnwIf/M7FG1Z7YtATmXhyq3C69L1yz35naqqjh/v7wv2ExGHMGTJ0drlrqaamuL9i1NZw8tCWGDa+GKsF4sZxw4UTxkHAgjk8SxUOgJHpva7dpbYWa9/Yc5Let2jO8fU2oOmuTVwplY8P/fNlRoeRZuxGqlocG9i3L967KzCsJFwkMOnrPq3x8SF690L9UTxPBcuAEd6/uML2U8GCZBC5r6H290kZQswneew3WvxJ+HBtegV3Rg9Fi2aFaoS0xHDkNjphETbPxyGsbWLt1F2u31rF1y2ZiO1YzpHkDI20To2KbGGkbGRPbTBl715w15Q/CykaTVTgQ27Is/GAintMPP2ICreXh1TxoAs1lE2kuGEhLq9Pq3v7uDlkxI3/TqxS9+BNyVz+NFwyk+aQvwczPkpVXfHCllebGUHL6yw+hbks4CH7g+n0bVXdtgflfD8ljyBS44FYYemzPt5sG7k5Dcyt1jS3samimrrGFusZmGmq303/5Qwx7Zy5Fu9ZSl1vG4sEf5W+DZrHVBpGXHaMgN4vC3CwKcrMpzMmiKKuFImopaq2lyGspaNlJQUsNec07yWncSXbDDqy+OhyQdq6Hc28OCTvZ1SvV60My2LIs/I2OnR2mN+2GZfOjev+nwFvC33Hq7FAiOsgrytyd5lansbmVppZWGltaaWpxWlqc4vxsSgpyyEpHqbqlGWo34Ts30LRjAw3bK2nevoHWmg3EajaSvWsjefWbyW2u3eejdVbADutPWes28mhon94cy6OmcAS7S0bTPGAMsbKjyDliHP2OHE+//oOx7k7y3EN1VtWyPYmhbbjmvT2LxXJoHTCaloHj8BlXkjf+rB59/Z4mgsuB6wlVQ+uiySMIVUP/4u739Ciag5SUxmJ32LlhT1LY8Gp47d4e5mflhqqIASNhx7pwFrB7785Xd+cPZmtuBZU2lBUtR7B4dxlv1g1krR9BLaGOPi87/CgKvI4xvo6jbR3jbR3H2DrGx95loO35AW72/rzdOpy3fQTLWofztg8nl2auzv4jZ2W9ynYv4s7mv+PelnPYxZ6zSjPIjhlZMSM7Fovew3hudoyyfrmUF+cxqKjtlUt5cT6DinIZFE0vsd3Yi7fBX38WDhptl5wWDQ7Xij/2jdBQd/o34JSv0EwW23Y1UlXbQFVN9KptYEtN27R6qmoa2FHX1B6jmWFAzAyz8A6hcGQYsbZljL2Wi/+TtQ/v8+f0Tue5Q11jM3UNLexqbKa1m+skjFZOjS3mU1lP8IHYa7Ri/NWOpak1RhG7KGUXpRbeC62h6xUBNV7ATorYGhvI7bmXszxvMvk5MfKys/Z6z8/OIi8az4sbz8/OIj8ni9zsGAd6/MxuquGkl6/hiC0vsWzsFeQ07GDYxifJba6lNu8IlpWfy5tl57EhfzRNzR4O3HEH8LbhphbvMB5Na2470LfS1Lxnue6YQUl+Dv0Lc+hfmEv/gjA8oDCX0oIcBrRNj94HFObQvyCX4vxsGltaqalvprahmdr6ZmoamqhtG2/YM33P/Oa95tfUN7Fzd3O3MRZST0VsO6PydjIyt5qKrB0MtR0MZAdbbCCrW4ewrGkwSxoGsaqxFO+ip57smNG/MIfSgvA9SgtycPd99lv8Pm6IhnNbahneUskoX89RsQ2MtQ0cZet5b/q1vP/Czx/Yj6B9v/e8sXgA8CFCY7ERHkj/uLtv71EkvSBlVw25h/q+Da/uKTlUV4bi3cAxe78GjOq0QbausZl123azdusu3t1Wx+aahnBQixlZZnveDWIGxc1bGbRrJWV1KxhY+w4Dd62gtHYV2a17DjQNOSUsHXU5S4fPoT5WSEtrKy2t0NLaSnNrKD20v7d4mB+VKuqbWtlS28CW2ka21Dawtbah04NhbnaM8qI8xhbu4vKmhzij5k+0xnLYUnwMQ6tfY23+RG7rfy2v1w8J69nVSGc/o6K87CjR5FFenEf/wlxiBq0edq9HpZxWd5zwzl7je5ZxnNbWvU+i9xqmwxHS9h00M/rlZlGQm0W/3GwK88J7x/HC6Iy/X14YLqitJPuVu8NZdHY+nl9KS15/mnJLaMwpoSG7hPrsEnZnFbMrVkyN9aOGIqq9iGoK2NUEdY0t1De1UN/USkNz9+/1TS00NIcDRG/IoZkf5fw3H816nlrP58+tM/l9y/t5sXUirdFBLDc7Rl5WjJzsGDlZRk5WjNzsGLlZsfbh7OhkIjcaz2mfFy3f/vkYuXHraJsXixm19U1sr2tiR10jO3aH4eq6xvZpO+sTevhht7JjRnF+NkX52RTl5VCcF4b75WVTkp9NcX4OJQXRe1RCKcnPpiQ/p31eQU4WlkCJrbG5lR27G6muawrfZ1f4XtV1TWyv23u4encTWTGL9puRm521z37KyYqR1+Fv0L5vs4yTxw5i/JADvLw4ostHD2UtzaEEsnkJ1FeHm6566dr/llZne11ICltqwntVTUN4b0sYNQ3k1qzlMw1zOTm2hLtaZzG/8ALKSgrbSxZtB/ryojzKi3MpL8pnUHEuhbnqweRgtLaGs+u2xNDQ1IrvU/5JkDvZW5ZiZWPJyS+KDtpGblYoNSZy0EuF5pZWdtY3h4NoW8KIDqQ765spyMmiKD+b4rxwYC/Kyw4H/by2A382edmxPvN9+pJeTwRmdoe7p+F+9gxMBH1Ea6tT19RCv9zEzpREpG/pURcT+/HfBxGPHIJiMaMoT2f4IoejHl236O6LejsQERFJjy4TgZlNjRvOMbPvmNk8M/uBmXVyq6qIiByKuisR3BM3fDNwFPDvQAFwexJjEhGRFOqu0je+RfAsws1lTWb2HPB6csMSEZFU6S4RlJrZRwmlhjx3bwJwdzezQ+uaUxER6VJ3ieAvwKxo+EUzG+zum8xsCLAl+aGJiEgqdJkI3P2KLqZvJFQV7ZeZnQv8F5AF3OXuN3eY/59AW29YhcAR7t4LnaiLiEiienRhuJkNiRJCd8tkAbcS+iaqBF42s3nuvrRtGXe/Nm75LwF9uLN/EZHDU0874k7k8ZQzgRXuvsrdG4H7gQu6WX4O8NsexiMiIj3U0xvK/i6BxSrY02sphFJBpw8XNbORwGjgmS7mX2VmC81sYVVV1YGGKyIi3Ujmgz0765Cmq6uNZgMPu3tLZzPd/Q53n+HuM8rLy3stQBER6WEiMLM/JbBYJRD/wNRhhGced2Y2qhYSEUmLnpYIPpfAMi8D48xstJnlEg728zouZGbjgQHACz2MRUREDkJCicDMBkYPqQHA3d/rbvlomWbgauBx4C3gQXdfYmY3mdmsuEXnAPf7ofZgBBGRw0SXl4+a2QjgR4R7BnaESVZCaNC9zt3X7G/l7j4fmN9h2vUdxm844KhFRKTXdFcieAD4AzDE3ce5+1HAUOCPhEtBRUTkMNBdIhjk7g/EX8nj7i3ufj9QlvzQREQkFbq7s3iRmd0G3Mue+wGGA5cDryY7MBERSY3uEsGngCuBGwk3ghkhITxKYncWi4jIIaC7TucagV9ELxEROUx196jK75jZwG7mf8DMPpycsEREJFW6qxpaDDxqZvXAK0AVkA+MA44DngJ+kPQIRUQkqbqrGnoEeMTMxgGnEC4d3Qn8GrjK3XenJkQREUmm/T6PwN3fAd5JQSwiIpIGyex9VEREDgFKBCIiGU6JQEQkw+23jcDMbulkcjWwMGpQFhGRQ1giJYJ8wuWibY3GU4GBwJVm9tMkxiYiIimw3xIBcBTwgej5ApjZL4AngLMJ9xqIiMghLJESQQXQL268H3Bk1CtpQ1KiEhGRlEmkRPAj4DUze5bQ8dxpwA/MrB/h7mIRETmEJXJD2S/NbD4wk5AI/tnd2x5C//VkBiciIsmX6OWjMUJfQ9uAo8zstOSFJCIiqZTI5aM/BC4FlgCt0WQHnktiXCIikiKJtBFcCIx3dzUMi4gchhKpGloF5CQ7EBERSY9ESgR1hKuGnibuclF3/3LSohIRkZRJJBHMi14iInIYSuTy0XtTEYiIiKRHl4nAzB5090vMbDHhKqG9uPvUpEYmIiIp0V2J4JroXQ+oFxE5jHV51ZC7vxcNfsHd18a/gC8ksnIzO9fMlpnZCjO7rotlLjGzpWa2xMx+c+BfQUREDkYil4+e3cm08/b3ITPLAm6Nlp0IzDGziR2WGQd8CzjF3ScBX0kgHhER6UXdtRH8I+HMf4yZvRE3qxh4PoF1zwRWuPuqaH33AxcAS+OW+Rxwq7tvB3D3zQcWvoiIHKzu2gh+AzwG/BsQX61T4+7bElh3BbAubrwSOLHDMkcDmNnzQBZwg7v/ueOKzOwq4CqAESNGJLBpERFJVHdtBNXuvsbd50TtArsJVw8VmVkiR2PrbLUdxrOBccAZwBzgLjPr30ksd7j7DHefUV5ensCmRUQkUfttIzCzj5jZO8Bq4C/AGkJJYX8qgeFx48OADZ0s84i7N7n7amAZITGIiEiKJNJY/H3gJGC5u48GziKxNoKXgXFmNtrMcoHZ7HuH8h+BMwHMbBChqmhVgrGLiEgvSCQRNLn7ViBmZjF3X0B4mH23omccXw08DrwFPOjuS8zsJjObFS32OLDVzJYCC4CvR9sSEZEUSaSvoR1mVkR4/sBcM9sMNCeycnefD8zvMO36uGEHvhq9REQkDRIpEVxA6IH0WuDPwErgI8kMSkREUieRTud2RYOtwL3RjWKzgbnJDExERFKjyxKBmZWY2bfM7Odmdo4FVxMacy9JXYgiIpJM3ZUI7gO2Ay8AnwW+DuQCF7j7aymITUREUqC7RDDG3acAmNldwBZghLvXpCQyERFJie4ai5vaBty9BVitJCAicvjprkRwrJntjIYNKIjGjXDlZ0nSoxMRkaTrMhG4e1YqAxERkfRI5D4CERE5jCkRiIhkOCUCEZEMp0QgIpLhlAhERDKcEoGISIZTIhARyXBKBCIiGU6JQEQkwykRiIhkOCUCEZEMp0QgIpLhlAhERDKcEoGISIZTIhARyXBKBCIiGU6JQEQkwykRiIhkOCUCEZEM193D6w+amZ0L/BeQBdzl7jd3mP9p4MfA+mjSz939rmTGJCJ9R1NTE5WVldTX16c7lMNGfn4+w4YNIycnJ+HPJC0RmFkWcCtwNlAJvGxm89x9aYdFH3D3q5MVh4j0XZWVlRQXFzNq1CjMLN3hHPLcna1bt1JZWcno0aMT/lwyq4ZmAivcfZW7NwL3AxckcXsicoipr6+nrKxMSaCXmBllZWUHXMJKZiKoANbFjVdG0zr6uJm9YWYPm9nwJMYjIsMcjc0AAA6ASURBVH2QkkDv6sn+TGYi6Cwa7zD+KDDK3acCTwH3drois6vMbKGZLayqqurlMEVEMlsyE0ElEH+GPwzYEL+Au29194Zo9E7g+M5W5O53uPsMd59RXl6elGBFRDJVMhPBy8A4MxttZrnAbGBe/AJmNjRudBbwVhLjERHZy44dO7jtttsO+HPnn38+O3bsSEJE6ZG0q4bcvdnMrgYeJ1w+ere7LzGzm4CF7j4P+LKZzQKagW3Ap5MVj4j0bTc+uoSlG3b26jonHlnC9z4yqcv5bYngC1/4wl7TW1payMrK6vJz8+fP77UY+4Kk3lDm7vPd/Wh3H+vu/xpNuz5KArj7t9x9krsf6+5nuvvbyYxHRCTeddddx8qVKznuuOM44YQTOPPMM/nEJz7BlClTALjwwgs5/vjjmTRpEnfccUf750aNGsWWLVtYs2YNEyZM4HOf+xyTJk3inHPOYffu3V1u74wzzuDaa6/ltNNOY8KECbz88st87GMfY9y4cXznO99pX66r7T7xxBOcfPLJTJ8+nYsvvpja2tre2RHufki9jj/+eBeRw8PSpUvTuv3Vq1f7pEmT3N19wYIFXlhY6KtWrWqfv3XrVnd3r6ur80mTJvmWLVvc3X3kyJFeVVXlq1ev9qysLH/11Vfd3f3iiy/2++67r8vtnX766f6Nb3zD3d1/+tOf+tChQ33Dhg1eX1/vFRUV7evvbLtVVVV+6qmnem1trbu733zzzX7jjTd2up3O9iuhJqbT42pS7ywWETmUzJw5c68bsW655Rb+8Ic/ALBu3TreeecdysrK9vrM6NGjOe644wA4/vjjWbNmTbfbmDVrFgBTpkxh0qRJDB0amkrHjBnDunXrKCsr63S7W7ZsYenSpZxyyikANDY2cvLJJx/8lybJXUyIiBxK+vXr1z787LPP8tRTT/HCCy9QWFjIGWec0emNWnl5ee3DWVlZ3VYNxS8fi8X2+mwsFqO5ubnL7bo7Z599Nr/97W8P9mvuQ53OiUjGKi4upqamptN51dXVDBgwgMLCQt5++21efPHFlMTU1XZPOukknn/+eVasWAFAXV0dy5cv75VtqkQgIhmrrKyMU045hcmTJ1NQUMDgwYPb55177rncfvvtTJ06lfHjx3PSSSelJKautlteXs4999zDnDlzaGgIt199//vf5+ijjz7obVpoQzh0zJgxwxcuXJjuMESkF7z11ltMmDAh3WEcdjrbr2a2yN1ndLa8qoZERDKcqoZERHrZF7/4RZ5//vm9pl1zzTVcccUVaYqoe0oEIiK97NZbb013CAdEVUMiIhlOiUBEJMMpEYiIZDglAhGRDKdEICKSoKKionSHkBS6akhE+obHroONi3t3nUOmwHk39+46D0MqEYhIxvrmN7+51xPKbrjhBm688UbOOusspk+fzpQpU3jkkUcSWtezzz7L6aefziWXXMLRRx/Nddddx9y5c5k5cyZTpkxh5cqVADz66KOceOKJTJs2jQ9+8INs2rQJgF27dvGZz3yGE044gWnTpiW83V7RVf/UffWl5xGIHD7S/TyCV155xU877bT28QkTJvjatWu9urra3d2rqqp87Nix3tra6u7u/fr163JdCxYs8NLS0vbnCxx55JF+/fXXu3t49sA111zj7u7btm1rX9+dd97pX/3qV93d/Vvf+lb7swy2b9/u48aNa3/2wIHS8whERBI0bdo0Nm/ezIYNG6iqqmLAgAEMHTqUa6+9lueee45YLMb69evZtGkTQ4YM2e/6TjjhhPbnC4wdO5ZzzjkHCM8eWLBgAQCVlZVceumlvPfeezQ2NrY//+CJJ55g3rx5/OQnPwGgvr6ed999NyV9MSkRiEhGu+iii3j44YfZuHEjs2fPZu7cuVRVVbFo0SJycnIYNWpUp88h6EzH5wvEP3ugubkZgC996Ut89atfZdasWTz77LPccMMNQKid+d3vfsf48eN79wsmQG0EIpLRZs+ezf3338/DDz/MRRddRHV1NUcccQQ5OTksWLCAtWvX9ur2qqurqaioAODee+9tn/6hD32In/3sZ3jUI/Srr77aq9vtjhKBiGS0SZMmUVNTQ0VFBUOHDuWyyy5j4cKFzJgxg7lz53LMMcf06vZuuOEGLr74Yk499VQGDRrUPv273/0uTU1NTJ06lcmTJ/Pd7363V7fbHT2PQETSRs8jSA49j0BERA6IGotFRA7A4sWL+eQnP7nXtLy8PF566aU0RXTwlAhEJK3cHTNLdxgJmzJlCq+99lq6w+hST6r7VTUkImmTn5/P1q1be3Twkn25O1u3biU/P/+APqcSgYikzbBhw6isrKSqqirdoRw28vPzGTZs2AF9RolARNImJyen/c5aSZ+kVg2Z2blmtszMVpjZdd0sd5GZuZl1emmTiIgkT9ISgZllAbcC5wETgTlmNrGT5YqBLwOHbpO7iMghLJklgpnACndf5e6NwP3ABZ0s9y/Aj4DEOvMQEZFelcw2ggpgXdx4JXBi/AJmNg0Y7u5/MrOvdbUiM7sKuCoarTWzZT2MaRCwpYefTQXFd3AU38Hr6zEqvp4b2dWMZCaCzi4Mbr9GzMxiwH8Cn97fitz9DuCOgw7IbGFXt1j3BYrv4Ci+g9fXY1R8yZHMqqFKYHjc+DBgQ9x4MTAZeNbM1gAnAfPUYCwiklrJTAQvA+PMbLSZ5QKzgXltM9292t0Hufsodx8FvAjMcnf1KCcikkJJSwTu3gxcDTwOvAU86O5LzOwmM5uVrO3ux0FXLyWZ4js4iu/g9fUYFV8SHHLdUIuISO9SX0MiIhlOiUBEJMMdlolgf11bmFmemT0QzX/JzEalMLbhZrbAzN4ysyVmdk0ny5xhZtVm9lr0uj5V8UXbX2Nmi6Nt79N4b8Et0f57w8ympzC28XH75TUz22lmX+mwTMr3n5ndbWabzezNuGkDzexJM3sneh/QxWcvj5Z5x8wuT1FsPzazt6O/3x/MrH8Xn+32t5DkGG8ws/Vxf8fzu/hsQl3ZJCG+B+JiW2NmnfZNnap9eFDc/bB6AVnASmAMkAu8DkzssMwXgNuj4dnAAymMbygwPRouBpZ3Et8ZwJ/SuA/XAIO6mX8+8BjhXpGTgJfS+LfeCIxM9/4DTgOmA2/GTfsRcF00fB3ww04+NxBYFb0PiIYHpCC2c4DsaPiHncWWyG8hyTHeAHwtgd9At//vyYqvw/x/B65P5z48mNfhWCJIpGuLC4B7o+GHgbMsRU/GcPf33P2VaLiGcEVVRSq23YsuAH7lwYtAfzMbmoY4zgJWuvvaNGx7L+7+HLCtw+T439m9wIWdfPRDwJPuvs3dtwNPAucmOzZ3f8LDlX0QLt0+sH6Le1kX+y8RiXZlc1C6iy86dlwC/La3t5sqh2Mi6Kxri44H2vZlon+GaqAsJdHFiaqkptF5h3snm9nrZvaYmU1KaWDhDvAnzGxR1L1HR4ns41SYTdf/fOncf20Gu/t7EE4AgCM6WaYv7MvPEEp4ndnfbyHZro6qr+7uomqtL+y/U4FN7v5OF/PTvQ/363BMBN12bXEAyySVmRUBvwO+4u47O8x+hVDdcSzwM+CPqYwNOMXdpxN6jv2imZ3WYX5f2H+5wCzgoU5mp3v/HYi07ksz+zbQDMztYpH9/RaS6RfAWOA44D1C9UtHaf8tAnPovjSQzn2YkMMxEeyva4u9ljGzbKCUnhVLe8TMcghJYK67/77jfHff6e610fB8IMfMBqUqPnffEL1vBv5AKH7HS2QfJ9t5wCvuvqnjjHTvvzib2qrMovfNnSyTtn0ZNUx/GLjMo8rsjhL4LSSNu29y9xZ3bwXu7GLbaf0tRsePjwEPdLVMOvdhog7HRNBt1xaReUDb1RkXAc909Y/Q26L6xF8Cb7n7f3SxzJC2Ngszm0n4O21NUXz9LDwjAjPrR2hUfLPDYvOAT0VXD50EVLdVgaRQl2dh6dx/HcT/zi4HHulkmceBc8xsQFT1cU40LanM7Fzgm4RuXeq6WCaR30IyY4xvd/poF9tO5P89mT4IvO3ulZ3NTPc+TFi6W6uT8SJc1bKccDXBt6NpNxF+9AD5hCqFFcDfgDEpjO39hKLrG8Br0et84B+Af4iWuRpYQrgC4kXgfSmMb0y03dejGNr2X3x8Rnjo0EpgMTAjxX/fQsKBvTRuWlr3HyEpvQc0Ec5SryS0Oz0NvBO9D4yWnQHcFffZz0S/xRXAFSmKbQWhbr3tN9h2Fd2RwPzufgsp3H/3Rb+vNwgH96EdY4zG9/l/T0V80fR72n53ccumZR8ezEtdTIiIZLjDsWpIREQOgBKBiEiGUyIQEclwSgQiIhlOiUBEJMMpEYhEzKylQ8+mvdaTpZmNiu+5UqQvyU53ACJ9yG53Py7dQYikmkoEIvsR9Sf/QzP7W/Q6Kpo+0syejjpFe9rMRkTTB0d9/L8evd4XrSrLzO608ByKJ8ysIFr+y2a2NFrP/Wn6mpLBlAhE9ijoUDV0ady8ne4+E/g58NNo2s8J3XFPJXTadks0/RbgLx46vZtOuKMUYBxwq7tPAnYAH4+mXwdMi9bzD8n6ciJd0Z3FIhEzq3X3ok6mrwE+4O6rog4DN7p7mZltIXR70BRNf8/dB5lZFTDM3Rvi1jGK8NyBcdH4N4Ecd/++mf0ZqCX0kvpHjzrME0kVlQhEEuNdDHe1TGca4oZb2NNG93eEvpuOBxZFPVqKpIwSgUhiLo17fyEa/iuht0uAy4D/i4afBv4RwMyyzKykq5WaWQwY7u4LgG8A/YF9SiUiyaQzD5E9Cjo8gPzP7t52CWmemb1EOHmaE037MnC3mX0dqAKuiKZfA9xhZlcSzvz/kdBzZWeygF+bWSmhV9f/dPcdvfaNRBKgNgKR/YjaCGa4+5Z0xyKSDKoaEhHJcCoRiIhkOJUIREQynBKBiEiGUyIQEclwSgQiIhlOiUBEJMP9f+B25xSR7QkBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer1 = 10\n",
    "layer2 = 100\n",
    "batch_size = 10\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(layer1, input_dim=nmovies+nusers, activation='relu',\n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.00001))) # input_shape=(n,nmovies)\n",
    "\n",
    "model.add(layers.Dense(layer2, activation='relu',\n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "#model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "opt = optimizers.RMSprop()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=opt,\n",
    "              metrics=['mae'])\n",
    "#model.summary()\n",
    "\n",
    "history = model.fit(X, y,\n",
    "                    shuffle=True,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.15,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)]\n",
    "                    )\n",
    "\n",
    "plt.ylabel(\"Rating (0..5.0) MAE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "accur = history.history['mae']\n",
    "plt.plot(accur, label='train_mae')\n",
    "val_accur = history.history['val_mae']\n",
    "plt.plot(val_accur, label='val_mae')\n",
    "# plt.xlim(0, 200)\n",
    "plt.ylim(0.4, 1.00)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a matrix that maps user and movie to a rating. Most of the entries will be zero because not all users have seen all movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.zeros(shape=(nusers+1,nmovies+1))\n",
    "for u,m,r in df_ratings.values:\n",
    "    ratings[int(u),int(m)] = r\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and uncompress [movie review polarity data set v2.0](https://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz) and put into `data` subdir.  The files contain positive and negative reviews:\n",
    "\n",
    "```\n",
    "data/review_polarity/txt_sentoken/\n",
    "├── neg\n",
    "│   ├── cv000_29416.txt\n",
    "│   ├── cv001_19502.txt\n",
    "│   ├── cv002_17424.txt\n",
    "...\n",
    "└── pos\n",
    "    ├── cv000_29590.txt\n",
    "    ├── cv001_18431.txt\n",
    "    ├── cv002_15918.txt\n",
    "    ├── cv003_11664.txt\n",
    "...\n",
    "```\n",
    "\n",
    "The idea will be to map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
