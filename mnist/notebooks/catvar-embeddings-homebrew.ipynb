{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding sparse vectors into high-but-lower-dimensional dense space\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/parrt/playdl/blob/master/mnist/notebooks/catvar-embeddings-homebrew.ipynb)\n",
    "\n",
    "One-hot vectors are simple but the vocabulary size can make word vectors extremely long; high dimensionality. And they are very sparse, mostly zeros.\n",
    "\n",
    "Word embeddings, on the other hand, embed that massive dimensional space into a smaller, dense space. For example, [GloVE](https://nlp.stanford.edu/projects/glove/) has pre-trained word embeddings of various sizes such as 50 and 300 dimensions. Unlike word vectors, we need to do some training to compute embeddings. I've used pre-trained word-to-embedding dictionaries to good effect, but we can also train and embedding specific to our task as part of our model, using an embedding layer.\n",
    "\n",
    "In this notebook, I'm going to explore creating dense vectors, first by playing around with random dense vectors for words and then move on to trying to create dense vectors for categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting random but dense not sparse vectors\n",
    "\n",
    "In [word-vectors](word-vectors.ipynb), we created sparse vectors representing words. When added together, these create bag of words (BOW) representations of documents. We can just turn on the particular position of a word in the vector if that word is present in the document. \n",
    "\n",
    "If we are passing words individually to a recurrent neural network (RNN), then these sparse vectors can get pretty big. If there are 20,000 words in the dictionary, we might have vectors of size 20,000. What we need is a dense representation that still gives us unique representations of each word.  (We also used to the hash trick also to try to shrink the size of the sparse vectors, but they are still sparse.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample tweets from my twitter inbox with added text for experimentation\n",
    "samples = [\n",
    "    \"\"\"Tesla Motors has nothing to do with this tweet.\n",
    "    On those rare occasions when I really, really need to reduce the\n",
    "    size of a file I use \"xz -9\". Today I found out about the \"extreme\" setting\n",
    "    and \"xz -e9\" squeezed files down another 15% or so. It is not exactly quick,\n",
    "    but that doesn't really matter in such cases!\"\"\",\n",
    "    \n",
    "    \"\"\"Securities and exchange commission has nothing to do with this tweet.\n",
    "    Do grad students get paid a lot? No. But do we at least have solid\n",
    "    job security? Also, no. But are we at least ensured a stress-free work\n",
    "    environment with a healthy work-life balance? Still, also no.\"\"\",\n",
    "\n",
    "    \"\"\"A design process hyperfocused on A/B testing can result in dark patterns even\n",
    "    if that’s not the intent. That’s because most A/B tests are based on metrics\n",
    "    that are relevant to the company’s bottom line, even if they result in harm to users.\"\"\"\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "words = tokenizer.word_index.keys() # get tokenized words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not using a hash function but instead dense factors, we need a dictionary to keep track of the word to vector mapping. But, we can create vectors of any length and get very little chance of collision. For example, even with a single floating-point number between 0 and 1, with our 96 words in the vocabulary, there's almost no chance of collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashwords(words, dimensionality = 4):\n",
    "    return {w:np.random.random(size=dimensionality) for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', array([0.26118067, 0.13403861, 0.61027729, 0.11396323])),\n",
       " ('to', array([0.32063386, 0.1671196 , 0.51435688, 0.0872403 ])),\n",
       " ('do', array([0.55765043, 0.03150559, 0.67089196, 0.74617893])),\n",
       " ('the', array([0.68176234, 0.91857488, 0.64404817, 0.71503278])),\n",
       " ('with', array([0.06174732, 0.39597205, 0.37767156, 0.69615172])),\n",
       " ('on', array([0.81636026, 0.46140716, 0.36661449, 0.44821374])),\n",
       " ('i', array([0.01798426, 0.91843474, 0.45449603, 0.57520315])),\n",
       " ('really', array([0.32699358, 0.76191127, 0.33386607, 0.90638247])),\n",
       " ('but', array([0.54423901, 0.38834331, 0.62148659, 0.39675912])),\n",
       " ('in', array([0.46300173, 0.80064166, 0.65154614, 0.24719102]))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = hashwords(words, dimensionality=4)\n",
    "list(index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 collisions between dense word vectors\n"
     ]
    }
   ],
   "source": [
    "ncollisions = len(index) - len(set([tuple(a) for a in index.values()]))\n",
    "print(f\"There were {ncollisions} collisions between dense word vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we only use dimensionality=1, then we are right back to label encoding, just with a floating-point number instead of an integer. We need at least a dimensionality of two.\n",
    "\n",
    "What happens if we need to send an entire document not just a single word into a model? We need a continuous bag of words (CBOW), which is easy for one hot encoding.  We just turn on all relevant word-columns. For dense vectors, we either need to concatenate them together or sum or average them into a single vector. If documents are different length, then concatenating them doesn't work because models typically require fixed length input.\n",
    "\n",
    "Those vectors are dense but there is literally no meaning to the values in the vector positions. Two similar words are in no way similar in some kind of semantic space. We are not helping the model very much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>50</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>1214</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>275</td>\n",
       "      <td>541</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>428</td>\n",
       "      <td>5064</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>150</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0     239       50     4.5\n",
       "1     265     1214     2.0\n",
       "2     275      541     5.0\n",
       "3     428     5064     3.0\n",
       "4     229      150     5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "\n",
    "def load(n = 10):\n",
    "    df_ratings = pd.read_csv('data/ml-latest-small/ratings.csv')\n",
    "    df_ratings = df_ratings.drop('timestamp', axis=1)\n",
    "    df_ratings = df_ratings.sample(n=n).reset_index(drop=True)\n",
    "    return df_ratings\n",
    "\n",
    "df_ratings = load(n=10_000)\n",
    "df_ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  50, 1214,  541, 5064,  150])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings['movieId'].head(5).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing arbitrarily large IDs to 1..n indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than deal with arbitrarily large integers representing the various IDs, let's compress that down to unique but adjacent integers. This is also how I would handle string to integer encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "catencoders = {} # convert real movie, user ID to compressed index value\n",
    "index_to_id = {} \n",
    "def compress_cats(df, colname):\n",
    "    df[colname] = df[colname].astype('category').cat.as_ordered()\n",
    "    catencoders[colname] = df[colname].cat.categories\n",
    "    index_to_id[colname] = df[colname].cat.categories.values\n",
    "    df[colname] = df[colname].cat.codes + 1 # encode 1..n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That function compresses one column at a time and modifies the data frame in place. Compare the movie IDs with the values above. We have converted `[3696,  281,  592, 1293, 4446]` to `[4, 1, 2, 3, 5]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>275</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>428</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0     239        1     4.5\n",
       "1     265        4     2.0\n",
       "2     275        3     5.0\n",
       "3     428        5     3.0\n",
       "4     229        2     5.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiny = df_ratings.head(5).copy()\n",
    "compress_cats(df_tiny, \"movieId\")\n",
    "df_tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also gotten a mapping from ID to the tiny index that we can use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([50, 150, 541, 1214, 5064], dtype='int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catencoders['movieId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later when we want to convert movie IDs to indexes, we can reuse the catencoders, but remember that pandas will display the values using the category \"ID names\" not the code unless we convert it to the \"code\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>275</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>428</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0     239        1     4.5\n",
       "1     265        4     2.0\n",
       "2     275        3     5.0\n",
       "3     428        5     3.0\n",
       "4     229        2     5.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiny = df_ratings.head(5).copy()\n",
    "df_tiny['movieId'] = pd.Categorical(df_tiny['movieId'], categories=catencoders['movieId'], ordered=True)\n",
    "df_tiny['movieId'] = df_tiny['movieId'].cat.codes+1\n",
    "df_tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map movie to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try mapping users to movies with a neural network. Presumably people self filter the movies they watch and so there could be information that will tell us about users and/or movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import models, layers, callbacks, optimizers\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 596, 3595)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_cats(df_ratings, \"userId\")\n",
    "compress_cats(df_ratings, \"movieId\")\n",
    "nusers = len(df_ratings.groupby('userId').count())\n",
    "nmovies = len(df_ratings.groupby('movieId').count())\n",
    "n = len(df_ratings)\n",
    "n, nusers, nmovies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the neural network will be one hot encoded movie identifiers. The output will also be one hot encoded user IDs, but keras will handle that part for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3595), (10000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(df_ratings['movieId'])\n",
    "y = df_ratings['userId'] #pd.get_dummies(df_ratings['userId'])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3586</th>\n",
       "      <th>3587</th>\n",
       "      <th>3588</th>\n",
       "      <th>3589</th>\n",
       "      <th>3590</th>\n",
       "      <th>3591</th>\n",
       "      <th>3592</th>\n",
       "      <th>3593</th>\n",
       "      <th>3594</th>\n",
       "      <th>3595</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3595 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...  3586  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   3587  3588  3589  3590  3591  3592  3593  3594  3595  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[3 rows x 3595 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    236\n",
       "1    261\n",
       "2    270\n",
       "Name: userId, dtype: int16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = 20\n",
    "layer2 = 200\n",
    "batch_size = 50\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(layer1, name='embedding', input_dim=nmovies, activation='relu')) # input_shape=(n,nmovies)\n",
    "model.add(layers.Dense(layer2, activation='relu'))\n",
    "model.add(layers.Dense(nusers+1, activation='softmax'))\n",
    "\n",
    "opt = optimizers.RMSprop()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a18dfc871064130a4790289e5146abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=50.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keras validation accuracy 0.3035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X, y,\n",
    "                    shuffle=True,\n",
    "                    epochs=50,\n",
    "                    validation_split=0.10,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)]\n",
    "                    )\n",
    "\n",
    "y_pred = model.predict(X.values.reshape(-1,nmovies))\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "val_accur = accuracy_score(y, y_pred)\n",
    "print(\"Keras validation accuracy\", val_accur)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "accur = history.history['accuracy']\n",
    "plt.plot(accur, label='train_accuracy')\n",
    "val_accur = history.history['val_accuracy']\n",
    "plt.plot(val_accur, label='valid_accuracy')\n",
    "# plt.xlim(0, 200)\n",
    "# plt.ylim(0.5, 1.02)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation error is terrible, but [Oliver](http://www.zeigermann.eu/) says we care about training error for getting embeddings since we won't be using the predictions.  In his example, he only has about 10% accuracy so I'm going to consider roughly 30% quite good. :)\n",
    "\n",
    "[Here](https://djcordhose.github.io/ml-workshop/2019-embeddings.html#/17), Oliver explains how to get the embeddings out. These are the outputs from the first constrained layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03, -0.07, -0.05, ..., -0.14, -0.1 , -0.09],\n",
       "       [ 0.05,  0.07, -0.08, ...,  0.13,  0.08,  0.01],\n",
       "       [-0.05,  0.01, -0.09, ...,  0.04,  0.  , -0.07],\n",
       "       ...,\n",
       "       [-0.01, -0.01, -0.03, ...,  0.03, -0.  , -0.05],\n",
       "       [-0.04,  0.03, -0.04, ...,  0.01,  0.01,  0.01],\n",
       "       [-0.11,  0.05, -0.06, ..., -0.01, -0.1 ,  0.15]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = model.get_layer('embedding')\n",
    "w, b = embedding_layer.get_weights()\n",
    "w.shape\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3586</th>\n",
       "      <th>3587</th>\n",
       "      <th>3588</th>\n",
       "      <th>3589</th>\n",
       "      <th>3590</th>\n",
       "      <th>3591</th>\n",
       "      <th>3592</th>\n",
       "      <th>3593</th>\n",
       "      <th>3594</th>\n",
       "      <th>3595</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3595 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...  3586  \\\n",
       "0     1     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     1     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   3587  3588  3589  3590  3591  3592  3593  3594  3595  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 3595 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_movieIds = np.unique(df_ratings['movieId'])\n",
    "uniq_movieIds_onehot = pd.get_dummies(uniq_movieIds)\n",
    "uniq_movieIds_onehot.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3595, 3595), (3595, 20), (20,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_movieIds_onehot.shape, w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the weight matrix is the transpose of what I would expect. For example, I like the convention of a row being the weights of a single neuron. Since I have 20 neurons, I would expect 20 rows, but still we can just reverse the operators of the dot product. The following should give us the output of the embedding layer:  take the dot product of every input movie one-hot and multiply times the weight vector then add the bias. Note: The dot product is really just selecting the ith row of w for one-hot turned on at position i.  A row in w is the set of weights across neurons for a particular feature, a word in our case. That gives us a vector in 20-space where each dimension is some semantic meaning we got from a neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3595, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.14,  0.  ,  0.04, ..., -0.01, -0.  , -0.  ],\n",
       "       [ 0.16,  0.15,  0.  , ...,  0.26,  0.18,  0.1 ],\n",
       "       [ 0.06,  0.08, -0.  , ...,  0.17,  0.1 ,  0.02],\n",
       "       ...,\n",
       "       [ 0.09,  0.06,  0.05, ...,  0.16,  0.1 ,  0.04],\n",
       "       [ 0.07,  0.1 ,  0.05, ...,  0.14,  0.1 ,  0.1 ],\n",
       "       [-0.  ,  0.12,  0.03, ...,  0.13,  0.  ,  0.24]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embeddings = np.dot(uniq_movieIds_onehot, w) + b\n",
    "print(movie_embeddings.shape)\n",
    "movie_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title                                       genres\n",
       "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1        2    Jumanji (1995)                   Adventure|Children|Fantasy"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies = pd.read_csv('data/ml-latest-small/movies.csv')\n",
    "df_movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                    title  \\\n",
       "0        1         Toy Story (1995)   \n",
       "1        2           Jumanji (1995)   \n",
       "2        3  Grumpier Old Men (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['movieId'] = pd.Categorical(df_movies['movieId'], categories=catencoders['movieId'], ordered=True)\n",
    "df_movies['movieId'] = df_movies['movieId'].cat.codes+1\n",
    "df_movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>39</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>208</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>50</td>\n",
       "      <td>1771</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Diary of a Chambermaid (Journal d'une femme de...</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>36</td>\n",
       "      <td>1720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Longest Yard, The (1974)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>585</td>\n",
       "      <td>419</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Bulletproof (1996)</td>\n",
       "      <td>Action|Comedy|Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>464</td>\n",
       "      <td>1775</td>\n",
       "      <td>3.5</td>\n",
       "      <td>All That Heaven Allows (1955)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>124</td>\n",
       "      <td>3524</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Captain Fantastic (2016)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId  rating  \\\n",
       "0        236       39     4.5   \n",
       "1        273       39     5.0   \n",
       "2        130       39     4.0   \n",
       "3         18       39     5.0   \n",
       "4        208       39     4.0   \n",
       "...      ...      ...     ...   \n",
       "9995      50     1771     3.5   \n",
       "9996      36     1720     2.0   \n",
       "9997     585      419     1.5   \n",
       "9998     464     1775     3.5   \n",
       "9999     124     3524     4.5   \n",
       "\n",
       "                                                  title  \\\n",
       "0                            Usual Suspects, The (1995)   \n",
       "1                            Usual Suspects, The (1995)   \n",
       "2                            Usual Suspects, The (1995)   \n",
       "3                            Usual Suspects, The (1995)   \n",
       "4                            Usual Suspects, The (1995)   \n",
       "...                                                 ...   \n",
       "9995  Diary of a Chambermaid (Journal d'une femme de...   \n",
       "9996                           Longest Yard, The (1974)   \n",
       "9997                                 Bulletproof (1996)   \n",
       "9998                      All That Heaven Allows (1955)   \n",
       "9999                           Captain Fantastic (2016)   \n",
       "\n",
       "                      genres  \n",
       "0     Crime|Mystery|Thriller  \n",
       "1     Crime|Mystery|Thriller  \n",
       "2     Crime|Mystery|Thriller  \n",
       "3     Crime|Mystery|Thriller  \n",
       "4     Crime|Mystery|Thriller  \n",
       "...                      ...  \n",
       "9995            Comedy|Drama  \n",
       "9996                  Comedy  \n",
       "9997     Action|Comedy|Crime  \n",
       "9998           Drama|Romance  \n",
       "9999                   Drama  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.merge(df_movies, on='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie+user -> rating\n",
    "\n",
    "Ok, Let's try to map both the movie and the user to a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 590, 3653)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = load(n=10000)\n",
    "compress_cats(df_ratings, \"userId\")\n",
    "compress_cats(df_ratings, \"movieId\")\n",
    "nusers = len(df_ratings.groupby('userId').count())\n",
    "nmovies = len(df_ratings.groupby('movieId').count())\n",
    "n = len(df_ratings)\n",
    "n, nusers, nmovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 4243), (10000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([pd.get_dummies(df_ratings['movieId']),\n",
    "               pd.get_dummies(df_ratings['userId'])], axis=1)\n",
    "y = df_ratings['rating'] #pd.get_dummies(df_ratings['userId'])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e7a4737bb54bd0b8d040fd7cf8e0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=20.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer1 = 10\n",
    "layer2 = 100\n",
    "batch_size = 10\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(layer1, input_dim=nmovies+nusers, activation='relu',\n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.00001))) # input_shape=(n,nmovies)\n",
    "\n",
    "model.add(layers.Dense(layer2, activation='relu',\n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "#model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "opt = optimizers.RMSprop()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=opt,\n",
    "              metrics=['mae'])\n",
    "#model.summary()\n",
    "\n",
    "history = model.fit(X, y,\n",
    "                    shuffle=True,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.15,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)]\n",
    "                    )\n",
    "\n",
    "plt.ylabel(\"Rating (0..5.0) MAE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "accur = history.history['mae']\n",
    "plt.plot(accur, label='train_mae')\n",
    "val_accur = history.history['val_mae']\n",
    "plt.plot(val_accur, label='val_mae')\n",
    "# plt.xlim(0, 200)\n",
    "plt.ylim(0.4, 1.00)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
