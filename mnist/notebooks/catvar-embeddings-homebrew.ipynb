{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding sparse vectors into high-but-lower-dimensional dense space\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/parrt/playdl/blob/master/mnist/notebooks/catvar-embeddings-homebrew.ipynb)\n",
    "\n",
    "One-hot vectors are simple but the vocabulary size can make word vectors extremely long; high dimensionality. And they are very sparse, mostly zeros.\n",
    "\n",
    "Word embeddings, on the other hand, embed that massive dimensional space into a smaller, dense space. For example, [GloVE](https://nlp.stanford.edu/projects/glove/) has pre-trained word embeddings of various sizes such as 50 and 300 dimensions. Unlike word vectors, we need to do some training to compute embeddings. I've used pre-trained word-to-embedding dictionaries to good effect, but we can also train and embedding specific to our task as part of our model, using an embedding layer.\n",
    "\n",
    "In this notebook, I'm going to explore creating dense vectors, first by playing around with random dense vectors for words and then move on to trying to create dense vectors for categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting random but dense not sparse vectors\n",
    "\n",
    "In [word-vectors](word-vectors.ipynb), we created sparse vectors representing words. When added together, these create bag of words (BOW) representations of documents. We can just turn on the particular position of a word in the vector if that word is present in the document. \n",
    "\n",
    "If we are passing words individually to a recurrent neural network (RNN), then these sparse vectors can get pretty big. If there are 20,000 words in the dictionary, we might have vectors of size 20,000. What we need is a dense representation that still gives us unique representations of each word.  (We also used to the hash trick also to try to shrink the size of the sparse vectors, but they are still sparse.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample tweets from my twitter inbox with added text for experimentation\n",
    "samples = [\n",
    "    \"\"\"Tesla Motors has nothing to do with this tweet.\n",
    "    On those rare occasions when I really, really need to reduce the\n",
    "    size of a file I use \"xz -9\". Today I found out about the \"extreme\" setting\n",
    "    and \"xz -e9\" squeezed files down another 15% or so. It is not exactly quick,\n",
    "    but that doesn't really matter in such cases!\"\"\",\n",
    "    \n",
    "    \"\"\"Securities and exchange commission has nothing to do with this tweet.\n",
    "    Do grad students get paid a lot? No. But do we at least have solid\n",
    "    job security? Also, no. But are we at least ensured a stress-free work\n",
    "    environment with a healthy work-life balance? Still, also no.\"\"\",\n",
    "\n",
    "    \"\"\"A design process hyperfocused on A/B testing can result in dark patterns even\n",
    "    if that’s not the intent. That’s because most A/B tests are based on metrics\n",
    "    that are relevant to the company’s bottom line, even if they result in harm to users.\"\"\"\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "words = tokenizer.word_index.keys() # get tokenized words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not using a hash function but instead dense factors, we need a dictionary to keep track of the word to vector mapping. But, we can create vectors of any length and get very little chance of collision. For example, even with a single floating-point number between 0 and 1, with our 96 words in the vocabulary, there's almost no chance of collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashwords(words, dimensionality = 4):\n",
    "    return {w:np.random.random(size=dimensionality) for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', array([0.21878612, 0.49951186, 0.24633657, 0.81154734])),\n",
       " ('to', array([0.27422558, 0.0334855 , 0.2614062 , 0.75577529])),\n",
       " ('do', array([0.4351233 , 0.39484151, 0.45951211, 0.60866169])),\n",
       " ('the', array([0.79776878, 0.38560538, 0.07386959, 0.68120947])),\n",
       " ('with', array([0.81159709, 0.71763206, 0.87479089, 0.10563322])),\n",
       " ('on', array([0.89453229, 0.12182721, 0.79217392, 0.90376565])),\n",
       " ('i', array([0.9753419 , 0.39322187, 0.63026127, 0.71034304])),\n",
       " ('really', array([0.4453442 , 0.24629894, 0.78251748, 0.24459754])),\n",
       " ('but', array([0.3315644 , 0.95520421, 0.95982411, 0.32887414])),\n",
       " ('in', array([0.0857075 , 0.05425982, 0.93413581, 0.33890915]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = hashwords(words, dimensionality=4)\n",
    "list(index.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 collisions between dense word vectors\n"
     ]
    }
   ],
   "source": [
    "ncollisions = len(index) - len(set([tuple(a) for a in index.values()]))\n",
    "print(f\"There were {ncollisions} collisions between dense word vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we only use dimensionality=1, then we are right back to label encoding, just with a floating-point number instead of an integer. We need at least a dimensionality of two.\n",
    "\n",
    "What happens if we need to send an entire document not just a single word into a model? We need a continuous bag of words (CBOW), which is easy for one hot encoding.  We just turn on all relevant word-columns. For dense vectors, we either need to concatenate them together or sum or average them into a single vector. If documents are different length, then concatenating them doesn't work because models typically require fixed length input.\n",
    "\n",
    "Those vectors are dense but there is literally no meaning to the values in the vector positions. Two similar words are in no way similar in some kind of semantic space. We are not helping the model very much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>2174</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>414</td>\n",
       "      <td>60072</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>599</td>\n",
       "      <td>46970</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>608</td>\n",
       "      <td>2375</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>783</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0     182     2174     3.5\n",
       "1     414    60072     2.5\n",
       "2     599    46970     2.5\n",
       "3     608     2375     2.5\n",
       "4      68      783     2.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "\n",
    "def load(n = 10):\n",
    "    df_ratings = pd.read_csv('data/ml-latest-small/ratings.csv')\n",
    "    df_ratings = df_ratings.drop('timestamp', axis=1)\n",
    "    df_ratings = df_ratings.sample(n=n).reset_index(drop=True)\n",
    "    return df_ratings\n",
    "\n",
    "df_ratings = load(n=10_000)\n",
    "df_ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2174, 60072, 46970,  2375,   783])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings['movieId'].head(5).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing arbitrarily large IDs to 1..n indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than deal with arbitrarily large integers representing the various IDs, let's compress that down to unique but adjacent integers. This is also how I would handle string to integer encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "catencoders = {} # convert real movie, user ID to compressed index value\n",
    "index_to_id = {} \n",
    "def compress_cats(df, colname):\n",
    "    df[colname] = df[colname].astype('category').cat.as_ordered()\n",
    "    catencoders[colname] = df[colname].cat.categories\n",
    "    index_to_id[colname] = df[colname].cat.categories.values\n",
    "    df[colname] = df[colname].cat.codes + 1 # encode 1..n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That function compresses one column at a time and modifies the data frame in place. Compare the movie IDs with the values above. We have converted `[3696,  281,  592, 1293, 4446]` to `[4, 1, 2, 3, 5]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>414</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>599</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>608</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0     182        2     3.5\n",
       "1     414        5     2.5\n",
       "2     599        4     2.5\n",
       "3     608        3     2.5\n",
       "4      68        1     2.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiny = df_ratings.head(5).copy()\n",
    "compress_cats(df_tiny, \"movieId\")\n",
    "df_tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also gotten a mapping from ID to the tiny index that we can use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([783, 2174, 2375, 46970, 60072], dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catencoders['movieId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later when we want to convert movie IDs to indexes, we can reuse the catencoders, but remember that pandas will display the values using the category \"ID names\" not the code unless we convert it to the \"code\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>414</td>\n",
       "      <td>5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>599</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>608</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0     182        2     3.5\n",
       "1     414        5     2.5\n",
       "2     599        4     2.5\n",
       "3     608        3     2.5\n",
       "4      68        1     2.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiny = df_ratings.head(5).copy()\n",
    "df_tiny['movieId'] = pd.Categorical(df_tiny['movieId'], categories=catencoders['movieId'], ordered=True)\n",
    "df_tiny['movieId'] = df_tiny['movieId'].cat.codes+1\n",
    "df_tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map movie to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try mapping users to movies with a neural network. Presumably people self filter the movies they watch and so there could be information that will tell us about users and/or movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import models, layers, callbacks, optimizers\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 598, 3663)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_cats(df_ratings, \"userId\")\n",
    "compress_cats(df_ratings, \"movieId\")\n",
    "nusers = len(df_ratings.groupby('userId').count())\n",
    "nmovies = len(df_ratings.groupby('movieId').count())\n",
    "n = len(df_ratings)\n",
    "n, nusers, nmovies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the neural network will be one hot encoded movie identifiers. The output will also be one hot encoded user IDs, but keras will handle that part for us (we can leave y as a list of integer user IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3663), (10000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(df_ratings['movieId'])\n",
    "y = df_ratings['userId'] #pd.get_dummies(df_ratings['userId'])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>3654</th>\n",
       "      <th>3655</th>\n",
       "      <th>3656</th>\n",
       "      <th>3657</th>\n",
       "      <th>3658</th>\n",
       "      <th>3659</th>\n",
       "      <th>3660</th>\n",
       "      <th>3661</th>\n",
       "      <th>3662</th>\n",
       "      <th>3663</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3663 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1     2     3     4     5     6     7     8     9     10    ...  3654  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   3655  3656  3657  3658  3659  3660  3661  3662  3663  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[3 rows x 3663 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178, 406, 587, 596,  66,  87, 156, 261, 269, 206], dtype=int16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.values[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to map a sparse movie ID vector to a dense vector of say 20 dimensions. To do that, we use the first layer of a network that has 20 neurons. Each neuron will contribute a single dimension to each dense vector. The input X has 10,000 rows, one for each one hot movie ID. It has nmovies columns. If there are 10 movies, there are 10 possible positions in the one hot encoding. The first layer is a transformation from nmovies space to 20 space. The key is that we want to choke that first layer into just a few neurons and then have a big layer afterwards that tries to make sense of those new compressed features. We don't care about the prediction at the end, we are just going to take the weights out of the first layer to get the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = 20\n",
    "layer2 = 200\n",
    "batch_size = 50 # We want this small apparently (i've read and bigger values get crappy predictions)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(layer1, name='embedding', input_dim=nmovies, activation='relu')) # input_shape=(n,nmovies)\n",
    "model.add(layers.Dense(layer2, activation='relu'))\n",
    "model.add(layers.Dense(nusers+1, activation='softmax'))\n",
    "\n",
    "opt = optimizers.RMSprop()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad4ee621868492cb6fb3791b7da3948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=50.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keras validation accuracy 0.3493\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X, y,\n",
    "                    shuffle=True,\n",
    "                    epochs=50,\n",
    "#                    validation_split=0.10, # don't care\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)]\n",
    "                    )\n",
    "\n",
    "y_pred = model.predict(X.values.reshape(-1,nmovies))\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "val_accur = accuracy_score(y, y_pred)\n",
    "print(\"Keras validation accuracy\", val_accur)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "accur = history.history['accuracy']\n",
    "plt.plot(accur, label='train_accuracy')\n",
    "# val_accur = history.history['val_accuracy']\n",
    "# plt.plot(val_accur, label='valid_accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation error is terrible, but [Oliver](http://www.zeigermann.eu/) says we care about training error for getting embeddings since we won't be using the predictions.  In his example, he only has about 10% accuracy so I'm going to consider roughly 30% quite good. :)\n",
    "\n",
    "[Here](https://djcordhose.github.io/ml-workshop/2019-embeddings.html#/17), Oliver explains how to get the embeddings out. These are the outputs from the first constrained layer. I'm going to simply ask for the weights and the biases then manually get the embedding vectors, rather than create a model just to get the output transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3663, 20), (20,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = model.get_layer('embedding')\n",
    "w, b = embedding_layer.get_weights()\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the weight matrix is the transpose of what I would expect. For example, I like the convention of a row being the weights of a single neuron. Since I have 20 neurons, I would expect 20 rows, but still we can just reverse the operands of the dot product. The following should give us the output of the embedding layer:  take the dot product of every input movie one-hot and multiply times the weight vector then add the bias. Note: The dot product is really just selecting the ith row of w for one-hot turned on at position i.  A row in w is the set of weights across neurons for a particular feature, a (compressed) movie ID in our case. That gives us a vector in 20-space where each dimension is some semantic meaning we got from a neuron.\n",
    "\n",
    "There are repeated movies in the data set so let's get the unique movie IDs and get a mapping from compressed movie ID to dense 20-vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3663, 3663)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_movieIds = np.unique(df_ratings['movieId'])\n",
    "uniq_movieIds_onehot = pd.get_dummies(uniq_movieIds)\n",
    "uniq_movieIds_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each of 3663 we have a vector of size 20\n",
      "Example embedding: [0.3870209, -0.0065929145, 0.38117373, 0.20392317, 0.17074598, 0.01242359, -0.0067837685, 0.020016886, 0.018581286, -0.0054105073, 0.26380157, 0.10988442, -0.0071697235, 0.042017836, -0.0028987303, -0.01655864, 0.12423833, -0.013441332, -0.014091723, -0.0015578866]\n"
     ]
    }
   ],
   "source": [
    "movie_embeddings = np.dot(uniq_movieIds_onehot, w) + b\n",
    "print(f\"For each of {movie_embeddings.shape[0]} we have a vector of size {movie_embeddings.shape[1]}\")\n",
    "print(f\"Example embedding: {list(movie_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the movie embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('data/ml-latest-small/movies.csv')\n",
    "df_movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['movieId'] = pd.Categorical(df_movies['movieId'], categories=catencoders['movieId'], ordered=True)\n",
    "df_movies['movieId'] = df_movies['movieId'].cat.codes+1\n",
    "df_movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.merge(df_movies, on='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie+user -> rating???\n",
    "\n",
    "Ok, Let's try to map both the movie and the user to a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = load(n=10000)\n",
    "compress_cats(df_ratings, \"userId\")\n",
    "compress_cats(df_ratings, \"movieId\")\n",
    "nusers = len(df_ratings.groupby('userId').count())\n",
    "nmovies = len(df_ratings.groupby('movieId').count())\n",
    "n = len(df_ratings)\n",
    "n, nusers, nmovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([pd.get_dummies(df_ratings['movieId']),\n",
    "               pd.get_dummies(df_ratings['userId'])], axis=1)\n",
    "y = df_ratings['rating'] #pd.get_dummies(df_ratings['userId'])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = 10\n",
    "layer2 = 100\n",
    "batch_size = 10\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(layer1, input_dim=nmovies+nusers, activation='relu',\n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.00001))) # input_shape=(n,nmovies)\n",
    "\n",
    "model.add(layers.Dense(layer2, activation='relu',\n",
    "                       kernel_regularizer=tf.keras.regularizers.l2(0.00001)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "#model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "opt = optimizers.RMSprop()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=opt,\n",
    "              metrics=['mae'])\n",
    "#model.summary()\n",
    "\n",
    "history = model.fit(X, y,\n",
    "                    shuffle=True,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.15,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)]\n",
    "                    )\n",
    "\n",
    "plt.ylabel(\"Rating (0..5.0) MAE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "accur = history.history['mae']\n",
    "plt.plot(accur, label='train_mae')\n",
    "val_accur = history.history['val_mae']\n",
    "plt.plot(val_accur, label='val_mae')\n",
    "# plt.xlim(0, 200)\n",
    "plt.ylim(0.4, 1.00)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
