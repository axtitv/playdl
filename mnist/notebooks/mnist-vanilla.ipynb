{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST subset with vanilla network\n",
    "\n",
    "For DL, I get about what a RF (500 trees) gets with 8k training / 2k validation subsample of 60k images.\n",
    "\n",
    "**colab** github can't seem to display notebooks so...\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/parrt/playdl/blob/master/mnist/notebooks/mnist-vanilla.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Make sure to enable this to see progress bars:\n",
    "\n",
    "```\n",
    "$ jupyter nbextension enable --py widgetsnbextension\n",
    "$ jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --no-deps tensorflow-addons~=0.7\n",
    "!pip install -q \"tqdm>=4.36.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put back together so we can take our own subset\n",
    "X = np.concatenate([X_train, X_test], axis=0)\n",
    "y = np.concatenate([y_train, y_test], axis=0)\n",
    "n, w, h = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure to shuffle\n",
    "\n",
    "Shuffle before getting subsample or else we get mostly 0s,1s,2s etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 10_000\n",
    "idx = np.random.randint(0,n,size=subset)\n",
    "X = X[idx,:,:]\n",
    "y = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8000 images\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "n, w, h = X_train.shape\n",
    "\n",
    "print(f\"Using {n} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, \\\n",
    "    accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500,\n",
    "                            min_samples_leaf=1,\n",
    "                            oob_score=True, n_jobs=-1)\n",
    "rf.fit(X_train.reshape(-1,w*h), y_train)\n",
    "print(\"OOB\", rf.oob_score_)\n",
    "\n",
    "y_pred = rf.predict(X_test.reshape(-1, w*h))\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)\n",
    "print(\"test accuracy\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion is that a RF with only 500 trees does a quick easy job on this 8k image subsample. Does about what DL does with vanilla net. About 95% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla two-layers of 512 neurons, softmax on end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import models, layers, callbacks, optimizers\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget to normalize data for DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "layer1 = 512\n",
    "layer2 = 512\n",
    "batch_size = 2000\n",
    "dropout = 0.2\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(layer1, input_dim=w*h, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Dense(layer2, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(dropout))\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# learning_rate = 0.15\n",
    "# opt = optimizers.Adam(lr=learning_rate)\n",
    "opt = optimizers.RMSprop() # this one seems a bit better\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# callback = callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(X_train.reshape(n,w*h), y_train,\n",
    "                    shuffle=True,\n",
    "                    epochs=200,\n",
    "                    validation_data=(X_test.reshape(-1,w*h), y_test),\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    callbacks=[tfa.callbacks.TQDMProgressBar(show_epoch_progress=False)]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test.reshape(-1,w*h))\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "val_accur = accuracy_score(y_test, y_pred)\n",
    "print(\"Keras validation accuracy\", val_accur)\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "accur = history.history['accuracy']\n",
    "plt.plot(accur, label='train_accuracy')\n",
    "val_accur = history.history['val_accuracy']\n",
    "plt.plot(val_accur, label='valid_accuracy')\n",
    "plt.title(f\"batch_size {batch_size}, Layers {layer1,layer2}\\ntrain {accur[-1]:.3f}, valid {val_accur[-1]:.3f}, dropout {dropout:.2f}\")\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0.5, 1.02)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of data set size\n",
    "\n",
    "With 1k not 8k records, RF and DL also seemed about the same with DL again a little ahead of RF, though slower and requiring more expertise to train.  Accur dropped from .95ish to .90ish for RF, but DL dropped to .85 (w/o changing architecture or tuning). Regardless, more training data helped both. As expected DL wants more data.  With only 100 images, RF drops to .6, but DL drops only to .7. Hmm...\n",
    "\n",
    "Jumping to 16k records, RF is .97 and DL is almost .98."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (playdl)",
   "language": "python",
   "name": "pycharm-e2d464a9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
