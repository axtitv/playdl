{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Encoder-decoder \n",
    "\n",
    "use fastai human numbers data to train. First a classifier then do decoder.\n",
    "\n",
    "The data is from [fastai book chap 12](https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb). Looks like:\n",
    "\n",
    "```\n",
    "one \n",
    "two \n",
    "three \n",
    "...\n",
    "two hundred seven \n",
    "two hundred eight \n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/parrt/.fastai/data/human_numbers')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai2.text.all import *\n",
    "path = untar_data(URLs.HUMAN_NUMBERS)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename:str):\n",
    "    \"\"\"\n",
    "    Load and return the text of a text file, assuming latin-1 encoding as that\n",
    "    is what the BBC corpus uses.  Use codecs.open() function not open().\n",
    "    \"\"\"\n",
    "    f = codecs.open(filename, encoding='latin-1', mode='r')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    expy = torch.exp(y)\n",
    "    if len(y.shape)==1: # 1D case can't use axis arg\n",
    "        return expy / torch.sum(expy)\n",
    "    return expy / torch.sum(expy, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one \n",
      "two \n",
      "three \n",
      "four \n",
      "five \n",
      "['one ', 'two ', 'three ', 'four ', 'five ']\n"
     ]
    }
   ],
   "source": [
    "text = get_text(path/'train.txt').strip()\n",
    "print(text[:28])\n",
    "lines = text.lower().split('\\n')\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique vocab but don't sort; keep order so 'one'=1 etc...\n",
    "# use '#' to indicate padded (unused) char for embedding purposes\n",
    "v = set('#')\n",
    "X_vocab = ['#']\n",
    "for t in text.split():\n",
    "    if t not in v:\n",
    "        X_vocab.append(t)\n",
    "        v.add(t)\n",
    "X_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nineteen'],\n",
       " ['twenty'],\n",
       " ['twenty', 'one'],\n",
       " ['twenty', 'two'],\n",
       " ['twenty', 'three']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens = [line.strip().split(' ') for line in lines]\n",
    "X_tokens[18:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtoi = {w:i for i,w in enumerate(X_vocab)}\n",
    "wtoi['#'], wtoi['one'], wtoi['two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7999, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  1],\n",
       "        [ 0,  0,  0,  0,  0,  2],\n",
       "        [ 0,  0,  0,  0,  0,  3],\n",
       "        ...,\n",
       "        [ 7, 29,  9, 28, 27,  7],\n",
       "        [ 7, 29,  9, 28, 27,  8],\n",
       "        [ 7, 29,  9, 28, 27,  9]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = get_max_len(X_tokens)\n",
    "X = torch.zeros(len(X_tokens),max_len, device=device, dtype=torch.long) # zero implies padding\n",
    "print(X.shape)\n",
    "for i in range(len(X_tokens)):\n",
    "    x = X_tokens[i]\n",
    "    pad = max_len - len(x)\n",
    "    for j in range(len(x)):\n",
    "        X[i,j+pad] = wtoi[X_tokens[i][j]]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "\n",
    "### Create y target class vector\n",
    "\n",
    "y  is just 1..len(X_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   1,    2,    3,  ..., 7997, 7998, 7999], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(range(1,len(X_tokens)+1), device=device)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['one'], ['seven', 'thousand', 'nine', 'hundred', 'ninety', 'nine'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens[0], X_tokens[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = int(len(X)*.80)\n",
    "X_train, y_train = X[:ntrain], y[:ntrain]\n",
    "X_valid, y_valid = X[ntrain:], y[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,368 training records, batch size 32, 30 features (words), 7999 target classes, state is 128-vector\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "\n",
    "nhidden = 128\n",
    "batch_size = 32\n",
    "embed_sz = 10\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "nfeatures = len(X_vocab)\n",
    "nclasses = len(X_tokens) # they are unique targets\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (words), {nclasses} target classes, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(batch_X, max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    H = torch.zeros(nhidden, len(batch_X), device=device, dtype=torch.float64, requires_grad=False)\n",
    "    for t in range(max_len):\n",
    "        x_step_t = batch_X[:,t]\n",
    "        # column E[i] is the embedding for char index i. same as multiple E.mm(onehot(i))\n",
    "        embedding_step_t = E[:,x_step_t]\n",
    "        H = W.mm(H) + U.mm(embedding_step_t) + Bx\n",
    "        H = torch.tanh(H)        \n",
    "    o = V.mm(H) + Bo\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 training loss 28.8584 accur  0.0000   LR 0.002000\n",
      "Epoch   2 training loss 20.9657 accur  0.0003   LR 0.003000\n",
      "Epoch   3 training loss 15.8727 accur  0.0008   LR 0.004000\n",
      "Epoch   4 training loss 12.6007 accur  0.0014   LR 0.005000\n",
      "Epoch   5 training loss 10.6671 accur  0.0035   LR 0.004000\n",
      "Epoch   6 training loss  8.7913 accur  0.0099   LR 0.003000\n",
      "Epoch   7 training loss  7.3708 accur  0.0221   LR 0.002000\n",
      "Epoch   8 training loss  6.1835 accur  0.0397   LR 0.001000\n",
      "Epoch   9 training loss  5.1651 accur  0.0795   LR 0.001500\n",
      "Epoch  10 training loss  4.9712 accur  0.0832   LR 0.002000\n",
      "Epoch  11 training loss  4.9820 accur  0.0894   LR 0.002500\n",
      "Epoch  12 training loss  4.9760 accur  0.1021   LR 0.003000\n",
      "Epoch  13 training loss  4.9150 accur  0.1162   LR 0.002500\n",
      "Epoch  14 training loss  4.5396 accur  0.1519   LR 0.002000\n",
      "Epoch  15 training loss  4.1746 accur  0.1774   LR 0.001500\n",
      "Epoch  16 training loss  3.7810 accur  0.2057   LR 0.001000\n",
      "Epoch  17 training loss  3.4035 accur  0.2439   LR 0.001250\n",
      "Epoch  18 training loss  3.0151 accur  0.3068   LR 0.001500\n",
      "Epoch  19 training loss  2.7984 accur  0.3573   LR 0.001750\n",
      "Epoch  20 training loss  2.6295 accur  0.3951   LR 0.002000\n",
      "Epoch  21 training loss  2.4628 accur  0.4273   LR 0.001750\n",
      "Epoch  22 training loss  2.2286 accur  0.4790   LR 0.001500\n",
      "Epoch  23 training loss  2.0385 accur  0.5088   LR 0.001250\n",
      "Epoch  24 training loss  1.9097 accur  0.5289   LR 0.001000\n",
      "Epoch  25 training loss  1.7684 accur  0.5587   LR 0.001125\n",
      "Epoch  26 training loss  1.5822 accur  0.6126   LR 0.001250\n",
      "Epoch  27 training loss  1.4111 accur  0.6606   LR 0.001375\n",
      "Epoch  28 training loss  1.2721 accur  0.6980   LR 0.001500\n",
      "Epoch  29 training loss  1.1423 accur  0.7345   LR 0.001375\n",
      "Epoch  30 training loss  1.0180 accur  0.7679   LR 0.001250\n",
      "Epoch  31 training loss  0.9214 accur  0.7955   LR 0.001125\n",
      "Epoch  32 training loss  0.8361 accur  0.8210   LR 0.001000\n",
      "Epoch  33 training loss  0.7608 accur  0.8420   LR 0.001063\n",
      "Epoch  34 training loss  0.6672 accur  0.8673   LR 0.001125\n",
      "Epoch  35 training loss  0.5942 accur  0.8899   LR 0.001187\n",
      "Epoch  36 training loss  0.5153 accur  0.9081   LR 0.001250\n",
      "Epoch  37 training loss  0.4469 accur  0.9271   LR 0.001187\n",
      "Epoch  38 training loss  0.3878 accur  0.9433   LR 0.001125\n",
      "Epoch  39 training loss  0.3422 accur  0.9545   LR 0.001063\n",
      "Epoch  40 training loss  0.3003 accur  0.9618   LR 0.001000\n",
      "Epoch  41 training loss  0.2587 accur  0.9733   LR 0.001031\n",
      "Epoch  42 training loss  0.2258 accur  0.9782   LR 0.001063\n",
      "Epoch  43 training loss  0.1927 accur  0.9852   LR 0.001094\n",
      "Epoch  44 training loss  0.1633 accur  0.9893   LR 0.001125\n",
      "Epoch  45 training loss  0.1366 accur  0.9940   LR 0.001094\n",
      "Epoch  46 training loss  0.1075 accur  0.9959   LR 0.001063\n",
      "Epoch  47 training loss  0.0855 accur  0.9980   LR 0.001031\n",
      "Epoch  48 training loss  0.0688 accur  0.9987   LR 0.001000\n",
      "Epoch  49 training loss  0.0569 accur  0.9995   LR 0.001016\n",
      "Epoch  50 training loss  0.0488 accur  0.9997   LR 0.001031\n",
      "Epoch  51 training loss  0.0422 accur  0.9997   LR 0.001047\n",
      "Epoch  52 training loss  0.0373 accur  1.0000   LR 0.001063\n",
      "Epoch  53 training loss  0.0333 accur  1.0000   LR 0.001047\n",
      "Epoch  54 training loss  0.0298 accur  1.0000   LR 0.001031\n",
      "Epoch  55 training loss  0.0267 accur  1.0000   LR 0.001016\n"
     ]
    }
   ],
   "source": [
    "#%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "E = torch.randn(embed_sz,      len(X_vocab),  device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "W = torch.eye(nhidden,         nhidden,       device=device, dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,       embed_sz,      device=device, dtype=torch.float64, requires_grad=True) # input converter\n",
    "Bx = torch.zeros(nhidden,      batch_size,    device=device, dtype=torch.float64, requires_grad=True)\n",
    "Bo = torch.zeros(nclasses,     batch_size,    device=device, dtype=torch.float64, requires_grad=True)\n",
    "V = torch.randn(nclasses,      nhidden,       device=device, dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "with torch.no_grad():\n",
    "    E[:,0] = 0.0  # padding word gives 0 vector\n",
    "\n",
    "optimizer = torch.optim.Adam([E,W,U,V,Bx,Bo], lr=0.005, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                              mode='triangular2',\n",
    "                                              step_size_up=4,\n",
    "                                              base_lr=0.001, max_lr=0.005,\n",
    "                                              cycle_momentum=False)\n",
    "\n",
    "history = []\n",
    "epochs = 70 # gets to 100% at 70 with lr=0.001\n",
    "epochs = 55 # gets to 100% at 50 with cyclic base_lr=0.001, max_lr=0.005 every 4\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        o = forward(batch_X, max_len, X_vocab)\n",
    "        correct = torch.argmax(softmax(o), dim=1)==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "\n",
    "        loss = F.cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "    print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}   LR {scheduler.get_last_lr()[0]:7.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define y sequence of digits\n",
    "\n",
    "So `'one' -> '1'`, `['twenty', 'three'] -> ['2','3']`, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_vocab = {d:i for i,d in enumerate(\"0123456789\")}\n",
    "Y_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for i in range(0,len(X)):\n",
    "    Y.append([int(d) for d in str(i+1)])\n",
    "Y[:12]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
