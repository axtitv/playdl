{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Encoder-decoder non-vectorized\n",
    "\n",
    "Use [fastai book chap 12](https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb) human numbers data to train translator from english like \"two hundred seven\" to sequence of digits like \"207\". Data looks like:\n",
    "\n",
    "```\n",
    "one \n",
    "two \n",
    "three \n",
    "...\n",
    "two hundred seven \n",
    "two hundred eight \n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/parrt/.fastai/data/human_numbers')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai2.text.all import *\n",
    "path = untar_data(URLs.HUMAN_NUMBERS)\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename:str):\n",
    "    \"\"\"\n",
    "    Load and return the text of a text file, assuming latin-1 encoding as that\n",
    "    is what the BBC corpus uses.  Use codecs.open() function not open().\n",
    "    \"\"\"\n",
    "    f = codecs.open(filename, encoding='latin-1', mode='r')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    expy = torch.exp(y)\n",
    "    if len(y.shape)==1: # 1D case can't use axis arg\n",
    "        return expy / torch.sum(expy)\n",
    "    return expy / torch.sum(expy, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one \n",
      "two \n",
      "three \n",
      "four \n",
      "five \n",
      "['one ', 'two ', 'three ', 'four ', 'five ']\n"
     ]
    }
   ],
   "source": [
    "text = get_text(path/'train.txt').strip()\n",
    "print(text[:28])\n",
    "lines = text.lower().split('\\n')\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[0:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique vocab but don't sort; keep order so 'one'=1 etc...\n",
    "# use '#' to indicate padded (unused) char for embedding purposes\n",
    "v = set('#')\n",
    "X_vocab = ['#']\n",
    "for t in text.split():\n",
    "    if t not in v:\n",
    "        X_vocab.append(t)\n",
    "        v.add(t)\n",
    "X_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nineteen'],\n",
       " ['twenty'],\n",
       " ['twenty', 'one'],\n",
       " ['twenty', 'two'],\n",
       " ['twenty', 'three']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens = [line.strip().split(' ') for line in lines]\n",
    "X_tokens[18:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11, 'one', 'eleven')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(X_tokens)\n",
    "X_vocab = {w:i for i,w in enumerate(X_vocab)}\n",
    "X_idx = {i:w for i,w in enumerate(X_vocab)}\n",
    "X_vocab['one'], X_vocab['eleven'], X_idx[1], X_idx[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[16],\n",
       " [17],\n",
       " [18],\n",
       " [19],\n",
       " [20],\n",
       " [20, 1],\n",
       " [20, 2],\n",
       " [20, 3],\n",
       " [20, 4],\n",
       " [20, 5],\n",
       " [20, 6],\n",
       " [20, 7],\n",
       " [20, 8],\n",
       " [20, 9],\n",
       " [21]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numericalize but don't pad\n",
    "X = []\n",
    "for i in range(len(X_tokens)):\n",
    "    x = X_tokens[i]\n",
    "    X.append( [X_vocab[w] for w in x] )\n",
    "X[15:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define y sequence of digits\n",
    "\n",
    "Let's use Y as list of lists like X; targets like `'one' -> '1'`, `['twenty', 'three'] -> ['2','3']`, etc...\n",
    "\n",
    "Use '<' for start of sequence and '>' for end. So sequence `ab` is stored `<ab>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " '<': 10,\n",
       " '>': 11}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_vocab = {d:i for i,d in enumerate(\"0123456789<>\")}\n",
    "Y_idx = {i:w for i,w in enumerate(\"0123456789<>\")}\n",
    "Y_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<1>', '<2>', '<3>', '<4>', '<5>', '<6>', '<7>', '<8>', '<9>', '<10>', '<11>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ystr = [f\"<{i+1}>\" for i in range(0,len(X))]\n",
    "Y_max_len = get_max_len(Ystr)\n",
    "Ystr[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 2, 0, 11],\n",
       " [10, 2, 1, 11],\n",
       " [10, 2, 2, 11],\n",
       " [10, 2, 3, 11],\n",
       " [10, 2, 4, 11],\n",
       " [10, 2, 5, 11]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = []\n",
    "for i in range(0,len(X)):\n",
    "    y = Ystr[i]\n",
    "#    pad = Y_max_len - len(y)\n",
    "    Y.append([Y_vocab[d] for d in y])\n",
    "#Y = torch.tensor(Y)\n",
    "Y[19:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 training records, 12 target classes, state is 128-vector\n"
     ]
    }
   ],
   "source": [
    "embed_sz = 20\n",
    "y_embed_sz = 5\n",
    "nhidden = 128\n",
    "nclasses = len(Y_vocab) # char output vocab\n",
    "\n",
    "print(f\"{n:,d} training records, {nclasses} target classes, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out validation set\n",
    "\n",
    "Not sure this will generalize but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, y):\n",
    "    # ENCODER\n",
    "    h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "    for t in range(len(x)):\n",
    "        embedding_step_t = Ex[:,x[t]]\n",
    "        embedding_step_t = embedding_step_t.reshape(embed_sz,1)\n",
    "        h = W @ h + U @ embedding_step_t + bx\n",
    "        h = torch.tanh(h)\n",
    "\n",
    "    # DECODER\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "#     print(\"DECODE\", y)\n",
    "    for t in range(len(y)-1): # don't predict next char at final '>'\n",
    "        embedding_step_t = Ey[:,y[t]]\n",
    "        embedding_step_t = embedding_step_t.reshape(y_embed_sz,1)\n",
    "        h = W2 @ h + U2 @ embedding_step_t + by\n",
    "        h = torch.tanh(h)\n",
    "        o = V @ h + bo\n",
    "        o = o.reshape(1,nclasses)\n",
    "        # From y we want to predict y[1:]. at y[t], predict y[t+1]\n",
    "        loss += F.cross_entropy(o, torch.tensor([y[t+1]], device=device))\n",
    "\n",
    "        p = softmax(o)\n",
    "        correct += torch.argmax(p[0]).item()==y[t+1]\n",
    "#         epoch_training_accur += correct\n",
    "    return loss, int(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 training loss 22.8330 accur  0.2947\n",
      "Epoch   2 training loss  8.1087 accur  0.5325\n",
      "Epoch   3 training loss  4.2575 accur  0.7297\n",
      "Epoch   4 training loss  2.1354 accur  0.8232\n",
      "Epoch   5 training loss  1.5830 accur  0.8821\n",
      "Epoch   6 training loss  0.7892 accur  0.9350\n",
      "Epoch   7 training loss  0.5761 accur  0.9451\n",
      "Epoch   8 training loss  0.3111 accur  0.9736\n",
      "Epoch   9 training loss  0.1759 accur  0.9878\n",
      "Epoch  10 training loss  0.1106 accur  0.9919\n",
      "Epoch  11 training loss  0.0771 accur  0.9980\n",
      "Epoch  12 training loss  0.0363 accur  1.0000\n",
      "Epoch  13 training loss  0.0193 accur  1.0000\n",
      "Epoch  14 training loss  0.0150 accur  1.0000\n",
      "Epoch  15 training loss  0.0132 accur  1.0000\n"
     ]
    }
   ],
   "source": [
    "#%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "Ex = torch.randn(embed_sz,     len(X_vocab),  device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "W = torch.eye(nhidden,         nhidden,       device=device, dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,       embed_sz,      device=device, dtype=torch.float64, requires_grad=True) # input converter\n",
    "bx = torch.zeros(nhidden,      1,             device=device, dtype=torch.float64, requires_grad=True)\n",
    "by = torch.zeros(nhidden,      1,             device=device, dtype=torch.float64, requires_grad=True)\n",
    "bo = torch.zeros(nclasses,     1,             device=device, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "Ey = torch.randn(y_embed_sz,   len(Y_vocab),  device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "W2 = torch.eye(nhidden,        nhidden,       device=device, dtype=torch.float64, requires_grad=True)\n",
    "#C = torch.randn(nhidden,       nhidden,       device=device, dtype=torch.float64, requires_grad=True) # input converter\n",
    "U2 = torch.randn(nhidden,      y_embed_sz,    device=device, dtype=torch.float64, requires_grad=True) # input converter\n",
    "V = torch.randn(nclasses,      nhidden,       device=device, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.Adam([Ex,W,U,Ey,W2,U2,V,bx,by,bo], lr=0.001, weight_decay=0.0)\n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "#                                               mode='triangular2',\n",
    "#                                               step_size_up=4,\n",
    "#                                               base_lr=0.001, max_lr=0.005,\n",
    "#                                               cycle_momentum=False)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "history = []\n",
    "epochs = 15\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total_compares = 0\n",
    "    for i in range(n):\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "        loss, correct = forward(x, y)\n",
    "        epoch_training_accur += correct\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        total_compares += len(y) - 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "#     scheduler.step()\n",
    "    epoch_training_loss /= n\n",
    "    epoch_training_accur /= total_compares\n",
    "    print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")#   LR {scheduler.get_last_lr()[0]:7.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x):\n",
    "    n = len(x)\n",
    "    output = []\n",
    "    with torch.no_grad():\n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(len(x)):\n",
    "            embedding_step_t = Ex[:,x[t]]\n",
    "            embedding_step_t = embedding_step_t.reshape(embed_sz,1)\n",
    "            h = W @ h + U @ embedding_step_t + bx\n",
    "            h = torch.tanh(h)\n",
    "\n",
    "        # DECODER\n",
    "        y = [Y_vocab['<']] # begin with \"start of sequence\" char\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        while y!=Y_vocab['>']:\n",
    "            embedding_step_t = Ey[:,y]\n",
    "            embedding_step_t = embedding_step_t.reshape(y_embed_sz,1)\n",
    "            h = W2 @ h + U2 @ embedding_step_t + by\n",
    "            h = torch.tanh(h)\n",
    "            o = V @ h + bo\n",
    "            o = o.reshape(1,nclasses)\n",
    "            p = softmax(o[0])\n",
    "            y = torch.argmax(p).item()\n",
    "            if y!=Y_vocab['>']:\n",
    "                output.append(Y_idx[y])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 28, 10] ['one', 'hundred', 'ten']\n"
     ]
    }
   ],
   "source": [
    "x = [X_vocab[w] for w in \"one hundred ten\".split()]\n",
    "print(x, [X_idx[n] for n in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one'] => ['1']\n"
     ]
    }
   ],
   "source": [
    "x = [X_vocab[w] for w in \"one\".split()]\n",
    "output = sample(x)\n",
    "print([X_idx[n] for n in x],'=>', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'hundred'] => ['1', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "x = [X_vocab[w] for w in \"one hundred\".split()]\n",
    "output = sample(x)\n",
    "print([X_idx[n] for n in x],'=>', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'hundred', 'ten'] => ['1', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "x = [X_vocab[w] for w in \"one hundred ten\".split()]\n",
    "output = sample(x)\n",
    "print([X_idx[n] for n in x],'=>', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'hundred', 'thirty', 'two'] => ['1', '3', '2']\n"
     ]
    }
   ],
   "source": [
    "x = [X_vocab[w] for w in \"one hundred thirty two\".split()]\n",
    "output = sample(x)\n",
    "print([X_idx[n] for n in x],'=>', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eleven'] => ['1', '1']\n"
     ]
    }
   ],
   "source": [
    "x = [X_vocab[w] for w in \"eleven\".split()]\n",
    "output = sample(x)\n",
    "print([X_idx[n] for n in x],'=>', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ninety', 'nine'] => ['9', '9']\n"
     ]
    }
   ],
   "source": [
    "x = [X_vocab[w] for w in \"ninety nine\".split()]\n",
    "output = sample(x)\n",
    "print([X_idx[n] for n in x],'=>', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fifty', 'three'] => ['5', '3']\n"
     ]
    }
   ],
   "source": [
    "x = [X_vocab[w] for w in \"fifty three\".split()]\n",
    "output = sample(x)\n",
    "print([X_idx[n] for n in x],'=>', output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
