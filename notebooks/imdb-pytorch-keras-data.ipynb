{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB with pytorch but using keras data\n",
    "\n",
    "I just realized that I was using a mere 2000 records and the keras book and examples were using a much larger 25000 (train and also test) data set. So I'm going to use keras to pull that data and but process it using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size:float):\n",
    "    n = len(X)\n",
    "    shuffle_idx = np.random.permutation(range(n))\n",
    "    X = X[shuffle_idx]\n",
    "    y = y[shuffle_idx]\n",
    "    n_valid = int(n*test_size)\n",
    "    n_train = n - n_valid\n",
    "    X_train, X_valid = X[0:n_train].to(device), X[n_train:].to(device)\n",
    "    y_train, y_valid = y[0:n_train].to(device), y[n_train:].to(device)\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load IMDb from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import imdb\n",
    "from keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = vocab_size = 10_000\n",
    "maxlen = ndocprefix = 20\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).long().to(device)\n",
    "X_test = torch.tensor(X_test).long().to(device)\n",
    "y_train = torch.tensor(y_train).float().reshape(-1,1).to(device)\n",
    "y_test = torch.tensor(y_test).float().reshape(-1,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMBD(TensorDataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__(X, y)\n",
    "        self.X = X # track with easy to use fields\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def train(model, train_data, valid_data,\n",
    "          epochs=350,\n",
    "          test_size=0.20,\n",
    "          learning_rate = 0.002,\n",
    "          batch_size=32,\n",
    "          weight_decay=1.e-4,\n",
    "          loss_fn=nn.BCELoss(),\n",
    "          print_every=30):\n",
    "    history = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for ei in range(epochs): # epochs\n",
    "        for bi, (batch_x, batch_y) in enumerate(train_loader): # mini-batch\n",
    "#             if len(batch_x)!=batch_size:\n",
    "#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\n",
    "            y_prob = model(batch_x)\n",
    "            loss = loss_fn(y_prob, batch_y) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad and M.grad\n",
    "            optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss        = loss_fn(model(train_data.X), train_data.y)\n",
    "            loss_valid  = loss_fn(model(valid_data.X), valid_data.y)\n",
    "            accur_train = accuracy_score(torch.round(model(train_data.X).cpu()), train_data.y.cpu())\n",
    "            accur_valid = accuracy_score(torch.round(model(valid_data.X).cpu()), valid_data.y.cpu())\n",
    "\n",
    "        history.append( (loss, loss_valid) )\n",
    "        if ei % print_every == 0:\n",
    "            print(f\"Epoch {ei:3d} log loss {loss:7.3f}, {loss_valid:7.3f}   accuracy {accur_train:4.3f}, {accur_valid:4.3f}\")        \n",
    "\n",
    "    history = torch.tensor(history)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, nfactors):\n",
    "        super(Sentiment, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, nfactors)\n",
    "        self.final = nn.Linear(ndocprefix*nfactors,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(x.device)       # cuda:0 or cpu\n",
    "#         print(x.shape)      # [1600, 20]\n",
    "        output = self.embedding(x)\n",
    "#         print(output.shape) # [1600, 20, 8] = (samples, num word features, embedding dim)\n",
    "        # must cat the 20 64-vectors together\n",
    "        output = output.view((x.shape[0], -1))\n",
    "#         print(output.shape) # [1600, 160]\n",
    "        output = self.final(output)\n",
    "#         print(output.shape) # [1600, 1]\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 training and 5000 test records\n",
      "Epoch   0 log loss   0.466,   0.535   accuracy 0.777, 0.728\n",
      "Epoch   1 log loss   0.435,   0.531   accuracy 0.796, 0.732\n",
      "Epoch   2 log loss   0.427,   0.528   accuracy 0.804, 0.742\n",
      "Epoch   3 log loss   0.426,   0.528   accuracy 0.804, 0.742\n",
      "Epoch   4 log loss   0.421,   0.527   accuracy 0.807, 0.740\n",
      "Epoch   5 log loss   0.415,   0.524   accuracy 0.811, 0.741\n",
      "Epoch   6 log loss   0.416,   0.525   accuracy 0.812, 0.743\n",
      "Epoch   7 log loss   0.416,   0.527   accuracy 0.811, 0.745\n",
      "Epoch   8 log loss   0.416,   0.528   accuracy 0.812, 0.746\n",
      "Epoch   9 log loss   0.416,   0.527   accuracy 0.810, 0.744\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nfactors = 6\n",
    "model = Sentiment(vocab_size, nfactors).to(device)\n",
    "\n",
    "print(f\"{len(X_train)} training and {len(X_valid)} test records\")\n",
    "model, history = train(model, IMBD(X_train, y_train), IMBD(X_valid, y_valid),\n",
    "                       epochs=10,\n",
    "                       learning_rate=.03,\n",
    "                       weight_decay=0.0001,\n",
    "                       batch_size=32,\n",
    "                       print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew! Ok,Getting the same rough accuracy that those guys do from the book. They said about 76% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more layers and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "layer1 = 64\n",
    "layer2 = 32\n",
    "class SentimentRegularized(nn.Module):\n",
    "    def __init__(self, vocab_size, nfactors):\n",
    "        super(SentimentRegularized, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, nfactors)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(ndocprefix*nfactors,layer1), # 300 neurons\n",
    "#            nn.BatchNorm1d(layer1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=layer1, out_features=layer2),\n",
    "#            nn.BatchNorm1d(layer2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(layer2,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.embedding(x)\n",
    "        output = output.view((x.shape[0], -1))\n",
    "        output = self.layers(output)\n",
    "        return torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 training and 5000 test records\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d01a29c578fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                        \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#0001,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                        print_every=1)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3f298de18854>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, valid_data, epochs, test_size, learning_rate, batch_size, weight_decay, loss_fn, print_every)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#             if len(batch_x)!=batch_size:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-7a58f21f20b0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1603\u001b[0m     \"\"\"\n\u001b[1;32m   1604\u001b[0m     \u001b[0mtens_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nfactors = 8\n",
    "model = SentimentRegularized(vocab_size, nfactors).to(device)\n",
    "\n",
    "print(f\"{len(X_train)} training and {len(X_valid)} test records\")\n",
    "model, history = train(model, IMBD(X_train, y_train), IMBD(X_valid, y_valid),\n",
    "                       epochs=15,\n",
    "                       learning_rate=.01,\n",
    "                       weight_decay=0.0,#0001,\n",
    "                       batch_size=16,\n",
    "                       print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
