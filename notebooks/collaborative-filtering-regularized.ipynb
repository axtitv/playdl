{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized collaborative filtering with pytorch\n",
    "\n",
    "Start again with a momentum base to gradient descent that uses a randomly selected validation set each iteration to measure validation error. Add L2 regularization to the process. Start without bias vector first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "def RF_valid(df, movie_embeddings, user_embeddings):\n",
    "    X = df[['movieId','userId']]\n",
    "    y = df['rating']\n",
    "    X_emb = np.concatenate([movie_embeddings[X['movieId']],user_embeddings[X['userId']]], axis=1)\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True)\n",
    "    rf.fit(X_emb, y)\n",
    "    print(f\"OOB R^2 {rf.oob_score_:.3f}\")\n",
    "    print(f\"Train R^2 {rf.score(X_emb, y):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def load(n = 10):\n",
    "    df_ratings = pd.read_csv('data/ml-latest-small/ratings.csv')\n",
    "    df_ratings = df_ratings.drop('timestamp', axis=1)\n",
    "    df_ratings = df_ratings.sample(n=n).reset_index(drop=True)\n",
    "    # Merge in the title and genres\n",
    "    df_movies = pd.read_csv('data/ml-latest-small/movies.csv')\n",
    "    df = df_ratings.merge(df_movies, on='movieId')\n",
    "    # Strip the \"(1999)\" dates from the titles\n",
    "    p = re.compile(r'[()0-9]+$')\n",
    "    df['title'] = df['title'].map(lambda x: p.sub('', x).strip())\n",
    "    return df\n",
    "\n",
    "def compress_cats(df, colname):\n",
    "    df[colname] = df[colname].astype('category').cat.as_ordered()\n",
    "    df[colname] = df[colname].cat.codes # encode 0..n-1  NB: Different than I usually do (1..n)!!!!\n",
    "    df[colname] = df[colname].astype(int)\n",
    "    \n",
    "def normal_transform(x, mean=0.0, std=0.01):\n",
    "    \"Convert x to have mean and std\"\n",
    "    return x*std + mean\n",
    "\n",
    "def randn(n1, n2, device, dtype, mean=0.0, std=0.01, requires_grad=False):\n",
    "    x = torch.randn(n1, n2, device=device, dtype=dtype)\n",
    "    x = normal_transform(x, mean=mean, std=std)\n",
    "    x.requires_grad=requires_grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>474</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Phenomenon</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>474</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Phenomenon</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating       title         genres\n",
       "0     302      474     4.0  Phenomenon  Drama|Romance\n",
       "1      83      474     4.0  Phenomenon  Drama|Romance"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load(n=20_000)\n",
    "n = len(df)\n",
    "nmovies = len(df.groupby('movieId').count())\n",
    "nusers = len(df.groupby('userId').count())\n",
    "compress_cats(df, 'movieId') # make IDs 0..nmovies-1\n",
    "compress_cats(df, 'userId')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and track validation error\n",
    "\n",
    "By randomly selecting validation and training sets at each iteration (epoch), we are moving to stochastic gradient descent (SGD). Previously I only used gradient descent. The best I have seen is 0.7ish OOB R^2 before SGD.  Adding the `mean=math.sqrt(2.5/nfactors)` seems to have consistently produced about 0.05 R^2 improvement for this SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 MSE training 2.367 valid 2.369\n",
      "Epoch  40 MSE training 0.732 valid 0.706\n",
      "Epoch  80 MSE training 0.237 valid 0.230\n",
      "Epoch 120 MSE training 0.206 valid 0.210\n",
      "Epoch 160 MSE training 0.197 valid 0.181\n",
      "Epoch 200 MSE training 0.190 valid 0.183\n"
     ]
    }
   ],
   "source": [
    "nfactors = 4\n",
    "n_train = int(n*0.85)\n",
    "n_valid = n - n_train\n",
    "U = randn(nusers,  nfactors, device=device, dtype=dtype, requires_grad=True, mean=math.sqrt(2.5/nfactors))\n",
    "M = randn(nmovies, nfactors, device=device, dtype=dtype, requires_grad=True, mean=math.sqrt(2.5/nfactors))\n",
    "\n",
    "data = torch.tensor( df[['userId','movieId','rating']].values )\n",
    "\n",
    "def mse_loss(U, M, data):\n",
    "    # data has (user, movie, rating) records\n",
    "    r_pred = (U[data[:,0].long()] * M[data[:,1].long()]).sum(axis=1)\n",
    "    r_pred = torch.sigmoid(r_pred) * 5  # limit to 0..5\n",
    "    diff = r_pred - torch.tensor(data[:,2])\n",
    "    return torch.mean( diff.pow(2) )\n",
    "\n",
    "learning_rate = 200\n",
    "momentum = 0.01\n",
    "for t in range(500):\n",
    "    indices = torch.randperm(n)\n",
    "    train_idx = indices[0:n_train]\n",
    "    valid_idx = indices[n_train:]\n",
    "    train, valid = data[train_idx], data[valid_idx] # copying data but could not get columns out of a Subset object\n",
    "    loss = mse_loss(U, M, train)\n",
    "    with torch.no_grad():\n",
    "        valid_loss = mse_loss(U, M, valid)\n",
    "\n",
    "    if t % 40 == 0:\n",
    "        print(f\"Epoch {t:3d} MSE training {loss:4.3f} valid {valid_loss:4.3f}\")\n",
    "\n",
    "    loss.backward() # autograd computes U.grad and M.grad\n",
    "\n",
    "    # Update weights; weights have requires_grad=True but we don't need to track these updates\n",
    "    with torch.no_grad():\n",
    "        U -= (momentum*U + learning_rate * U.grad)\n",
    "        M -= (momentum*M + learning_rate * M.grad)\n",
    "        U.grad.zero_() # reset gradients\n",
    "        M.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB R^2 0.704\n",
      "Train R^2 0.959\n"
     ]
    }
   ],
   "source": [
    "RF_valid(df, M.detach().cpu(), U.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
