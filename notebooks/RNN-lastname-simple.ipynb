{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use simple matrix-based RNN to classify the language of last names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_transform(x, mean=0.0, std=0.01):\n",
    "    \"Convert x to have mean and std\"\n",
    "    return x*std + mean\n",
    "\n",
    "def randn(n1, n2,          \n",
    "          mean=0.0, std=0.01, requires_grad=False,\n",
    "          device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "          dtype=torch.float64):\n",
    "    x = torch.randn(n1, n2, device=device, dtype=dtype)\n",
    "    x = normal_transform(x, mean=mean, std=std)\n",
    "    x.requires_grad=requires_grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend()#loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    expy = torch.exp(y)\n",
    "    if len(y.shape)==1: # 1D case can't use axis arg\n",
    "        return expy / torch.sum(expy)\n",
    "    return expy / torch.sum(expy, axis=1).reshape(-1,1)\n",
    "\n",
    "def cross_entropy(y_prob, y_true):\n",
    "    \"\"\"\n",
    "    y_pred is n x k for n samples and k output classes and y_true is n x 1\n",
    "    and is often softmax of final layer.\n",
    "    y_pred values must be probability that output is a specific class.\n",
    "    Binary case: When we have y_pred close to 1 and y_true is 1,\n",
    "    loss is -1*log(1)==0. If y_pred close to 0 and y_true is 1, loss is\n",
    "    -1*log(small value) = big value.\n",
    "    y_true values must be positive integers in [0,k-1].\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    # Get value at y_true[j] for each sample with fancy indexing\n",
    "    p = y_prob[range(n),y_true]\n",
    "    return torch.mean(-torch.log(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_test.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (6700, 2))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING SUBSAMPLE\n",
    "df_train = df_train.sample(n=2000)\n",
    "df_test = df_test.sample(n=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8347</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8342</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8347  To The First Page  Russian\n",
       "8342  To The First Page  Russian"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page' # wth?\n",
    "df_train[badname].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably destroying useful info but much smaller vocab\n",
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(df_train['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split names into variable-length lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [list(name) for name in df_train['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['name']!='To The First Page']\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[df_test['name']!='To The First Page']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split names into variable-length lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['g', 'u', 'o'], ['l', 'o', 'w', 'n', 'd', 'e', 's']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df_train['name'], df_train['language']\n",
    "X = [list(name) for name in X]\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['k', 'a', 'l', 'e', 't', 'i', 'n'],\n",
       " ['b', 'e', 's', 't', 'e', 'm', 'y', 'a', 'n', 'o', 'v']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = df_test['name'], df_test['language']\n",
    "X_test = [list(name) for name in X_test]\n",
    "X_test[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 14, 14, 14, 14, 14, 14,  4, 16, 14])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.tensor(np.array(y_train.cat.codes.values), dtype=torch.long)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = torch.tensor(np.array(pd.Categorical(y_valid, categories=y_cats, ordered=True).codes),\n",
    "                       dtype=torch.long)\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12,  4, 14, 14,  0]), array([14, 14, 14,  7, 14], dtype=int8))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(c) -> torch.tensor:\n",
    "    v = torch.zeros((len(vocab),1), dtype=torch.float64)\n",
    "    v[ctoi[c]] = 1\n",
    "    return v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward1(x):\n",
    "    h = torch.zeros(nhidden, 1, dtype=torch.float64, device=device, requires_grad=False)  # reset hidden state at start of record\n",
    "    for j in range(len(x)):  # for each char in a name\n",
    "        x_onehot = onehot(x[j])\n",
    "        h = W.mm(h) + U.mm(x_onehot)# + b\n",
    "#             h = torch.tanh(h)  # squish to (-1,+1)\n",
    "        h = torch.relu(h)\n",
    "#             print(\"h\",h)\n",
    "    # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "    # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "#         h = dropout(h, p=0.4)\n",
    "    o = V.mm(h)# + Vb\n",
    "    o = o.reshape(1,nclasses)\n",
    "#     print(torch.sum(o[0]).item())\n",
    "    o = softmax(o)\n",
    "    return o\n",
    "\n",
    "def forward(X:Sequence[Sequence]):#, apply_softmax=True):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "#     outputs = torch.empty(len(X), nclasses, dtype=torch.float64).to(device)\n",
    "    outputs = []\n",
    "    for i in range(0, len(X)): # for each input record\n",
    "        o = forward1(X[i])\n",
    "        outputs.append( o[0] ) \n",
    "    return torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(a:torch.tensor,   # activation/output of a layer\n",
    "            p=0.0             # probability an activation is zeroed\n",
    "           ) -> torch.tensor:\n",
    "    usample = torch.empty_like(a).uniform_(0, 1) # get random value for each activation\n",
    "    mask = (usample>p).int()                     # get mask as those with value greater than p\n",
    "    a = a * mask                                 # kill masked activations\n",
    "    a /= 1-p                                     # scale during training by 1/(1-p) to avoid scaling by p at test time\n",
    "                                                 # after dropping p activations, (1-p) are left untouched, on average\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,600 training records, 28 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(y_cats)\n",
    "n = len(X_train)\n",
    "print(f\"{n:,d} training records, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using pure SGD, one record used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  1.8735 accur 0.466 | train loss  1.6743 accur 0.496 | valid loss  1.6968 accur 0.470\n",
      "Epoch:   2 accum loss  1.5304 accur 0.548 | train loss  1.3733 accur 0.623 | valid loss  1.4343 accur 0.595\n",
      "Epoch:   3 accum loss  1.3470 accur 0.610 | train loss  1.2228 accur 0.631 | valid loss  1.3250 accur 0.615\n",
      "Epoch:   4 accum loss  1.2139 accur 0.639 | train loss  1.0951 accur 0.668 | valid loss  1.2043 accur 0.663\n",
      "Epoch:   5 accum loss  1.1114 accur 0.664 | train loss  1.0134 accur 0.679 | valid loss  1.1824 accur 0.665\n",
      "Epoch:   6 accum loss  1.0127 accur 0.688 | train loss  0.9314 accur 0.704 | valid loss  1.1504 accur 0.680\n",
      "Epoch:   7 accum loss  0.9329 accur 0.706 | train loss  0.8670 accur 0.727 | valid loss  1.1409 accur 0.688\n",
      "Epoch:   8 accum loss  0.8557 accur 0.736 | train loss  0.7479 accur 0.772 | valid loss  1.1570 accur 0.688\n",
      "Epoch:   9 accum loss  0.7813 accur 0.756 | train loss  0.7293 accur 0.774 | valid loss  1.1240 accur 0.680\n",
      "Epoch:  10 accum loss  0.7271 accur 0.766 | train loss  0.6600 accur 0.794 | valid loss  1.2729 accur 0.673\n",
      "Epoch:  11 accum loss  0.6481 accur 0.786 | train loss  0.5833 accur 0.807 | valid loss  1.2201 accur 0.675\n",
      "Epoch:  12 accum loss  0.6033 accur 0.803 | train loss  0.5729 accur 0.815 | valid loss  1.3689 accur 0.670\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden, nhidden,   dtype=torch.float64, device=device, requires_grad=True)\n",
    "U = randn(nhidden,     nfeatures, dtype=torch.float64, device=device, requires_grad=True) # embed one-hot char vec\n",
    "V = randn(nclasses,    nhidden,   dtype=torch.float64, device=device, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.001, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    for i in range(0, n): # an epoch trains all input records\n",
    "        x = X_train[i]\n",
    "        h = torch.zeros(nhidden, 1, dtype=torch.float64, device=device, requires_grad=False)  # reset hidden state at start of record\n",
    "        for j in range(len(x)):  # for each char in a name\n",
    "            h = W.mm(h) + U.mm(onehot(x[j]))\n",
    "            h = torch.relu(h)\n",
    "        # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "        # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "#         h = dropout(h, p=0.3)\n",
    "        o = V.mm(h)\n",
    "        o = o.reshape(1,nclasses)\n",
    "        o = softmax(o)\n",
    "\n",
    "        loss = cross_entropy(o, y_train[i])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        correct = torch.argmax(o[0])==y_train[i]\n",
    "        epoch_training_accur += correct\n",
    "\n",
    "    epoch_training_loss /= n\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid)\n",
    "        valid_loss = cross_entropy(o, y_valid)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using mini-batch SGD, multiple records used to compute gradient\n",
    "\n",
    "Still w/o vectorization, one record at a time. Just do a batch before computing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,600 training records, 28 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(y_cats)\n",
    "batch_size = 32\n",
    "n = len(X_train)\n",
    "print(f\"{n:,d} training records, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  2.0834 accur 0.450 | train loss  1.7008 accur 0.468 | valid loss  1.7450 accur 0.465\n",
      "Epoch:   2 accum loss  1.7062 accur 0.472 | train loss  1.5447 accur 0.494 | valid loss  1.6028 accur 0.493\n",
      "Epoch:   3 accum loss  1.5424 accur 0.525 | train loss  1.4098 accur 0.579 | valid loss  1.5268 accur 0.575\n",
      "Epoch:   4 accum loss  1.4293 accur 0.582 | train loss  1.2788 accur 0.615 | valid loss  1.3769 accur 0.590\n",
      "Epoch:   5 accum loss  1.3124 accur 0.619 | train loss  1.1889 accur 0.654 | valid loss  1.3551 accur 0.630\n",
      "Epoch:   6 accum loss  1.2803 accur 0.621 | train loss  1.1122 accur 0.665 | valid loss  1.3031 accur 0.642\n",
      "Epoch:   7 accum loss  1.1863 accur 0.642 | train loss  1.0396 accur 0.680 | valid loss  1.2282 accur 0.670\n",
      "Epoch:   8 accum loss  1.1604 accur 0.649 | train loss  1.0084 accur 0.692 | valid loss  1.2841 accur 0.668\n",
      "Epoch:   9 accum loss  1.1111 accur 0.658 | train loss  0.9643 accur 0.706 | valid loss  1.1696 accur 0.675\n",
      "Epoch:  10 accum loss  1.0273 accur 0.678 | train loss  0.8484 accur 0.728 | valid loss  1.2416 accur 0.685\n",
      "Epoch:  11 accum loss  0.9942 accur 0.691 | train loss  0.8621 accur 0.736 | valid loss  1.3127 accur 0.675\n",
      "Epoch:  12 accum loss  0.9919 accur 0.694 | train loss  0.7914 accur 0.755 | valid loss  1.1894 accur 0.695\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden, nhidden,   dtype=torch.float64, device=device, requires_grad=True)\n",
    "U = randn(nhidden,     nfeatures, dtype=torch.float64, device=device, requires_grad=True) # embed one-hot char vec\n",
    "V = randn(nclasses,    nhidden,   dtype=torch.float64, device=device, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.01, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        for i in range(p, p+batch_size): # do one batch\n",
    "            x = X_train[i]\n",
    "            h = torch.zeros(nhidden, 1, dtype=torch.float64, device=device, requires_grad=False)  # reset hidden state at start of record\n",
    "            for j in range(len(x)):  # for each char in a name\n",
    "                h = W.mm(h) + U.mm(onehot(x[j]))\n",
    "                h = torch.relu(h)\n",
    "            # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "            # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "#             h = dropout(h, p=0.3)\n",
    "            o = V.mm(h)\n",
    "            o = o.reshape(1,nclasses)\n",
    "            o = softmax(o)\n",
    "            loss += cross_entropy(o, y_train[i])\n",
    "            correct = torch.argmax(o[0])==y_train[i]\n",
    "            epoch_training_accur += correct\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= n\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid)\n",
    "        valid_loss = cross_entropy(o, y_valid)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using vectorized mini-batch SGD\n",
    "\n",
    "Instead of processing batch one record at a time from time 1 to time len(word), process all time steps t across all batch records at once then proceed to time step (char index) t+1.  This allows us to vectorize and perform each time step in parallel.  We effectively remove a loop.\n",
    "\n",
    "Means we must pad to have same length in batch. pad on left so they are ignored to get same answer as record-by-record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros((len(X),max_len,len(vocab)), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [['a','b'],['c','d','e'], # batch 1\n",
    "           ['f'],['c','a'], # batch 2\n",
    "           ['e']] # strip\n",
    "y_train = [0,2,1,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 training records, batch size 2, 6 features (chars), 3 target languages, state is 2-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 2\n",
    "batch_size = 2\n",
    "n = len(X_train)\n",
    "\n",
    "n = batch_size * (n // batch_size)\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X)\n",
    "max_len = get_max_len(X)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(torch.tensor(y_train)))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64) \n",
      "\n",
      "['c', 'd', 'e']\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 0.]], dtype=torch.float64) \n",
      "\n",
      "['f']\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 1.]], dtype=torch.float64) \n",
      "\n",
      "['c', 'a']\n",
      "tensor([[0., 0., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_onehot = onehot_matrix(X_train, max_len, vocab, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X:Sequence[Sequence], max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    X_onehot = onehot_matrix(X, max_len, vocab)\n",
    "    h = torch.zeros(nhidden, len(X), dtype=torch.float64, device=device, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        h = W.mm(h) + U.mm(x_step_t)\n",
    "        h = torch.relu(h)        \n",
    "    o = V.mm(h)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = X_train\n",
    "y_valid = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3332, 0.3335]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3332, 0.3334],\n",
      "        [0.3333, 0.3331, 0.3335]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   1 accum loss  0.5494 accur 0.000 | train loss  1.0981 accur 0.250 | valid loss  1.0981 accur 0.250\n",
      "EPOCH 2\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3330, 0.3329, 0.3341]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3334]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   2 accum loss  0.5490 accur 0.000 | train loss  1.0971 accur 0.250 | valid loss  1.0971 accur 0.250\n",
      "EPOCH 3\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3321, 0.3326, 0.3353]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   3 accum loss  0.5486 accur 0.000 | train loss  1.0956 accur 0.250 | valid loss  1.0956 accur 0.250\n",
      "EPOCH 4\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3308, 0.3319, 0.3374]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   4 accum loss  0.5478 accur 0.000 | train loss  1.0933 accur 0.250 | valid loss  1.0933 accur 0.250\n",
      "EPOCH 5\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3289, 0.3307, 0.3404]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3332, 0.3333, 0.3335]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   5 accum loss  0.5467 accur 0.000 | train loss  1.0903 accur 0.250 | valid loss  1.0903 accur 0.250\n",
      "EPOCH 6\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3264, 0.3289, 0.3447]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3332, 0.3333, 0.3336]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   6 accum loss  0.5452 accur 0.000 | train loss  1.0864 accur 0.250 | valid loss  1.0864 accur 0.250\n",
      "EPOCH 7\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3233, 0.3266, 0.3501]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3332, 0.3332, 0.3336]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   7 accum loss  0.5432 accur 0.000 | train loss  1.0815 accur 0.250 | valid loss  1.0815 accur 0.250\n",
      "EPOCH 8\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3195, 0.3235, 0.3570]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3332, 0.3333, 0.3335]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   8 accum loss  0.5408 accur 0.000 | train loss  1.0756 accur 0.250 | valid loss  1.0756 accur 0.250\n",
      "EPOCH 9\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3149, 0.3196, 0.3655]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3334]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:   9 accum loss  0.5378 accur 0.000 | train loss  1.0686 accur 0.250 | valid loss  1.0686 accur 0.250\n",
      "EPOCH 10\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3094, 0.3148, 0.3758]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:  10 accum loss  0.5343 accur 0.000 | train loss  1.0604 accur 0.250 | valid loss  1.0604 accur 0.250\n",
      "EPOCH 11\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3027, 0.3089, 0.3883]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3334]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:  11 accum loss  0.5302 accur 0.000 | train loss  1.0509 accur 0.250 | valid loss  1.0509 accur 0.250\n",
      "EPOCH 12\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.2948, 0.3018, 0.4034]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "softmax\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3335]], dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch:  12 accum loss  0.5255 accur 0.000 | train loss  1.0402 accur 0.250 | valid loss  1.0402 accur 0.250\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADUCAYAAABwOKTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZHElEQVR4nO3de5QU9Zn/8fene0YGBRQQuRouUSAqChEUQ2Ii/n4E8UKOF8SICpuEg0ZFdyXi7iYbPbo/k83PbNwYWBIRkxAXhWBwg6jBC2uiGMYdBARBOBgmqFwMt1UCM/3sH1U99Aw9PTWX6p5mntc5fbrqW7enG56p6qrvRWaGc654JAodgHOucTxpnSsynrTOFRlPWueKjCetc0XGk9a5IhNb0koaJKki47VP0h1xHc+5tkL5eE4rKQn8GTjfzN6L/YDOHcPydXl8MbDZE9a55stX0k4EnsjTsZw7psV+eSzpOGA7cKaZfZhl+VRgKsAJJ5xw7uDBg2ONx7liUF5evsvMumVblo+kHQ9808zGNLTu8OHDbdWqVbHG41wxkFRuZsOzLcvH5fF1+KWxcy0m1qSVdDzwf4Ffx3kc59qSkjh3bmYfA13jPIZzbU2sSeuOTYcPH6ayspKDBw8WOpSiV1ZWRp8+fSgtLY28jSeta7TKyko6duxIv379kFTocIqWmbF7924qKyvp379/5O287rFrtIMHD9K1a1dP2GaSRNeuXRt9xeJJ65rEE7ZlNOV79KR1rsh40rqis2fPHn7yk580ertx48axZ8+eRm83efJkFi5c2Ojt4uJJ64pOfUlbXV2dc7ulS5dy0kknxRVW3vjdY9cs9z6zjre372vRfZ7RqxP/dPmZ9S6fOXMmmzdvZujQoZSWltKhQwd69uxJRUUFb7/9Nl/5ylfYtm0bBw8eZPr06UydOhWAfv36sWrVKg4cOMAll1zC5z//ef7whz/Qu3dvfvOb39C+ffsGY1u+fDl33XUXVVVVjBgxglmzZtGuXTtmzpzJkiVLKCkpYcyYMfzgBz/gqaee4t577yWZTHLiiSeyYsWKFvl+PGld0XnwwQdZu3YtFRUVvPzyy1x66aWsXbu25rHJ3Llz6dKlC5988gkjRozgqquuomvX2nV8Nm3axBNPPMFPf/pTJkyYwKJFi5g0aVLO4x48eJDJkyezfPlyBg4cyI033sisWbO48cYbWbx4MRs2bEBSzSX4fffdx3PPPUfv3r2bdFleH09a1yy5zoj5ct5559V6zvnwww+zePFiALZt28amTZuOStr+/fszdOhQAM4991y2bt3a4HHeeecd+vfvz8CBAwG46aabeOSRR7j11lspKyvj61//OpdeeimXXXYZAKNGjWLy5MlMmDCBK6+8siU+KuC/ad0x4IQTTqiZfvnll/nd737Ha6+9xurVqxk2bFjW56Dt2rWrmU4mk1RVVTV4nPpaxJWUlPDGG29w1VVX8fTTTzN27FgAZs+ezf3338+2bdsYOnQou3fvbuxHy368FtmLc3nUsWNH9u/fn3XZ3r176dy5M8cffzwbNmzg9ddfb7HjDh48mK1bt/Luu+9y2mmn8Ytf/IIvfvGLHDhwgI8//phx48YxcuRITjvtNAA2b97M+eefz/nnn88zzzzDtm3bjjrjN4UnrSs6Xbt2ZdSoUZx11lm0b9+e7t271ywbO3Yss2fP5uyzz2bQoEGMHDmyxY5bVlbGY489xjXXXFNzI2ratGl89NFHjB8/noMHD2Jm/PCHPwRgxowZbNq0CTPj4osv5pxzzmmROPLSsVtU3gi+OKxfv57PfOYzhQ7jmJHt+yxYI3hJJ0laKGmDpPWSLojzeM61BXFfHv8IWGZmV4d9RR0f8/Gca7JvfvOb/P73v69VNn36dKZMmVKgiLKLLWkldQIuBCYDmNkh4FBcx3OuuR555JFChxBJnJfHA4CdwGOS/lvSzySd0NBGzrnc4kzaEuCzwCwzGwb8DzCz7kqSpkpaJWnVzp07YwzHuWNDnElbCVSa2cpwfiFBEtdiZnPMbLiZDe/WLWs3r865DLElrZl9AGyTNCgsuhh4O67jOddWxF2N8TZgvqS3gKHAP8d8POeO0qFDh3qXbd26lbPOOiuP0TRf3F2oVgBZHxA755rGqzG65nl2JnywpmX32WMIXPJgvYvvvvtu+vbtyy233ALAd7/7XSSxYsUK/vKXv3D48GHuv/9+xo8f36jDHjx4kJtvvplVq1ZRUlLCQw89xEUXXcS6deuYMmUKhw4dIpVKsWjRInr16sWECROorKykurqab3/721x77bXN+thRedK6ojNx4kTuuOOOmqR98sknWbZsGXfeeSedOnVi165djBw5kiuuuKJRHaeln9OuWbOGDRs2MGbMGDZu3Mjs2bOZPn06119/PYcOHaK6upqlS5fSq1cvfvvb3wJBQ4V88aR1zZPjjBiXYcOGsWPHDrZv387OnTvp3LkzPXv25M4772TFihUkEgn+/Oc/8+GHH9KjR4/I+3311Ve57bbbgKBFT9++fdm4cSMXXHABDzzwAJWVlVx55ZWcfvrpDBkyhLvuuou7776byy67jC984QtxfdyjeHtaV5SuvvpqFi5cyIIFC5g4cSLz589n586dlJeXU1FRQffu3Rvdn3B9jWe++tWvsmTJEtq3b8+Xv/xlXnzxRQYOHEh5eTlDhgzhnnvu4b777muJjxWJn2ldUZo4cSLf+MY32LVrF6+88gpPPvkkp5xyCqWlpbz00ku89957jd7nhRdeyPz58xk9ejQbN27kT3/6E4MGDWLLli0MGDCA22+/nS1btvDWW28xePBgunTpwqRJk+jQoQPz5s1r+Q9ZD09aV5TOPPNM9u/fT+/evenZsyfXX389l19+OcOHD2fo0KE0ZXDyW265hWnTpjFkyBBKSkqYN28e7dq1Y8GCBfzyl7+ktLSUHj168J3vfIc//vGPzJgxg0QiQWlpKbNmzYrhU2bn7Wldo3l72pbVqtrTOudanl8euzZhzZo13HDDDbXK2rVrx8qVK+vZovVqMGklTQceA/YDPwOGATPN7PmYY3OuxQwZMoSKiopCh9Eiolwe/42Z7QPGAN2AKUD+H865VqU13QspZk35HqMkbbpKyTjgMTNbnVHm2qCysjJ2797tidtM6UGly8rKGrVdlN+05ZKeB/oD90jqCKSaEKM7RvTp04fKykq804LmKysro0+fPo3aJkrSfo2gWd0WM/tYUheCS2TXRpWWltYahsPlV5TL4wuAd8xsj6RJwD8C+asd7ZyrJUrSzgI+lnQO8C3gPeDnUXYuaaukNZIqJHmtCedaQJTL4yozM0njgR+Z2aOSbmrEMS4ys11NjM85V0eUpN0v6R7gBuALkpJAabxhOefqE+Xy+FrgrwTPaz8AegP/EnH/BjwvqVzS1GwreBeqzjVOpAYDkroDI8LZN8xsR6SdS73MbLukU4AXgNvMrN4x7L3BgHOBZjUYkDQBeAO4BpgArJR0dZQDm9n28H0HsBg4L2rQzrnsovym/QdgRPrsKqkb8DuCzsfrFQ4BkjCz/eH0GCB/zfudO0ZFSdpEncvh3UT7LdwdWBx2rFUC/MrMljU+ROdcpihJu0zSc8AT4fy1wNKGNjKzLUDLDH3tnKvRYNKa2QxJVwGjCBoKzDGzxbFH5pzLKlIjeDNbBCyKORbnXAT1Jq2k/QTPWY9aBJiZdYotKudcvepNWjPrmM9AnHPReMduzhUZT1rniownrXNFxpPWuSITpQvVbHeR9wKrgL8LK1E45/IkynPah4DtwK8IHvdMBHoA7wBzgS/FFZxz7mhRLo/Hmtm/m9l+M9tnZnOAcWa2AOgcc3zOuTqiJG1K0gRJifA1IWOZd3zrXJ5FSdrrCbqa2RG+bgAmSWoP3BpjbM65LKI0GNgCXF7P4ldbNhznXEOi9FzRR9JiSTskfShpkaTIXaJLSkr6b0n/2bxQnXMQ7fL4MWAJ0IugU7dnwrKopgPrGx+acy6bKEnbzcweM7Oq8DWPYPS8BoVn5EsJhsh0zrWAKEm7S9Kk8DI3GQ4Nsjvi/v+VYFQCH7DLuRYSaXxagl4YPwDeB64Oy3KSdBmww8zKG1jP+z12rhEi9XvcpB1L/4/g8VAVUAZ0An5tZpPq28b7PXYukKvf41w9V/wbOSpPmNntuQ5qZvcA94T7+hJwV66Edc5Fk+s5rZ/ynGuFcnU383hLHcTMXgZebqn9OdeWeXta54qMJ61zRSZKNcZRUcqcc/kR5Uz7bxHLnHN5kOuRzwXA54Bukv42Y1EnIBl3YM657HI98jkO6BCuk9lx+T6CWlHOuQLI9cjnFeAVSfPM7L08xuScyyFKx27tJM0B+mWub2aj4wrKOVe/KEn7FDCboHlddbzhOOcaEiVpq8xsVuyROOciifLI5xlJt0jqKalL+hV7ZM65rKKcaW8K32dklBkwoOXDcc41JEpvjP3zEYhzLpoo1RiPl/SP4R1kJJ0e9krhnCuAqL0xHiKoHQVQCdzf0EaSyiS9IWm1pHWS7m1GnM65UJSk/bSZfR84DGBmnxAMxNWQvwKjzewcYCgwVtLIJkfqnAOi3Yg6FA4BYgCSPk2QkDlZ0PnUgXC2NHz52D/ONVOUM+0/AcuAUyXNB5YTdIvaoLDL1QqCMYBeMLOVTY7UOQdEu3v8gqQ3gZEEl8XTzWxXlJ2bWTUwVNJJwGJJZ5nZ2sx1JE0FpgJ86lOfamz8zrU5UXuu6E3QHO844EJJVzbmIGa2h6CPqLFZls0xs+FmNrxbt0gDFzjXpjV4ppU0FzgbWMeRkQIM+HUD23UDDpvZnvA38f8Bvte8cJ1zUW5EjTSzM5qw757A45KSBGf0J83MR85zrpmiJO1rks4ws7cbs2MzewsY1rSwnHP1iZK0jxMk7gcEj3pE8ETn7Fgjc85lFSVp5xKMybMGH/3OuYKLkrR/MrMlsUfinIskStJukPQrghHga2pCmVnOu8fOuXhESdr2BMk6JqOswUc+zrl4RKkRNSUfgTjnosnVWfm3zOz79Y1T29D4tM65eOQ6064P332cWudakVydlT8TTn5sZk9lLpN0TaxROefqFaXBwD0Ry5xzeZDrN+0lwDigt6SHMxZ1AqriDsw5l12u37TbCX7PXgGUZ5TvB+6MMyjnXP1y/aZdDayW9CszO5zHmJxzOUSpXHGepO8CfcP10w0GvLNy5wogStI+SnA5XI4PwOVcwUVJ2r1m9mxjdyzpVODnQA+C1kFzzOxHjd2Pc662KEn7kqR/IahrnNlg4M0GtqsC/s7M3pTUESiX9EJjG9M752qLkrTnh+/DM8oMyDmotJm9D7wfTu+XtJ6ggzhPWueaIUqDgYuaexBJ/Qi6njmq32PvQtW5xokyAFd3SY9KejacP0PS16IeQFIHYBFwh5ntq7vcu1B1rnGiVGOcBzwH9ArnNwJ3RNm5pFKChJ3vjeadaxlRkvZkM3uSsH8oM6siwqMfSSJ4XLTezB5qVpTOuRpRkvZ/JHXlyABcI4G9EbYbRdAh3GhJFeFrXNNDdc5BtLvHfwssAT4t6fdAN+DqhjYys1eJNiSmc64Rotw9flPSF4FBBEn4jtdFdq5w6r08ljRCUg+o+R17LvAA8P8ldclTfM65OnL9pv134BCApAuBBwmqJe4F5sQfmnMum1yXx0kz+yicvpag7vAiYFE4ULRzrgBynWmTktJJfTHwYsayKDewnHMxyJV8TwCvSNoFfAL8F4Ck04j2yMc5F4NcPVc8IGk5wTizz5tZuu/jBHBbPoJzzh0t52Wumb2epWxjfOE45xoSpUaUc64V8aR1rsh40jpXZDxpnSsynrTOFRlPWueKTGw1myTNBS4DdpjZWc3d33sb3mT7K49mlGT8vanVAFDpAI4uyyhXWGZSlm2y7KNmuwRWUyxQIlhbCtdR7f3UKhM6ar2MZYlEzTqWuX64TrBtIpyu/Y6SKLM8ISCRMZ8I5hNCSgbzEgklIBGsp0S4j8z5RKJmv0oEZYlEItyHSCRLSNSslyCRXp4sIZFIhK9geSKRJJksqTmGa5o4qyPOA35M0Mig2fZsf5dh2xcAtXNUtca7tpzLVWd5QkeNle3yJGWimgQpEqTQkXelyxJYTXmClNLzyXA6XZ7Ewm1MyfA9eKWUxMLyoCwJSpBSCZZIgpLBsoxpEiWgBJYogcSReRIlKD2fKEHJEpQogfA9mC8N/lglS+q8lwZ/3JKlJJJJ2nfsTO8BZzb5u4stac1sRdgLY4s4Z/QEGD2hpXZ3FEulgvew4teR91StMrOM9cxqyqxmOnPdYB1qLU9lrGeQMoyMZalUuA41+4cUll4vVR0uSx3ZVyr9Xg3UnjcMUikwIxXuP9hvNZZK7zvYF+my9Oe06oxlYVmqOvxc6en0Po+8LFVde94MrBpqyjPnDVm6vBplbJcuV8Yy1SqvrpkXKRIZ6yStClnwZ0EWLAtSu5qEhX8KwrIkR96TdmS+hFQsf9jXHXc2vf/+v5q8vVf8D6Uv17yrDZcpVV1NdXVV8Ko6TFVVFVZdRVXVYVLVVVRXHQrf0/NVpKoPk6o6jIXbWXWwzFKHSVVV0a7Tyc2KqeBJ6/0eu9YskUySSCYppV2hQ6lR8LsB3u+xc41T8KR1zjVObEkr6QngNWCQpMrGjErgnKtfnHePr4tr3861ZX557FyR8aR1rsh40jpXZDxpnSsynrTOFRlPWueKjCetc0XGk9a5IuNJ61yR8aR1rsh40jpXZDxpnSsynrTOFRlPWueKTKxJK2mspHckvStpZpzHcq6tiLMRfBJ4BLgEOAO4TtIZcR3PubYizjPtecC7ZrbFzA4B/wGMj/F4zrUJcSZtb2BbxnxlWOaca4Y4u1DN1oXwUT0/Z3ahChyQ9E6OfZ4M7GqB2OLU2mNs7fFB648xH/H1rW9BnElbCZyaMd8H2F53JTObA8yJskNJq8xseMuEF4/WHmNrjw9af4yFji/Oy+M/AqdL6i/pOGAisCTG4znXJsTZG2OVpFuB54AkMNfM1sV1POfailiHBTGzpcDSFtxlpMvoAmvtMbb2+KD1x1jQ+JQe5c05Vxy8GqNzRaZVJm1D1R8ltZO0IFy+siXHwY0Y36mSXpK0XtI6SdOzrPMlSXslVYSv7+Q5xq2S1oTHXpVluSQ9HH6Hb0n6bB5jG5TxvVRI2ifpjjrr5P37kzRX0g5JazPKukh6QdKm8L1zPdveFK6zSdJNsQaaORhya3gR3LTaDAwAjgNWA2fUWecWYHY4PRFYkOcYewKfDac7AhuzxPgl4D8L+D1uBU7OsXwc8CzB8/SRwMoC/nt/APQt9PcHXAh8FlibUfZ9YGY4PRP4XpbtugBbwvfO4XTnuOJsjWfaKNUfxwOPh9MLgYsl5W08aDN738zeDKf3A+spvtpe44GfW+B14CRJPQsQx8XAZjN7rwDHrsXMVgAf1SnO/L/2OPCVLJt+GXjBzD4ys78ALwBj44qzNSZtlOqPNeuYWRWwF+ial+jqCC/NhwErsyy+QNJqSc9KOjOvgQW1z56XVB7WOqurtVQznQg8Uc+yQn5/ad3N7H0I/lgDp2RZJ6/fZcFHgs8iSvXHSFUk4yapA7AIuMPM9tVZ/CbBJd8BSeOAp4HT8xjeKDPbLukU4AVJG8IzSVrBv8Ow0s0VwD1ZFhf6+2uMvH6XrfFMG6X6Y806kkqAEzn6siZWkkoJEna+mf267nIz22dmB8LppUCppJPzFZ+ZbQ/fdwCLCX52ZIpUzTRmlwBvmtmHdRcU+vvL8GH6Z0P4viPLOnn9Lltj0kap/rgESN+huxp40cI7AvkQ/n5+FFhvZg/Vs06P9O9sSecRfNe78xTfCZI6pqeBMcDaOqstAW4M7yKPBPamLwPz6DrquTQu5PdXR+b/tZuA32RZ5zlgjKTO4d3lMWFZPApxxzDCXbxxBHdkNwP/EJbdB1wRTpcBTwHvAm8AA/Ic3+cJLn/eAirC1zhgGjAtXOdWYB3B3e/Xgc/lMb4B4XFXhzGkv8PM+ETQScFmYA0wPM/f4fEESXhiRllBvz+CPyDvA4cJzp5fI7hXshzYFL53CdcdDvwsY9u/Cf8/vgtMiTNOrxHlXJFpjZfHzrkcPGmdKzKetM4VGU9a54qMJ61zRcaT9hgiqbpO65kW6yBeUr/M1i+ucFpjNUbXdJ+Y2dBCB+Hi5WfaNiBsW/s9SW+Er9PC8r6SloftaZdL+lRY3l3S4rCy/mpJnwt3lZT007AN8fOS2ofr3y7p7XA//1Ggj9lmeNIeW9rXuTy+NmPZPjM7D/gx8K9h2Y8JmuedDcwHHg7LHwZeMbNzCNqXpjvkOx14xMzOBPYAV4XlM4Fh4X6mxfXhXMBrRB1DJB0wsw5ZyrcCo81sS9jQ4QMz6yppF9DTzA6H5e+b2cmSdgJ9zOyvGfvoR9Bm9PRw/m6g1Mzul7QMOEDQEudpCyv6u3j4mbbtsHqm61snm79mTFdz5J7IpQT1mM8FysOWVy4mnrRtx7UZ76+F038gaEUFcD3waji9HLgZgtEPJXWqb6eSEsCpZvYS8C3gJOCos71rOf4X8djSXlJFxvwyM0s/9mknaSXBH+rrwrLbgbmSZgA7gSlh+XRgjqSvEZxRbyZo/ZJNEvilpBMJWg790Mz2tNgnckfx37RtQPibdriZteZBrVxEfnnsXJHxM61zRcbPtM4VGU9a54qMJ61zRcaT1rki40nrXJHxpHWuyPwv6uhCDUblmg4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden, nhidden,   dtype=torch.float64, device=device, requires_grad=True)\n",
    "U = randn(nhidden,     nfeatures, dtype=torch.float64, device=device, requires_grad=True) # embed one-hot char vec\n",
    "V = randn(nclasses,    nhidden,   dtype=torch.float64, device=device, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.01, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        batch_X_onehot = onehot_matrix(batch_X, max_len, vocab)\n",
    "        h = torch.zeros(nhidden, batch_size, dtype=torch.float64, device=device, requires_grad=False)\n",
    "        for j in range(max_len):\n",
    "            x_step_t = batch_X_onehot[:,j].T\n",
    "            h = W.mm(h) + U.mm(x_step_t)\n",
    "            h = torch.relu(h)        \n",
    "        o = V.mm(h)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        print(\"softmax\")\n",
    "        print(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "        correct = torch.argmax(o[0])==batch_y\n",
    "        epoch_training_accur += correct\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= n\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==torch.tensor(y_train)\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==torch.tensor(y_valid)\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
