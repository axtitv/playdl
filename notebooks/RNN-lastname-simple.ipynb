{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use simple matrix-based RNN to classify the language of last names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_transform(x, mean=0.0, std=0.01):\n",
    "    \"Convert x to have mean and std\"\n",
    "    return x*std + mean\n",
    "\n",
    "def randn(n1, n2,          \n",
    "          mean=0.0, std=0.01, requires_grad=False,\n",
    "          device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "          dtype=torch.float64):\n",
    "    x = torch.randn(n1, n2, device=device, dtype=dtype)\n",
    "    x = normal_transform(x, mean=mean, std=std)\n",
    "    x.requires_grad=requires_grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend()#loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    expy = torch.exp(y)\n",
    "    if len(y.shape)==1: # 1D case can't use axis arg\n",
    "        return expy / torch.sum(expy)\n",
    "    return expy / torch.sum(expy, axis=1).reshape(-1,1)\n",
    "\n",
    "def cross_entropy(y_prob, y_true):\n",
    "    \"\"\"\n",
    "    y_pred is n x k for n samples and k output classes and y_true is n x 1\n",
    "    and is often softmax of final layer.\n",
    "    y_pred values must be probability that output is a specific class.\n",
    "    Binary case: When we have y_pred close to 1 and y_true is 1,\n",
    "    loss is -1*log(1)==0. If y_pred close to 0 and y_true is 1, loss is\n",
    "    -1*log(small value) = big value.\n",
    "    y_true values must be positive integers in [0,k-1].\n",
    "    \"\"\"\n",
    "    n = y_prob.shape[0]\n",
    "    # Get value at y_true[j] for each sample with fancy indexing\n",
    "    p = y_prob[range(n),y_true]\n",
    "    return torch.mean(-torch.log(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_test.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (6700, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING SUBSAMPLE\n",
    "df_train = df_train.sample(n=2000)\n",
    "df_test = df_test.sample(n=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8347</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8341</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8347  To The First Page  Russian\n",
       "8341  To The First Page  Russian"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page' # wth?\n",
    "df_train[badname].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probably destroying useful info but much smaller vocab\n",
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(df_train['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split names into variable-length lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [list(name) for name in df_train['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['name']!='To The First Page']\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[df_test['name']!='To The First Page']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split names into variable-length lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['m', 'o', 'r', 'i', 't', 'a'], ['a', 'l', 'm', 'a', 's', 'i']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df_train['name'], df_train['language']\n",
    "X = [list(name) for name in X]\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['c', 'a', 'r', 'p', 'e', 'n', 't', 'e', 'r'],\n",
       " ['m', 'i', 'k', 'h', 'a', 's', 'e', 'n', 'k', 'o']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = df_test['name'], df_test['language']\n",
    "X_test = [list(name) for name in X_test]\n",
    "X_test[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 14,  0, 10,  4, 14,  4,  4, 14, 14])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.tensor(np.array(y_train.cat.codes.values), dtype=torch.long)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = torch.tensor(np.array(pd.Categorical(y_valid, categories=y_cats, ordered=True).codes),\n",
    "                       dtype=torch.long)\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11,  0, 14,  0, 14]), array([ 4, 14,  6, 14, 14], dtype=int8))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(c) -> torch.tensor:\n",
    "    v = torch.zeros((len(vocab),1), dtype=torch.float64)\n",
    "    v[ctoi[c]] = 1\n",
    "    return v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward1(x):\n",
    "    h = torch.zeros(nhidden, 1, dtype=torch.float64, device=device, requires_grad=False)  # reset hidden state at start of record\n",
    "    for j in range(len(x)):  # for each char in a name\n",
    "        x_onehot = onehot(x[j])\n",
    "        h = W.mm(h) + U.mm(x_onehot)# + b\n",
    "#             h = torch.tanh(h)  # squish to (-1,+1)\n",
    "        h = torch.relu(h)\n",
    "#             print(\"h\",h)\n",
    "    # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "    # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "#         h = dropout(h, p=0.4)\n",
    "    o = V.mm(h)# + Vb\n",
    "    o = o.reshape(1,nclasses)\n",
    "#     print(torch.sum(o[0]).item())\n",
    "    o = softmax(o)\n",
    "    return o\n",
    "\n",
    "def forward(X:Sequence[Sequence]):#, apply_softmax=True):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "#     outputs = torch.empty(len(X), nclasses, dtype=torch.float64).to(device)\n",
    "    outputs = []\n",
    "    for i in range(0, len(X)): # for each input record\n",
    "        o = forward1(X[i])\n",
    "        outputs.append( o[0] ) \n",
    "    return torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(a:torch.tensor,   # activation/output of a layer\n",
    "            p=0.0             # probability an activation is zeroed\n",
    "           ) -> torch.tensor:\n",
    "    usample = torch.empty_like(a).uniform_(0, 1) # get random value for each activation\n",
    "    mask = (usample>p).int()                     # get mask as those with value greater than p\n",
    "    a = a * mask                                 # kill masked activations\n",
    "    a /= 1-p                                     # scale during training by 1/(1-p) to avoid scaling by p at test time\n",
    "                                                 # after dropping p activations, (1-p) are left untouched, on average\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,600 training records, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(y_cats)\n",
    "n = len(X_train)\n",
    "print(f\"{n:,d} training records, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using pure SGD, one record used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  1.9213 accur 0.466 | train loss  1.6518 accur 0.471 | valid loss  1.5268 accur 0.533\n",
      "Epoch:   2 accum loss  1.5667 accur 0.525 | train loss  1.3558 accur 0.596 | valid loss  1.2935 accur 0.652\n",
      "Epoch:   3 accum loss  1.3529 accur 0.587 | train loss  1.1750 accur 0.638 | valid loss  1.1813 accur 0.670\n",
      "Epoch:   4 accum loss  1.2020 accur 0.637 | train loss  1.0602 accur 0.669 | valid loss  1.1335 accur 0.702\n",
      "Epoch:   5 accum loss  1.0759 accur 0.671 | train loss  0.9419 accur 0.697 | valid loss  1.1040 accur 0.723\n",
      "Epoch:   6 accum loss  0.9711 accur 0.697 | train loss  0.8868 accur 0.706 | valid loss  1.1056 accur 0.725\n",
      "Epoch:   7 accum loss  0.8872 accur 0.719 | train loss  0.8385 accur 0.733 | valid loss  1.1840 accur 0.705\n",
      "Epoch:   8 accum loss  0.8248 accur 0.738 | train loss  0.7331 accur 0.760 | valid loss  1.0659 accur 0.720\n",
      "Epoch:   9 accum loss  0.7318 accur 0.760 | train loss  0.7528 accur 0.769 | valid loss  1.1374 accur 0.717\n",
      "Epoch:  10 accum loss  0.7142 accur 0.770 | train loss  0.6073 accur 0.806 | valid loss  1.1153 accur 0.702\n",
      "Epoch:  11 accum loss  0.5949 accur 0.804 | train loss  0.6216 accur 0.814 | valid loss  1.3995 accur 0.705\n",
      "Epoch:  12 accum loss  0.5549 accur 0.819 | train loss  0.5824 accur 0.822 | valid loss  1.3580 accur 0.715\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 s, sys: 325 ms, total: 28.3 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden, nhidden,   dtype=torch.float64, device=device, requires_grad=True)\n",
    "U = randn(nhidden,     nfeatures, dtype=torch.float64, device=device, requires_grad=True) # embed one-hot char vec\n",
    "V = randn(nclasses,    nhidden,   dtype=torch.float64, device=device, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.001, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    for i in range(0, n): # an epoch trains all input records\n",
    "        x = X_train[i]\n",
    "        h = torch.zeros(nhidden, 1, dtype=torch.float64, device=device, requires_grad=False)  # reset hidden state at start of record\n",
    "        for j in range(len(x)):  # for each char in a name\n",
    "            h = W.mm(h) + U.mm(onehot(x[j]))\n",
    "            h = torch.relu(h)\n",
    "        # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "        # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "#         h = dropout(h, p=0.3)\n",
    "        o = V.mm(h)\n",
    "        o = o.reshape(1,nclasses)\n",
    "        o = softmax(o)\n",
    "\n",
    "        loss = cross_entropy(o, y_train[i])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        correct = torch.argmax(o[0])==y_train[i]\n",
    "        epoch_training_accur += correct\n",
    "\n",
    "    epoch_training_loss /= n\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid)\n",
    "        valid_loss = cross_entropy(o, y_valid)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using mini-batch SGD, multiple records used to compute gradient\n",
    "\n",
    "Still w/o vectorization, one record at a time. Just do a batch before computing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,600 training records, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(y_cats)\n",
    "batch_size = 32\n",
    "n = len(X_train)\n",
    "print(f\"{n:,d} training records, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss     nan accur 0.150 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:   2 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:   3 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:   4 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:   5 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:   6 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:   7 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:   8 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:   9 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:  10 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:  11 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n",
      "Epoch:  12 accum loss     nan accur 0.090 | train loss     nan accur 0.090 | valid loss     nan accur 0.093\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 145 ms, total: 22.4 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden, nhidden,   dtype=torch.float64, device=device, requires_grad=True)\n",
    "U = randn(nhidden,     nfeatures, dtype=torch.float64, device=device, requires_grad=True) # embed one-hot char vec\n",
    "V = randn(nclasses,    nhidden,   dtype=torch.float64, device=device, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.005, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        for i in range(p, p+batch_size): # do one batch\n",
    "            x = X_train[i]\n",
    "            h = torch.zeros(nhidden, 1, dtype=torch.float64, device=device, requires_grad=False)  # reset hidden state at start of record\n",
    "            for j in range(len(x)):  # for each char in a name\n",
    "                h = W.mm(h) + U.mm(onehot(x[j]))\n",
    "                h = torch.relu(h)\n",
    "            # h is output of RNN, a fancy CBOW embedding for variable-length sequence in x\n",
    "            # run through a final layer to map that h to a one-hot encoded predicted class\n",
    "#             h = dropout(h, p=0.3)\n",
    "            o = V.mm(h)\n",
    "            o = o.reshape(1,nclasses)\n",
    "            o = softmax(o)\n",
    "            loss += cross_entropy(o, y_train[i])\n",
    "            correct = torch.argmax(o[0])==y_train[i]\n",
    "            epoch_training_accur += correct\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= n\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid)\n",
    "        valid_loss = cross_entropy(o, y_valid)\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using vectorized mini-batch SGD\n",
    "\n",
    "Instead of processing batch one record at a time from time 1 to time len(word), process all time steps t across all batch records at once then proceed to time step (char index) t+1.  This allows us to vectorize and perform each time step in parallel.  We effectively remove a loop.\n",
    "\n",
    "Means we must pad to have same length in batch. pad on left so they are ignored to get same answer as record-by-record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros((len(X),max_len,len(vocab)), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with trivial data set\n",
    "\n",
    "Set TESTING=True to test vs full X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = False\n",
    "\n",
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "if TESTING:\n",
    "    nhidden = 2\n",
    "    batch_size = 2\n",
    "\n",
    "    X_train = [['a','b'],['c','d','e'], # batch 1\n",
    "               ['f'],['c','a'], # batch 2\n",
    "               ['e']] # strip\n",
    "    y_train = [0,2,1,1,2]\n",
    "\n",
    "    X_valid = X_train\n",
    "    y_valid = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,600 training records, batch size 32, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X)\n",
    "max_len = get_max_len(X)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(torch.tensor(y_train)))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot = onehot_matrix(X_train, max_len, vocab, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With verbose and trivial X_train we get:\n",
    "\n",
    "```\n",
    "['a', 'b']\n",
    "tensor([[0., 1., 0.],\n",
    "        [0., 0., 1.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.]], dtype=torch.float64) \n",
    "\n",
    "['c', 'd', 'e']\n",
    "tensor([[0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [1., 0., 0.],\n",
    "        [0., 1., 0.],\n",
    "        [0., 0., 1.],\n",
    "        [0., 0., 0.]], dtype=torch.float64) \n",
    "\n",
    "['f']\n",
    "tensor([[0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 1.]], dtype=torch.float64) \n",
    "\n",
    "['c', 'a']\n",
    "tensor([[0., 0., 1.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 1., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.],\n",
    "        [0., 0., 0.]], dtype=torch.float64) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X:Sequence[Sequence], max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    X_onehot = onehot_matrix(X, max_len, vocab)\n",
    "    h = torch.zeros(nhidden, len(X), dtype=torch.float64, device=device, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        h = W.mm(h) + U.mm(x_step_t)\n",
    "        h = torch.relu(h)        \n",
    "    o = V.mm(h)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  2.2246 accur 0.461 | train loss  1.9119 accur 0.465 | valid loss  1.9377 accur 0.525\n",
      "Epoch:   2 accum loss  1.8960 accur 0.465 | train loss  1.7842 accur 0.465 | valid loss  1.7029 accur 0.525\n",
      "Epoch:   3 accum loss  1.7857 accur 0.465 | train loss  1.7101 accur 0.465 | valid loss  1.5942 accur 0.525\n",
      "Epoch:   4 accum loss  1.7221 accur 0.466 | train loss  1.6590 accur 0.474 | valid loss  1.5432 accur 0.545\n",
      "Epoch:   5 accum loss  1.6703 accur 0.484 | train loss  1.6154 accur 0.498 | valid loss  1.5115 accur 0.558\n",
      "Epoch:   6 accum loss  1.6312 accur 0.496 | train loss  1.5691 accur 0.511 | valid loss  1.4784 accur 0.572\n",
      "Epoch:   7 accum loss  1.5889 accur 0.522 | train loss  1.5162 accur 0.537 | valid loss  1.4469 accur 0.608\n",
      "Epoch:   8 accum loss  1.5425 accur 0.541 | train loss  1.4762 accur 0.553 | valid loss  1.4163 accur 0.605\n",
      "Epoch:   9 accum loss  1.5077 accur 0.556 | train loss  1.4460 accur 0.562 | valid loss  1.3966 accur 0.615\n",
      "Epoch:  10 accum loss  1.4725 accur 0.572 | train loss  1.4156 accur 0.574 | valid loss  1.3742 accur 0.615\n",
      "Epoch:  11 accum loss  1.4391 accur 0.584 | train loss  1.3842 accur 0.590 | valid loss  1.3508 accur 0.615\n",
      "Epoch:  12 accum loss  1.4088 accur 0.597 | train loss  1.3553 accur 0.603 | valid loss  1.3299 accur 0.632\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.7 s, sys: 1.87 s, total: 41.6 s\n",
      "Wall time: 6.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden, nhidden,   dtype=torch.float64, device=device, requires_grad=True)\n",
    "U = randn(nhidden,     nfeatures, dtype=torch.float64, device=device, requires_grad=True) # embed one-hot char vec\n",
    "V = randn(nclasses,    nhidden,   dtype=torch.float64, device=device, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.001, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        batch_X_onehot = onehot_matrix(batch_X, max_len, vocab)\n",
    "        h = torch.zeros(nhidden, batch_size, dtype=torch.float64, device=device, requires_grad=False)\n",
    "        for j in range(max_len):\n",
    "            x_step_t = batch_X_onehot[:,j].T # make it len(vocab) x batch_size\n",
    "            h = W.mm(h) + U.mm(x_step_t)\n",
    "            h = torch.relu(h)        \n",
    "        o = V.mm(h)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "        correct = torch.argmax(o, dim=1)==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==torch.tensor(y_train)\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==torch.tensor(y_valid)\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
