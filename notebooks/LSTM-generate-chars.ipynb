{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with an LSTM and Keras\n",
    "\n",
    "Redo with chars not tokens.  Also, step by 3 through chars when getting windows (didn't do this for tokens might make big difference so go back and try.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, layers, callbacks, optimizers, Sequential, losses\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "def get_text(filename:str):\n",
    "    \"\"\"\n",
    "    Load and return the text of a text file, assuming latin-1 encoding as that\n",
    "    is what the BBC corpus uses.  Use codecs.open() function not open().\n",
    "    \"\"\"\n",
    "    f = codecs.open(filename, encoding='latin-1', mode='r')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    return s\n",
    "\n",
    "def compress_whitespace(s): # collapse things like \"\\n   \\t  \" with \" \"\n",
    "    return re.sub(r\"(\\s+)\", ' ', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus\n",
    "\n",
    "Let's use [Alexander Hamilton's federalist papers 1-10](https://guides.loc.gov/federalist-papers/text-1-10#s-lg-box-wrapper-25493264) as our corpus.\n",
    "\n",
    "Try with https://s3.amazonaws.com/text-datasets/nietzsche.txt which is 6x bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE SUPPOSING that Truth is a woman--what then? Is there not ground for suspecting that all philosophers, in so far as they have been dogmatists, have failed to understand women--that the terrible seriousness and clumsy importunity with which they have usually paid their addresses to Truth, have'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = get_text(\"data/federalist-papers.txt\")\n",
    "text = get_text(\"data/nietzsche.txt\")\n",
    "text = compress_whitespace(text)\n",
    "text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "#text = text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab and get X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = sorted(set(tokens))\n",
    "len(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {c:i for i,c in enumerate(V)}\n",
    "def ctoi(c):\n",
    "    return index[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 60\n",
    "step = 1\n",
    "Xy = [np.array((np.array(tokens[i-k:i],dtype=object),tokens[i])) for i in range(k,len(tokens)-1,step)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([array(['P', 'R', 'E', 'F', 'A', 'C', 'E', ' ', 'S', 'U', 'P', 'P', 'O',\n",
       "        'S', 'I', 'N', 'G', ' ', 't', 'h', 'a', 't', ' ', 'T', 'r', 'u',\n",
       "        't', 'h', ' ', 'i', 's', ' ', 'a', ' ', 'w', 'o', 'm', 'a', 'n',\n",
       "        '-', '-', 'w', 'h', 'a', 't', ' ', 't', 'h', 'e', 'n', '?', ' ',\n",
       "        'I', 's', ' ', 't', 'h', 'e', 'r', 'e'], dtype=object),\n",
       "        ' '], dtype=object),\n",
       " array([array(['R', 'E', 'F', 'A', 'C', 'E', ' ', 'S', 'U', 'P', 'P', 'O', 'S',\n",
       "        'I', 'N', 'G', ' ', 't', 'h', 'a', 't', ' ', 'T', 'r', 'u', 't',\n",
       "        'h', ' ', 'i', 's', ' ', 'a', ' ', 'w', 'o', 'm', 'a', 'n', '-',\n",
       "        '-', 'w', 'h', 'a', 't', ' ', 't', 'h', 'e', 'n', '?', ' ', 'I',\n",
       "        's', ' ', 't', 'h', 'e', 'r', 'e', ' '], dtype=object),\n",
       "        'n'], dtype=object),\n",
       " array([array(['E', 'F', 'A', 'C', 'E', ' ', 'S', 'U', 'P', 'P', 'O', 'S', 'I',\n",
       "        'N', 'G', ' ', 't', 'h', 'a', 't', ' ', 'T', 'r', 'u', 't', 'h',\n",
       "        ' ', 'i', 's', ' ', 'a', ' ', 'w', 'o', 'm', 'a', 'n', '-', '-',\n",
       "        'w', 'h', 'a', 't', ' ', 't', 'h', 'e', 'n', '?', ' ', 'I', 's',\n",
       "        ' ', 't', 'h', 'e', 'r', 'e', ' ', 'n'], dtype=object),\n",
       "        'o'], dtype=object),\n",
       " array([array(['F', 'A', 'C', 'E', ' ', 'S', 'U', 'P', 'P', 'O', 'S', 'I', 'N',\n",
       "        'G', ' ', 't', 'h', 'a', 't', ' ', 'T', 'r', 'u', 't', 'h', ' ',\n",
       "        'i', 's', ' ', 'a', ' ', 'w', 'o', 'm', 'a', 'n', '-', '-', 'w',\n",
       "        'h', 'a', 't', ' ', 't', 'h', 'e', 'n', '?', ' ', 'I', 's', ' ',\n",
       "        't', 'h', 'e', 'r', 'e', ' ', 'n', 'o'], dtype=object),\n",
       "        't'], dtype=object),\n",
       " array([array(['A', 'C', 'E', ' ', 'S', 'U', 'P', 'P', 'O', 'S', 'I', 'N', 'G',\n",
       "        ' ', 't', 'h', 'a', 't', ' ', 'T', 'r', 'u', 't', 'h', ' ', 'i',\n",
       "        's', ' ', 'a', ' ', 'w', 'o', 'm', 'a', 'n', '-', '-', 'w', 'h',\n",
       "        'a', 't', ' ', 't', 'h', 'e', 'n', '?', ' ', 'I', 's', ' ', 't',\n",
       "        'h', 'e', 'r', 'e', ' ', 'n', 'o', 't'], dtype=object),\n",
       "        ' '], dtype=object)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = np.array(Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Xy[:,0], Xy[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['P', 'R', 'E', 'F', 'A', 'C', 'E', ' ', 'S', 'U', 'P', 'P', 'O',\n",
       "        'S', 'I', 'N', 'G', ' ', 't', 'h', 'a', 't', ' ', 'T', 'r', 'u',\n",
       "        't', 'h', ' ', 'i', 's', ' ', 'a', ' ', 'w', 'o', 'm', 'a', 'n',\n",
       "        '-', '-', 'w', 'h', 'a', 't', ' ', 't', 'h', 'e', 'n', '?', ' ',\n",
       "        'I', 's', ' ', 't', 'h', 'e', 'r', 'e'],\n",
       "       ['R', 'E', 'F', 'A', 'C', 'E', ' ', 'S', 'U', 'P', 'P', 'O', 'S',\n",
       "        'I', 'N', 'G', ' ', 't', 'h', 'a', 't', ' ', 'T', 'r', 'u', 't',\n",
       "        'h', ' ', 'i', 's', ' ', 'a', ' ', 'w', 'o', 'm', 'a', 'n', '-',\n",
       "        '-', 'w', 'h', 'a', 't', ' ', 't', 'h', 'e', 'n', '?', ' ', 'I',\n",
       "        's', ' ', 't', 'h', 'e', 'r', 'e', ' ']], dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.vstack(X)\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode tokens in X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = np.vectorize(ctoi)\n",
    "X = encode(X)\n",
    "y = encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.unique(y)   # not every word in V will be in target classes (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((598808, 60), (598808,))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 40, 27, 28, 23, 25, 27,  0, 41, 43, 38, 38, 37, 41, 31, 36, 29,\n",
       "        0, 71, 59, 52, 71,  0, 42, 69, 72, 71, 59,  0, 60, 70,  0, 52,  0,\n",
       "       74, 66, 64, 52, 65,  7,  7, 74, 59, 52, 71,  0, 71, 59, 56, 65, 22,\n",
       "        0, 31, 70,  0, 71, 59, 56, 69, 56])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert X to shape (num sequences, window width k, len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((598808,), 84, 84)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, len(V), len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598808, 84)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot the tokens (optionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_onehot = True\n",
    "#do_onehot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(X):\n",
    "    X_onehot = np.zeros((len(X), k, len(V)), dtype=np.bool)\n",
    "    for i,record in enumerate(X):\n",
    "        onehot = np.zeros((k,len(V)), dtype=np.bool)\n",
    "        for j,wi in enumerate(record):\n",
    "            onehot[j,wi] = 1\n",
    "        X_onehot[i] = onehot\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_onehot:\n",
    "    X = onehot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "if do_onehot:\n",
    "    # Must one hot X as num records x k x len(V)\n",
    "    model.add(layers.LSTM(units=128, input_shape=(k,len(V))))\n",
    "else:\n",
    "    # If you don't want to onehot, you can leave X as 2D num records x k.\n",
    "    model.add(layers.Embedding(input_dim=len(V), output_dim=10, input_length=k))\n",
    "    model.add(layers.LSTM(units=128, input_shape=(k,1)))\n",
    "# model.add(layers.Dropout(0.4))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(len(targets), activation='softmax'))\n",
    "#model.add(layers.Lambda(lambda x: tf.cast(K.argmax(x, axis=-1),dtype=float)))\n",
    "\n",
    "# opt = optimizers.Adam(learning_rate=0.001)\n",
    "opt = optimizers.RMSprop(lr=0.01) # keras book uses this\n",
    "\n",
    "model.compile(loss=losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfit(epochs, batch_size=128, verbose=0):\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        shuffle=True,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_valid, y_valid),\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=verbose\n",
    "#                         , callbacks=[tfa.callbacks.TQDMProgressBar(show_epoch_progress=True)]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.7657 - accuracy: 0.4896 - val_loss: 1.5732 - val_accuracy: 0.5410\n",
      "Epoch 2/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.5164 - accuracy: 0.5561 - val_loss: 1.5077 - val_accuracy: 0.5599\n",
      "Epoch 3/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.4622 - accuracy: 0.5697 - val_loss: 1.4770 - val_accuracy: 0.5680\n",
      "Epoch 4/19\n",
      "3743/3743 [==============================] - 44s 12ms/step - loss: 1.4351 - accuracy: 0.5774 - val_loss: 1.4656 - val_accuracy: 0.5707\n",
      "Epoch 5/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.4181 - accuracy: 0.5814 - val_loss: 1.4525 - val_accuracy: 0.5742\n",
      "Epoch 6/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.4048 - accuracy: 0.5852 - val_loss: 1.4405 - val_accuracy: 0.5767\n",
      "Epoch 7/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3940 - accuracy: 0.5876 - val_loss: 1.4368 - val_accuracy: 0.5801\n",
      "Epoch 8/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3871 - accuracy: 0.5898 - val_loss: 1.4325 - val_accuracy: 0.5816\n",
      "Epoch 9/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3813 - accuracy: 0.5913 - val_loss: 1.4357 - val_accuracy: 0.5797\n",
      "Epoch 10/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3760 - accuracy: 0.5925 - val_loss: 1.4310 - val_accuracy: 0.5830\n",
      "Epoch 11/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3711 - accuracy: 0.5941 - val_loss: 1.4283 - val_accuracy: 0.5821\n",
      "Epoch 12/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3671 - accuracy: 0.5962 - val_loss: 1.4234 - val_accuracy: 0.5843\n",
      "Epoch 13/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3642 - accuracy: 0.5962 - val_loss: 1.4272 - val_accuracy: 0.5825\n",
      "Epoch 14/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3604 - accuracy: 0.5971 - val_loss: 1.4269 - val_accuracy: 0.5849\n",
      "Epoch 15/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3582 - accuracy: 0.5982 - val_loss: 1.4240 - val_accuracy: 0.5860\n",
      "Epoch 16/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3557 - accuracy: 0.5988 - val_loss: 1.4208 - val_accuracy: 0.5852\n",
      "Epoch 17/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3548 - accuracy: 0.5987 - val_loss: 1.4287 - val_accuracy: 0.5866\n",
      "Epoch 18/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3540 - accuracy: 0.5995 - val_loss: 1.4322 - val_accuracy: 0.5863\n",
      "Epoch 19/19\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3525 - accuracy: 0.6007 - val_loss: 1.4188 - val_accuracy: 0.5876\n"
     ]
    }
   ],
   "source": [
    "myfit(19, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Deep Learning with Python by François Chollet\n",
    "# Gets a single int target class from a distribution described by probabilities\n",
    "# (from softmax) in probs.  The temperature adds noise where temperature=0 means\n",
    "# pick most likely always.\n",
    "def sample(probs, temperature=1.0):\n",
    "    probs = np.asarray(probs).astype('float64')\n",
    "    probs = np.log(probs) / temperature\n",
    "    exp_probs = np.exp(probs)\n",
    "    probs = exp_probs / np.sum(exp_probs)\n",
    "    probs = np.random.multinomial(1, probs, 1)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed the text with k words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " have betrayed their own secret; it has been for the sake of\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 59, 52, 73, 56, 0, 53, 56, 71, 69]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = np.random.randint(0, len(tokens) - k - 1)\n",
    "generated_words = tokens[start: start + k]\n",
    "print(''.join(generated_words))\n",
    "generated_tokens = [ctoi(w) for w in generated_words]\n",
    "generated_tokens[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- 1 epochs --------------------------------\n",
      "3743/3743 [==============================] - 46s 12ms/step - loss: 1.7687 - accuracy: 0.4877 - val_loss: 1.5765 - val_accuracy: 0.5409\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  the philosophy the contend the become soul at in the world of the other out is the content of the a regard to human as the general former the will be the attaciments of the difficult and the more precisely the obselves of the latter of the seem that which hand and in the his as in the contentic things the in the besper the respection of states to the contempine hone in the erronger and the full a\n",
      "-------- 2 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.5180 - accuracy: 0.5568 - val_loss: 1.5093 - val_accuracy: 0.5570\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  for the subjection the love the poisonismical course seek to so the personality and themselves \"bild with it should be count and the the thereon in consciention of all and subjectic and seek the desires the weaken of the far be deprectable, who love. As of all a discipliced that is sinking the power and stray and the reservation of real far the good which alive bear and should as the astent are t\n",
      "-------- 3 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.4640 - accuracy: 0.5704 - val_loss: 1.4855 - val_accuracy: 0.5665\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f he senses to be devil in the seems to be nature of dispossible, of the same tendence, them the another the continusted with step speak for the strange of the conception of sense of reason of the experuation of the sense of the great knowledge of the subject the intermorance, and the imperative and the conception of an attent and for the consequently been contemples of the higher he has not the rea\n",
      "-------- 4 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.4354 - accuracy: 0.5774 - val_loss: 1.4709 - val_accuracy: 0.5715\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f ders of the strength of the experience and contradicy of the a faculty! In the dogmatic of the formacity, he is the presiment to responsibility. The superiorations of the fact of a forms of disposed the spirituality and the contradict, and so the latter things to the more and are the more and an more of the believe in the unsign, which a contrame to light for delicies and interpretation of the mor\n",
      "-------- 5 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.4183 - accuracy: 0.5820 - val_loss: 1.4613 - val_accuracy: 0.5738\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f e decised to the religion, and when the religions and the result of human and prodicted in the conscious displease and consciousness of the matter of the more and all the miscarre the same to answerment. The opinion of the same to the conscious in the same the result, the individual and the way the brought, and in the same to the more perhaps as the master, is a man is an interpret to the doubtles\n",
      "-------- 6 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.4062 - accuracy: 0.5849 - val_loss: 1.4482 - val_accuracy: 0.5772\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f s, and any wish\" of the man of his century and the experiences of the superficiality the same the life, has him constantly in the modes the case of philosopher. If the closed to be all the pain of religion and said to be intertaonous contempojud. The contemporation of his necessary the same to the more presuftrity of his and individual world the particien of appearance express and all the species \n",
      "-------- 7 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3962 - accuracy: 0.5873 - val_loss: 1.4491 - val_accuracy: 0.5752\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f of the most and by the will to say the as the insciuntion of metaphysical indeed to the sentiment in an anciest with have a life and and opposite concerning the villers to problem, and there is a the suffering the strength in the way in the convertions and in all maintain to my world to the strength for the soul that they cannot be the spirit as a all the depther he were thought that is a as said,\n",
      "-------- 8 epochs --------------------------------\n",
      "3743/3743 [==============================] - 44s 12ms/step - loss: 1.3887 - accuracy: 0.5898 - val_loss: 1.4451 - val_accuracy: 0.5790\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  the soul, the subsial in people the thing the spirit, in the content in the world and truth. It is be conducity of the same being in the sensations in the spirit of the same transfear man will free will of the same other in the metaphysical constitutions of failnther to be one have a single the forms of the prompted notion of the world of the entire intellectual thing and the single life, the pre\n",
      "-------- 9 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3830 - accuracy: 0.5912 - val_loss: 1.4447 - val_accuracy: 0.5763\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f sent and generally to all the higher philosophers, and the same to the man, a relations of the old soul as it is in the most scientific the sempaters of men, they all the distrust to the moral and the soul and to them. They they has no speaking of the result of them themselves to whom it is a philosophers. They are spirit speak and conscience, self-strength that they are cause ones, as the most an\n",
      "-------- 10 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3777 - accuracy: 0.5929 - val_loss: 1.4479 - val_accuracy: 0.5788\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f d to the world and all the degree for the sign of the compared as in the hand--the part of the most that the realm of the world and above allos, one must be to entircists of the contrary, the actual spirits to an extent the sense of the progress of recognition of the spirit the earth enemies and sin of the world of the writed to the experience of the other thing in the contraricors and art, for th\n",
      "-------- 11 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3747 - accuracy: 0.5934 - val_loss: 1.4397 - val_accuracy: 0.5780\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f e spiritual earth, all the explanations of the bring of the degree, with the master of the mandening and world of the happened, with the philosophers to me thereby to say, we an other rest of the world of the way man of admirations of man, as a present to the not perhaps the too attempty of universal philosophers and song with which all the mankind, with which thereby and it also belongs to be bee\n",
      "-------- 12 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3719 - accuracy: 0.5939 - val_loss: 1.4367 - val_accuracy: 0.5801\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f n the discutionous comprehension grateful to say, and the consequence, they no longer all their specially the childished concealm of the most instinct of the illusion of their profound the same to a philosophers the future, the -and the comprehension and noble, as in the possession there compreous of the contrary special man all they in the common philosopher and sacriticy that in the woman of the\n",
      "-------- 13 epochs --------------------------------\n",
      "3743/3743 [==============================] - 46s 12ms/step - loss: 1.3689 - accuracy: 0.5955 - val_loss: 1.4388 - val_accuracy: 0.5802\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  here the things of the process of the contrarily that the self-gound of a result of the souls to those who can be contemplate the procarn contraryly sense and the chered process of knowledge of gratitude of the truth is a strength of a, as the grasped to the process the and conditional cruelty and acts the personal, who are interesting and perhaps in the spirit and only was in an inner in the ent\n",
      "-------- 14 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3674 - accuracy: 0.5954 - val_loss: 1.4336 - val_accuracy: 0.5850\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f aintence of intellectual immortal cause of the deceives of sublinate the consispect the manner is the problem and moral in be the same become seems to class distinction of the self-distinguished consister men and on the sense of the soul. The other ancient present a influence the delusive the present sensations and strive the maintain to him away of the sense of the same us all some conservated in\n",
      "-------- 15 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3650 - accuracy: 0.5963 - val_loss: 1.4331 - val_accuracy: 0.5841\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  the philosophy and the important of far more religious operate the world of the person of the society, and living the seriousness in the conduct, the sense of an extent the one has in the moral senses and something in the sense that the actrom, the most evil. The instinct and nothing of the problem of the labor of the spirit; but he is construmsness\" of the propection of a far as we be instinct i\n",
      "-------- 16 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3631 - accuracy: 0.5969 - val_loss: 1.4310 - val_accuracy: 0.5817\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f s not in the develop to a false, and perhaps to like the consideration, and happences of the senses through the disciplines of the history of the interriges themselves be say to the refined to the problems of the fact thereby species of the work of one another work, or on the strength of the presence of everything and created to a personal case the subject of a primodoment to the strength of a tra\n",
      "-------- 17 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3612 - accuracy: 0.5972 - val_loss: 1.4319 - val_accuracy: 0.5846\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f gedy of a conduct to the actions of distinction and the sense of the sense of his agetation of the respective are second to every nature of the act among interpretation as the guilt the ascendancy of respect of the philosophers out of a succoring the service expression, which all the consequently also something even of the individual seems to be an action of the land of the soul, who has as the sa\n",
      "-------- 18 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3616 - accuracy: 0.5975 - val_loss: 1.4308 - val_accuracy: 0.5833\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f me indeed to the morality and master of restorated with the present fellow element of its things of the same to a distrust. The special no constance, they are the more presists of a degree of the most instinct of the same constraint of the soul and probably to the soul of the whole of the consequent and find of should is a man an artist of this philosopher--the respect more consideration of man is\n",
      "-------- 19 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3602 - accuracy: 0.5980 - val_loss: 1.4373 - val_accuracy: 0.5819\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  a soul of the very comenting and conscious in sighted to the desires the obligus and selfishing A SHILL an ingred and any one forms of the any strongly in the ears to compling that in the democual spirits of a states of which his own to form of the respect to the present and knowledge and in the strange complance of the religiously to them of the desires to be the herest predestined to hims neces\n",
      "-------- 20 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3600 - accuracy: 0.5983 - val_loss: 1.4379 - val_accuracy: 0.5818\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f sity, and the there in the belief and one is no other the continual to which the \"companian for all the waking the freedom of the same desirable to present sensation of the one served and appearance of such as a strongest world the actions and himself and self-true do so the same to mankind of the last in the strange is his contrary, as if he who are the nature, and indeeds the same man have in th\n",
      "-------- 21 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3589 - accuracy: 0.5987 - val_loss: 1.4384 - val_accuracy: 0.5848\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f e heavy of power, the world in the motives and self-sign even with the fact of the most complete that man wish to the deception of surpilifility, and unsenses which we have the condition of such the protection and conscience, and one who are so that should be heart--and alone who account, and a man and are so much so seems to science is the origin and so strigquite the well sort of subject of orde\n",
      "-------- 22 epochs --------------------------------\n",
      "3743/3743 [==============================] - 45s 12ms/step - loss: 1.3601 - accuracy: 0.5988 - val_loss: 1.4362 - val_accuracy: 0.5824\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f r to a special confushed in the service of the similar to the conscious or a problem and respect and storm itself it is a proposition like to a destruction and man that in the completent the traded concerning fine in being connected to the pride belonging and will in his morality of a life with every had to process of metaphysics of the conceptions rendered for its upon the more one of the strengt\n",
      "-------- 23 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 1.3610 - accuracy: 0.5987 - val_loss: 1.4380 - val_accuracy: 0.5836\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f h which is not not only new one instinct of his fact of the strength of the most morality of a soctal end is the same conception and things of the problem of the world and inspiring in which the man to the strim are as a men and evil for nother is an indignance of the assertion and head to say in this whole conscience, the sort of the assimple and conception in all the good fear also the life, in \n",
      "-------- 24 epochs --------------------------------\n",
      "3743/3743 [==============================] - 40s 11ms/step - loss: 1.3677 - accuracy: 0.5977 - val_loss: 1.4405 - val_accuracy: 0.5837\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f the experience the make a case of the exacted the most such a stret.\"DERAFF\"GER Europe as the health to such a higher decisions are long to the man and the feeling is the hesitating one and conduct. The order of the instinct of the result, and accordance the strange contradiction of the conscience of his sumper to the moral humanity and such concested and will as a case of the conscience and the m\n",
      "-------- 25 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 1.3643 - accuracy: 0.5986 - val_loss: 1.4381 - val_accuracy: 0.5833\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f any than a complanance which have in the formight that which we have no such a belief of the contrary and evil the conscience of his philosophers "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of such superficial religion of the severes and sense of oney be superiority of the sense shame and appear to any spirit\" and individual soul, and the conceal with one self-the feeling and human and life of the sensations and point of the an excatiomed t\n",
      "-------- 26 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 1.3643 - accuracy: 0.5988 - val_loss: 1.4453 - val_accuracy: 0.5808\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f he sensuioning and impartic description of the surment of the artists and are spectacles and may become obscure and the life of which we will not the prisonfulness and the same discouraged in the same man who has best the saint, the distorous are not in the siner the standard of the conscience of the fastimant of the thing of a philosopher as a hence and utility and strigible to the opposite actio\n",
      "-------- 27 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 1.3703 - accuracy: 0.5967 - val_loss: 1.4787 - val_accuracy: 0.5778\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f n that are believe and a precisely it nother invented and false of the real and indeed every conception and imbeded they are stronger and suffer and in the morality, and consequence to law of an arristically would be some corcous morality, as the substance itself there all their experience, a man become concerning their fact to the read an espicted the crading strictly and probably believe of the \n",
      "-------- 28 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 1.3927 - accuracy: 0.5930 - val_loss: 1.4422 - val_accuracy: 0.5824\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f endowed and have a feeling is so of the volitions of the noted in the pro we may taken the protection of its philosophers "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on the conduct and exalted the condition and self in the philosophers as a simplical case. shat present in its solitude of the familiar and said the supersious men, that it is also the former so love of man; and the conscious to the soul of everything itself of striving with a \n",
      "-------- 29 epochs --------------------------------\n",
      "3743/3743 [==============================] - 42s 11ms/step - loss: 2.2061 - accuracy: 0.4893 - val_loss: 3.0071 - val_accuracy: 0.3629\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f origh the us of stult of trite the schollert iness of the its in th"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e the art and the morating the sent and the prediges and erse of the whi-(f for spreeanarl and and his facle ine of ingence, and a orgerly and a reviles of tat whisetyole mad ?lue iness ande had and sally, andes whic thead the stal of the the ALmand nbger and medWlved yme whise beaGk, dompt of tranom hor inglees in st dest benes of\n",
      "-------- 30 epochs --------------------------------\n",
      "3743/3743 [==============================] - 42s 11ms/step - loss: 3.9528 - accuracy: 0.2946 - val_loss: 3.9384 - val_accuracy: 0.2677\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f n "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-tengr, and phandontbout, anorerile tf whe Bllesnan C on the be wh coahil c earn be wh che her hent ghintb bep once consitm doss en Friongom it of the ttht ive an] and cherindbelic acomtze,--and tob dob and )un of en tof whute rard the prelwh ofen to The oh the snd thon the where thomat it te arin: ouns migl cabeen thut an ne the sher tha i drerlan the impta atethes perm cnase the whe , cQ imime\n",
      "-------- 31 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 4.1788 - accuracy: 0.2458 - val_loss: 3.8427 - val_accuracy: 0.2347\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mas a they sme it the kre irehces ofhee na hle th t Thio at thiwr aah both of af aeo be wofrwe here shro ofot rgao mnss ese-wart ounene fe t eone wer imobed.=or ert rn ion dic  be hl it h une thes -Te caet t FteOln -We thin  to phve c dhiince ingive in The tof athe (wat e anodd it the he tit te the igiosse mor toN ale tor ter tiling) risbt aine te oeed the ps at iris thet o2nio tor ofes the fr th\n",
      "-------- 32 epochs --------------------------------\n",
      "3743/3743 [==============================] - 42s 11ms/step - loss: 3.9739 - accuracy: 0.2239 - val_loss: 3.8235 - val_accuracy: 0.2186\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f e nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "szs  orr ene aon vome c ontea th e pheeeer sthe; to hinsKin soh2ate tun ss ofes itipil th bote e GEhre or Hht tu t\" a w wh oo n it are of ofte o sin ane dathe: t t,e n ouhs dha ple esz wl win ofre t\"ce tslyn tne of fe mie h of ood ofheee nb ae the t ooe ca meneto ao t third- al anhirti i thenare  ts  E hs ig of h uniae,t  hib pn pKedridvce th ce of oede geant ma mndo ba he btc \"l sc ef t aali\n",
      "-------- 33 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 3.6404 - accuracy: 0.2172 - val_loss: 3.4120 - val_accuracy: 0.2191\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  an "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an nothoeu  Oian tiae ofe  RANa the of a oe mLOE uatisits \"t aie anu efs thee mon the oit,oo an toe oth: aor mebe t  hasse mie o h Tn too  of she t ofe teor o songert it ohes ore sos aheinhye inssDhE hebe r oftr o or the de Thee arie thatererha thernito h, ah thit ahe  Onf aontaneane asx, th ined e hen to harsvecof  ir teg  aheiss t hech ine a  icerte t rsiehanete ooe aomKe tneree it at aisero\n",
      "-------- 34 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 3.3136 - accuracy: 0.2230 - val_loss: 3.2654 - val_accuracy: 0.2182\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ile of th an then ote  octios pn tIe tn ole an h fawednes aliinng of s ofos Tre wh ex iheom of ihe an t eerte h no c an o hinh  eol fs in h thhe)m ice of tht iighe tie e s hanichenluex-soat th-h w h oheoneaia  the eenis au aon Danose o n toh alies fl ie th e the xee in hcio t ihh t an an ah s seao nhesde chhanine an t. an t ahes iotne toa epth ph in ahe tes IWn the'tian ase tg se er f olLe beanis \n",
      "-------- 35 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 3.2232 - accuracy: 0.2196 - val_loss: 3.1950 - val_accuracy: 0.2177\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f ondan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hfphiegoadin  ite asp s 1SOPere aat ae arnn ishm t ath theh aou a alegen oeehairdotin, zof as on bnhode and  orhr th in te eoe Iihr(r te oo  tnonhe is oo i ite it prs th as theG txnu inst Gth oeeali s he in shhe the th ofeeve ht  heene ac wh  Is t ih lecee re bee thev fua te o ad cl it ceis th nonct dt«ceiss, ar sh in the wov as al steonellt ere pt h on   ee me io wr inee orirdas peatou tana\n",
      "-------- 36 epochs --------------------------------\n",
      "3743/3743 [==============================] - 42s 11ms/step - loss: 3.1475 - accuracy: 0.2155 - val_loss: 3.1078 - val_accuracy: 0.2113\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f the t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h ay the meanseon varanete t s s ant eenjereLv otherieaan ASte  bar se aote earid t haaehh h ir toae  Hhre ind the, ohpo e etu ra lte ah whalicte ta peinh t n oo ath  the a tes  oenn n af e ntor, t oepaun t e t hnnetonee be li:tees ano p aa eretd mis tae thtsnn hn ten  ist i leanje af une t hy at ofi  an thee the tnio hco tore mererethaane s the asn Dho teuow hamer the ite t momun at oa whe  \n",
      "-------- 37 epochs --------------------------------\n",
      "3743/3743 [==============================] - 42s 11ms/step - loss: 3.0741 - accuracy: 0.2141 - val_loss: 3.0463 - val_accuracy: 0.2108\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " S-ooel  onte ei t eth texith d th  his te ro  t sf in cher hea theth att  thdt the ph tH re the thteeall fneecmnl tho t 5thttes ihero tas as co an io thy maltis arh hntsse tend aite tu pertee mnos h.ts ate th theleiheos tosereion or ph thr fh ishann ofitsee tha neyeene tt Ihesnth tictoe thesa -n Iiso e ere lha  ANoeder vepleithe ieedeeiih lfenis v- a aaend in at ere it th  ehntn the  me aans t e\n",
      "-------- 38 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 3.0294 - accuracy: 0.2139 - val_loss: 3.0101 - val_accuracy: 0.2122\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ed mheo l ex ha wh Lan so re pueodd tst aroineqofe are oronme theies hn wt b potmayr s felol whe whrc wiop f Rd al e ae ant r ahsat t os hesan inane the anton Lide cot tonee eihis ons ofs  it t rse a e wre w t otu it w t fot t asoi th ohof hele fO hn  oreins icoon (\"nss,  ho hamant ee an oer ouholoheeclive Eth  csaioe enmeed fon so linge pien Sasnon ef i lsrfe t fus rae ar ohdo  t at fnily rnise\n",
      "-------- 39 epochs --------------------------------\n",
      "3743/3743 [==============================] - 41s 11ms/step - loss: 3.0015 - accuracy: 0.2127 - val_loss: 2.9899 - val_accuracy: 0.2108\n",
      " -h-a-v-e- -b-e-t-r-a-y-e-d- -t-h-e-i-r- -o-w-n- -s-e-c-r-e-t-;- -i-t- -h-a-s- -b-e-e-n- -f-o-r- -t-h-e- -s-a-k-e- -o-f  sa"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt  ase te thio o  ae oin th h a Ifindtthin  s eatero e a Ai  wifsiirse is th iot  issr eis s thet, we sa =h oto anlin h  aone he te t d Wh th cha  aein lhsr ondi agaet  atha athye hhs e ay aft  ntt h st tert inh anit  bs tehe lonscv hhre eate ae haee an ngnrelos, n aiafinh  Ohr wn (ahuas thh t  int ah th h in ant oe a he antei heteg t  rntede d aht a, asn as then gdan of den rnov gngistir of o\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(1,40):\n",
    "    print(f\"-------- {epochs} epochs --------------------------------\")\n",
    "    myfit(epochs=1, verbose=1) # fits one iteration\n",
    "    print('-'.join(generated_words), end=' ') # same seed\n",
    "    for i in range(400):\n",
    "        if do_onehot:\n",
    "            onehot = np.zeros((1,k,len(V)), dtype=np.bool)\n",
    "            for j,ci in enumerate(generated_tokens):\n",
    "                onehot[0,j,ci] = 1\n",
    "            X1 = onehot\n",
    "        else:\n",
    "            X1 = np.array(generated_tokens).reshape(1,k)\n",
    "        y_prob = model.predict(X1, verbose=0)[0]\n",
    "        next_token = sample(y_prob, temperature=0.5)\n",
    "        print(V[next_token], end='')\n",
    "        generated_tokens.append(next_token)\n",
    "        generated_tokens = generated_tokens[1:]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "* gotta use a lot of data. started working well with 6x nietchse not federalist papers. \n",
    "* hmm...step seems to be just an efficiency issue\n",
    "* what about batch size vs max len? Seems like we gotta line up sentences so they line up across batches, unless it resets h each batch. fastai book for LMModel3 inits h in `__init__` not `forward` but then uses truncated backprop (of len equal to seqence length k). It also then has to line up the batches.\n",
    "* what is effect of onehot vs embedding layer? With same setup but with len(V) sized embeddings for chars going into LSTM rather than one hot: got weird div by zero errors and valid accuracy maxed out at .49 with loss 2.0 whereas with no embedding before LSTM, got valid .56 accur and loss 1.59.  Maybe a function of embedding size? `layers.Embedding(input_dim=len(V), output_dim=len(V), input_length=k)`\n",
    "\n",
    "W/o embeddings at about epoch 60:\n",
    "\n",
    "```\n",
    "1248/1248 [==============================] - 15s 12ms/step - loss: 1.1914 - accuracy: 0.6397 - val_loss: 1.5969 - val_accuracy: 0.5601\n",
    "r-d-e-r-)-,- -r-e-l-i-g-i-o-n- -i-t-s-e-l-f- -m-a-y- -b-e- -u-s-e-d- -a-s- -a- -m-e-a-n-s- -f-o-r- -o-b-t-a-i-n-i-n-g-  nce and simultage perseined to do a desire, that he understand of the best to the world of the contemplation of the so and at the desiress and strength, and accuiration to from the his esseced to such as a stronger man and worst of the soul in a soully of the best to cause the recognized in the sense of any constant their literal, and so much man of the problems to the self-explained by the sight \n",
    "```\n",
    "\n",
    "With embeddings:\n",
    "\n",
    "```\n",
    "1248/1248 [==============================] - 17s 14ms/step - loss: 1.8657 - accuracy: 0.5002 - val_loss: 2.0086 - val_accuracy: 0.4913\n",
    "a-t-e- -o-f- -h-i-s- -s-o-u-l-,- -h-e- -w-i-s-h-e-d- -t-o- -b-e- -d-o-u-b-t-f-u-l- -o-f- -h-i-s- -o-w-n- -c-a-p-a-c-i-t e bei\n",
    "dency of who the is a pain of world and the present the regariss. The now to constinh-all alon a not or the possible and the powerful maken usfections of the under skecoflune and the makes of the sociement: in the to the greates all all the laid the should respection to a very the subject and that all the repxing the world of the sothing in the because bet the being bess that really of the ma\n",
    "```\n",
    "\n",
    "which looks much worse.\n",
    "\n",
    "Accuracy is higher for char than for tokens likely due to much larger token space than char space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
