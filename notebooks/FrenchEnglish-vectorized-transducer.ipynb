{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation vectorized\n",
    "\n",
    "Let's do French -> English. French has multiple phrases that map to single English phrase so can't do English->French as well. E.g.,\n",
    "\n",
    "```\n",
    "Get ready.      Prépare-toi.\n",
    "Get ready.      Préparez-vous.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "import editdistance # Get Levenshtein (pip install editdistance)\n",
    "import re\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, input_size, embed_sz):\n",
    "        self.E = torch.randn(embed_sz, input_size, device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "        self.input_size = input_size\n",
    "        self.embed_sz = embed_sz\n",
    "#         with torch.no_grad():\n",
    "#             self.E *= 0.01\n",
    "    def parameters(self): return [self.E]\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, int) or (x.dim()==0 or isinstance(x, torch.Tensor) and x.dim()==1 and len(x)==1):\n",
    "            return self.E[:,x].reshape(self.embed_sz, 1)\n",
    "        # column E[i] is the embedding for char index i. same as multiple E.mm(onehot(i))\n",
    "        return self.E[:,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_sz, nhidden):\n",
    "        self.W = torch.eye(nhidden,    nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.U = torch.randn(nhidden,  input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bx = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.first_h_shape = None # debugging\n",
    "#         with torch.no_grad():\n",
    "#             self.W *= 0.01\n",
    "#             self.U *= 0.01\n",
    "    def parameters(self): return [self.W, self.U, self.bx]\n",
    "    def __call__(self, h, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        h = self.W@h + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(RNN):\n",
    "    def __init__(self, input_sz, context_sz, nhidden):\n",
    "        super().__init__(input_sz, nhidden)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        h = self.W@h + self.C@c + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, input_sz, nhidden, include_bias=False):\n",
    "        self.Whz  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whr  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whh_ = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxh_ = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxz  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxr  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        # if include_bias these stay 0\n",
    "        self.bz   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.br   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bh_  = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.include_bias = include_bias\n",
    "        self.first_h_shape = None # debugging\n",
    "    def parameters(self):\n",
    "        p = [self.Whz, self.Whr, self.Whh_, self.Uxh_, self.Uxz, self.Uxr]\n",
    "        if self.include_bias:\n",
    "            p += [self.bz, self.br, self.bh_]    \n",
    "        return p\n",
    "    def __call__(self, h, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        z = torch.sigmoid(self.Whz@h    + self.Uxz@x)#  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.Uxr@x)#  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.Uxh_@x)# + self.bh_)\n",
    "#         print(h.shape, z.shape, r.shape, h_.shape)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(GRU):\n",
    "    def __init__(self, input_sz, context_sz, nhidden, include_bias=False):\n",
    "        super().__init__(input_sz, nhidden, include_bias)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        z = torch.sigmoid(self.Whz@h    + self.C@c + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.C@c + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.C@c + self.Uxh_@x + self.bh_)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.V = torch.randn(output_size,  input_size, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.by = torch.zeros(output_size, 1,          device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.V *= 0.01\n",
    "    def parameters(self): return [self.V, self.by]\n",
    "    def __call__(self, h):\n",
    "        o = self.V@h + self.by\n",
    "        o = o.T # make it input_size x output_size\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.0, fixed=False):\n",
    "        \"If fixed, reuse same mask for all future uses of this layer.\"\n",
    "        self.p = p\n",
    "        self.fixed = fixed\n",
    "        self.mask = None\n",
    "    def __call__(self, v):\n",
    "        if self.fixed:\n",
    "            if self.mask is None:\n",
    "                usample = torch.empty_like(v).uniform_(0, 1) # get random value for each activation\n",
    "                self.mask = (usample>self.p).int()           # get mask as those with value greater than p\n",
    "            mask = self.mask\n",
    "        else:\n",
    "            usample = torch.empty_like(v).uniform_(0, 1) # get random value for each activation\n",
    "            mask = (usample>self.p).int()                # get mask as those with value greater than p\n",
    "        v = v * mask                                     # kill masked activations\n",
    "        v /= 1 - self.p                                  # scale during training by 1/(1-p) to avoid scaling by p at test time\n",
    "                                                         # after dropping p activations, (1-p) are left untouched, on average\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/eng-fra.txt\") as f:\n",
    "    text = f.read().strip().lower()\n",
    "\n",
    "# clean up, normalize\n",
    "text = re.sub(r\"[ \\u202f\\u209f\\u20bf\\u2009\\u3000\\xa0]+\", \" \", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"\\u200b|\\xad|‐|–\", \"-\", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"‘|’\", \"'\", text)  # there are lots of space chars in unicode\n",
    "text = text.replace(\"‽\", \"?\")\n",
    "text = text.replace(\"…\", \"\")\n",
    "text = text.replace(\"₂\", \"\")\n",
    "# text = text.replace(\"\\u202f\", \" \")\n",
    "# text = text.replace(\"\\u209f\", \" \")\n",
    "# text = text.replace(\"\\u20bf\", \" \")\n",
    "text = text.replace(\" !\", \"\")\n",
    "text = text.replace(\" .\", \"\")\n",
    "text = re.sub(r\"([.!?])\", \"\", text)\n",
    "lines = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line for line in lines if not len(set(line).intersection({'(',')','~','€','$','%','&','/','«','»'}))]\n",
    "pairs = [line.split('\\t') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 15\n",
    "pairs = [p for p in pairs if len(p[0])<=MAX_LENGTH and len(p[1])<=MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER = False\n",
    "if FILTER:\n",
    "    eng_prefixes = (\n",
    "        \"i am \", \"i'm \",\n",
    "        \"he is \", \"he's \",\n",
    "        \"she is \", \"she's \",\n",
    "        \"you are \", \"you're \",\n",
    "        \"we are \", \"we're \",\n",
    "        \"they are \", \"they're \"\n",
    "        )\n",
    "    filtered_pairs = []\n",
    "    for p in pairs:\n",
    "        en,fr = p\n",
    "        for pre in eng_prefixes:\n",
    "            if en.startswith(pre):\n",
    "                filtered_pairs.append(p)\n",
    "                break\n",
    "\n",
    "    pairs = filtered_pairs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[0:100] # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(p[1],p[0]) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "pairs = list(dict(pairs).items())\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set('\\n'.join(lines)))\n",
    "vocab = vocab[2:] # drop \\t and \\n\n",
    "vocab = ['<','>']+vocab # add delimiters as 0, 1\n",
    "ctoi = {c:i for i, c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<> \"\\'+,-0123456789:;abcdefghijklmnopqrstuvwxyzàâçèéêëîïòôöùúûœас'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', 'go'),\n",
       " ('cours', 'run'),\n",
       " ('courez', 'run'),\n",
       " ('ça alors', 'wow'),\n",
       " ('au feu', 'fire'),\n",
       " (\"à l'aide\", 'help'),\n",
       " ('saute', 'jump'),\n",
       " ('ça suffit', 'stop'),\n",
       " ('stop', 'stop'),\n",
       " ('arrête-toi', 'stop')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap in <...> and Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(f\"{p[0]}\",f\"<{p[1]}>\") for p in pairs]  # X doesn't need <...> brackets\n",
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0, 46,  2, 31,  4, 20, 28, 23, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 20, 40, 39, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0, 48, 20,  2, 38, 40, 25, 25, 28, 39],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 39, 34, 35],\n",
       "        [ 0,  0,  0,  0,  0, 20, 37, 37, 51, 39, 24,  7, 39, 34, 28]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numericalize and left pad\n",
    "X = torch.zeros(len(pairs), MAX_LENGTH, device=device, dtype=torch.long) # zero implies padding\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(fr)\n",
    "    for j in range(len(fr)):\n",
    "        X[i,j+pad] = ctoi[fr[j]]\n",
    "X[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 26, 34,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 42, 34, 42,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 25, 28, 37, 24,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = []\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(en)\n",
    "    Y.append([ctoi[d] for d in en]+[ctoi['>']]*pad)  # pad with \"end of string\" symbols '>'\n",
    "Y = torch.tensor(Y)\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridx = torch.randperm(len(pairs))\n",
    "# shuffle\n",
    "X = X[ridx]\n",
    "Y = Y[ridx]\n",
    "# split\n",
    "ntrain = int(0.8 * len(pairs))\n",
    "X_train, X_test = X[:ntrain], X[ntrain:]\n",
    "Y_train, Y_test = Y[:ntrain], Y[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 training records, 10 embedding size, 64 target classes, state is 300-vector\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "char_embed_sz = 10\n",
    "nhidden = 300\n",
    "nclasses = len(vocab) # char output vocab\n",
    "\n",
    "print(f\"{n:,d} training records, {char_embed_sz} embedding size, {nclasses} target classes, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostr(x):\n",
    "    s = ''.join([vocab[v] for v in x])\n",
    "    if '>' in s:\n",
    "        i = s.index('>')\n",
    "        return s[0:i+1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transducer:\n",
    "    def __init__(self, input_sz, output_sz, input_embed_sz, output_embed_sz, nhidden, \n",
    "                 dropout=0.0,\n",
    "                 useGRU=False):\n",
    "        self.dropout = dropout\n",
    "        self.embx = Embedding(input_sz, input_embed_sz)\n",
    "        self.emby = Embedding(output_sz, output_embed_sz)\n",
    "        self.lin = Linear(nhidden, output_sz)\n",
    "        if useGRU:\n",
    "            self.encoder = GRU(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderGRU(output_embed_sz, nhidden, nhidden)\n",
    "        else:\n",
    "            self.encoder = RNN(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderRNN(output_embed_sz, nhidden, nhidden)\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.embx.parameters()+\\\n",
    "               self.emby.parameters()+\\\n",
    "               self.lin.parameters()+\\\n",
    "               self.encoder.parameters()+\\\n",
    "               self.decoder.parameters()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        x_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        y_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        z_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "\n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(len(x)):\n",
    "            embedding_step_t = self.embx(x[t])\n",
    "            embedding_step_t = x_dropout(embedding_step_t)\n",
    "#             print(embedding_step_t.shape, embedding_step_t)\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        output = []\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(len(y)-1): # don't predict next char at final '>'\n",
    "            embedding_step_t = self.emby(y[t])\n",
    "            embedding_step_t = y_dropout(embedding_step_t)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            o = self.lin(h)\n",
    "#             print(embedding_step_t.shape, o.shape, torch.tensor([y[t+1]], device=device).shape)\n",
    "            o = z_dropout(o)\n",
    "            # From y we want to predict y[1:]. at y[t], predict y[t+1] using c as context vector\n",
    "            loss += F.cross_entropy(o, torch.tensor([y[t+1]], device=device), reduction=\"sum\")\n",
    "            p = F.softmax(o, dim=1)\n",
    "            y_pred = torch.argmax(p, dim=1).item()\n",
    "            correct += y_pred==y[t+1]\n",
    "            output.append(y_pred)\n",
    "        return output, loss, int(correct)\n",
    "    \n",
    "    def predict(self, x, Y_ctoi):\n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(len(x)):\n",
    "            embedding_step_t = self.embx(x[t])\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        loss = 0.0\n",
    "        output = []\n",
    "        y_pred = Y_ctoi['<'] # begin with \"start of sequence\" char\n",
    "        output.append(y_pred)\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "#         h = c\n",
    "        MAX = 20 # for safety\n",
    "        while y_pred!=Y_ctoi['>'] and len(output)<=MAX:\n",
    "            embedding_step_t = self.emby(y_pred)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            o = self.lin(h)\n",
    "            p = F.softmax(o, dim=1)\n",
    "            y_pred = torch.argmax(p, dim=1).item()\n",
    "            output.append(y_pred)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 training loss   21.189   accur  0.0069   LR 0.000001\n",
      "Epoch   2 training loss   13.028   accur  0.2361   LR 0.000167\n",
      "Epoch   3 training loss    6.534   accur  0.5347   LR 0.000334\n",
      "Epoch   4 training loss    3.273   accur  0.6716   LR 0.000500\n",
      "Epoch   5 training loss    1.583   accur  0.7897   LR 0.000334\n",
      "Epoch   6 training loss    0.978   accur  0.8671   LR 0.000167\n",
      "Epoch   7 training loss    0.785   accur  0.8948   LR 0.000001\n",
      "Epoch   8 training loss    0.773   accur  0.8968   LR 0.000084\n",
      "Epoch   9 training loss    0.677   accur  0.9038   LR 0.000167\n",
      "Epoch  10 training loss    0.530   accur  0.9266   LR 0.000251\n",
      "Epoch  11 training loss    0.377   accur  0.9514   LR 0.000167\n",
      "Epoch  12 training loss    0.305   accur  0.9623   LR 0.000084\n"
     ]
    }
   ],
   "source": [
    "trans = Transducer(input_sz=len(ctoi),\n",
    "                   output_sz=len(ctoi),\n",
    "                   input_embed_sz=char_embed_sz,\n",
    "                   output_embed_sz=char_embed_sz,\n",
    "                   nhidden=nhidden,\n",
    "                   dropout=0.0,\n",
    "                   useGRU=True)\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=0.0005, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                              mode='triangular2',\n",
    "                                              step_size_up=3,\n",
    "                                              base_lr=0.000001, max_lr=0.0005,\n",
    "                                              cycle_momentum=False)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total_compares = 0\n",
    "    for i in range(n):\n",
    "        x = X_train[i]\n",
    "        y = Y_train[i]\n",
    "#         print(f\"{tostr(x)}->{tostr(y)}\")\n",
    "        y_pred, loss, correct = trans(x, y)\n",
    "#         if epoch==10:\n",
    "#             print(f\"{tostr(x)}->{tostr(y)}: {tostr(y_pred)}, {correct} correct\")\n",
    "        epoch_training_accur += correct\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        total_compares += len(y) - 1  # From \"<foo>\" predict and count \"foo>\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_training_accur /= total_compares\n",
    "    epoch_training_loss /= total_compares\n",
    "    \n",
    "    print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:8.3f}   accur {epoch_training_accur:7.4f}   LR {scheduler.get_last_lr()[0]:7.6f}\")\n",
    "    scheduler.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    expy = torch.exp(y)\n",
    "    if len(y.shape)==1: # 1D case can't use axis arg\n",
    "        return expy / torch.sum(expy)\n",
    "    return expy / torch.sum(expy, dim=1)#.reshape(-1,1)\n",
    "\n",
    "def predict(self, x, Y_ctoi):\n",
    "    # ENCODER\n",
    "    h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "    for t in range(len(x)):\n",
    "        embedding_step_t = self.embx(x[t])\n",
    "        h = self.encoder(h, embedding_step_t)\n",
    "    c = h\n",
    "\n",
    "    # DECODER\n",
    "    loss = 0.0\n",
    "    output = []\n",
    "    y_pred = Y_ctoi['<'] # begin with \"start of sequence\" char\n",
    "    output.append(y_pred)\n",
    "    h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "    while y_pred!=Y_ctoi['>'] and len(output)<=20:\n",
    "        embedding_step_t = self.emby(y_pred)\n",
    "        h = self.decoder(h, c, embedding_step_t)\n",
    "        o = self.lin(h)\n",
    "        p = F.softmax(o, dim=1)\n",
    "        y_pred = torch.argmax(p, dim=1).item()\n",
    "        output.append(y_pred)\n",
    "    return output\n",
    "\n",
    "def check(X,Y,verbose=False):\n",
    "    \"Use Levenshtein to measure how close output predictions are to truth.\"\n",
    "    with torch.no_grad():\n",
    "        valid_accur = 0\n",
    "        total_compares = 0\n",
    "        total_correct = 0\n",
    "        total_d = 0\n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            y_pred = trans.predict(x, ctoi)\n",
    "            total_compares += len(y) - 1 # From \"<foo>\" predict \"foo>\" but don't count last '>' for metrics\n",
    "            total_correct += tostr(y)==tostr(y_pred)\n",
    "            d = editdistance.eval(tostr(y),tostr(y_pred))\n",
    "            total_d += d\n",
    "            if verbose:\n",
    "                print(f\"{tostr(x):20s} : {tostr(y)}\")\n",
    "                print(f\"{'':20s} : {tostr(y_pred):20s} Levenshtein {d} out of {len(y)}\")\n",
    "    return total_d, total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<à l'aide      : <help>\n",
      "                     : <help>               Levenshtein 0 out of 15\n",
      "<<<<soyez calme      : <be calm>\n",
      "                     : <be calm>            Levenshtein 0 out of 15\n",
      "<<je suis parti      : <i left>\n",
      "                     : <i leffalf>          Levenshtein 4 out of 15\n",
      "<<<<<<on essaye      : <we try>\n",
      "                     : <i try>              Levenshtein 2 out of 15\n",
      "<<<<<<<<<dégage      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<<fous le camp      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<<je vais bien      : <i'm ok>\n",
      "                     : <i'm ok>             Levenshtein 0 out of 15\n",
      "<soyez gentille      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<ça alors      : <wow>\n",
      "                     : <go t5 út;t>         Levenshtein 9 out of 15\n",
      "<<<<<<<<ah bon       : <really>\n",
      "                     : <really>             Levenshtein 0 out of 15\n",
      "<<<<j'ai 19 ans      : <i'm 19>\n",
      "                     : <i'm s19>            Levenshtein 1 out of 15\n",
      "<<<<<sois juste      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<<<arrête-toi      : <stop>\n",
      "                     : <i--:а1ëù-too>       Levenshtein 10 out of 15\n",
      "<<à la revoyure      : <goodbye>\n",
      "                     : <goo' oeatr>         Levenshtein 6 out of 15\n",
      "<<<<<<<<<<venez      : <come on>\n",
      "                     : <come on>            Levenshtein 0 out of 15\n",
      "<<à votre santé      : <cheers>\n",
      "                     : <cheers>             Levenshtein 0 out of 15\n",
      "<<<<<<<<<<monte      : <hop in>\n",
      "                     : <hop in>             Levenshtein 0 out of 15\n",
      "<<<<<<<compris       : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<je suis tombée      : <i fell>\n",
      "                     : <i fell>             Levenshtein 0 out of 15\n",
      "<<<<<<disparais      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<<appelez-nous      : <call us>\n",
      "                     : <call us>            Levenshtein 0 out of 15\n",
      "<<<<<<<lève-toi      : <get up>\n",
      "                     : <get up>             Levenshtein 0 out of 15\n",
      "<<<<<sois calme      : <be calm>\n",
      "                     : <be calm>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<saute      : <jump>\n",
      "                     : <be fair>            Levenshtein 7 out of 15\n",
      "<<<va doucement      : <go slow>\n",
      "                     : <go slow>            Levenshtein 0 out of 15\n",
      "<laissez tomber      : <drop it>\n",
      "                     : <go h no>            Levenshtein 6 out of 15\n",
      "soyez équitable      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<<c'est exclu      : <no way>\n",
      "                     : <go away>            Levenshtein 2 out of 15\n",
      "allez doucement      : <go slow>\n",
      "                     : <go slow>            Levenshtein 0 out of 15\n",
      "<<<<<<<attaquez      : <attack>\n",
      "                     : <attack>             Levenshtein 0 out of 15\n",
      "<<je suis tombé      : <i fell>\n",
      "                     : <i fell>             Levenshtein 0 out of 15\n",
      "<<<<<<<<<montez      : <hop in>\n",
      "                     : <hop in>             Levenshtein 0 out of 15\n",
      "<<nous gagnâmes      : <we won>\n",
      "                     : <be caweсnqg únqg únq Levenshtein 16 out of 15\n",
      "<attends un peu      : <hang on>\n",
      "                     : <hno on>             Levenshtein 2 out of 15\n",
      "<<<sois détendu      : <be cool>\n",
      "                     : <ableîtoç'lllïo>     Levenshtein 10 out of 15\n",
      "<<<<t'as capté       : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<<<<<<<<écoutez      : <listen>\n",
      "                     : <i-'ooèmo>           Levenshtein 8 out of 15\n",
      "<<<<<<<<<<ça va      : <i'm ok>\n",
      "                     : <i'm ok>             Levenshtein 0 out of 15\n",
      "<<<<<<<attendez      : <wait>\n",
      "                     : <cohe n>             Levenshtein 6 out of 15\n",
      "<<<<<<<<<<<<<va      : <go>\n",
      "                     : <go>                 Levenshtein 0 out of 15\n",
      "<<laisse tomber      : <drop it>\n",
      "                     : <go h no>            Levenshtein 6 out of 15\n",
      "<<<<<<<<je sais      : <i know>\n",
      "                     : <i wo>               Levenshtein 3 out of 15\n",
      "<<soyez gentils      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<<sors      : <get out>\n",
      "                     : <get out>            Levenshtein 0 out of 15\n",
      "<sois équitable      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<<sois gentil      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<j'essaye      : <i try>\n",
      "                     : <i try>              Levenshtein 0 out of 15\n",
      "<<<<<<<<va t'en      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<au feu      : <fire>\n",
      "                     : <go away>            Levenshtein 7 out of 15\n",
      "<<<<<<<<<<vrai       : <really>\n",
      "                     : <really>             Levenshtein 0 out of 15\n",
      "<<<je comprends      : <i see>\n",
      "                     : <i see>              Levenshtein 0 out of 15\n",
      "<<<<<<<<attends      : <wait>\n",
      "                     : <awabes>             Levenshtein 4 out of 15\n",
      "<<<<<<<<<oh non      : <oh no>\n",
      "                     : <ablï>               Levenshtein 5 out of 15\n",
      "je l'ai emporté      : <i won>\n",
      "                     : <i won>              Levenshtein 0 out of 15\n",
      "<<<en aucun cas      : <no way>\n",
      "                     : <go away>            Levenshtein 2 out of 15\n",
      "<<sois gentille      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<<compris      : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<<<<soyez juste      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<soyez calmes      : <be calm>\n",
      "                     : <be calm>            Levenshtein 0 out of 15\n",
      "<<<<<<j'ai pigé      : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<<<<<<<<<courez      : <run>\n",
      "                     : <ri---1n>            Levenshtein 5 out of 15\n",
      "<<<<<<<<attaque      : <attack>\n",
      "                     : <attack>             Levenshtein 0 out of 15\n",
      "<<<appelle-nous      : <call us>\n",
      "                     : <call us>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<pigé       : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<<<<fantastique      : <awesome>\n",
      "                     : <awesome>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<sortez      : <get out>\n",
      "                     : <get out>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<<pars      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<demande à tom      : <ask tom>\n",
      "                     : <hëzè\"l ez>          Levenshtein 9 out of 15\n",
      "soyez gentilles      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<allez      : <come on>\n",
      "                     : <come on>            Levenshtein 0 out of 15\n",
      "<<<<<<vraiment       : <really>\n",
      "                     : <really>             Levenshtein 0 out of 15\n",
      "<<<<<j'ai perdu      : <i lost>\n",
      "                     : <i lost>             Levenshtein 0 out of 15\n",
      "Training average Levenshtein score     1.81, perfect accuracy     0.69\n"
     ]
    }
   ],
   "source": [
    "total_d, total_correct = check(X_train, Y_train, verbose=True)\n",
    "print(f\"Training average Levenshtein score {total_d/len(X_train):8.2f}, perfect accuracy {total_correct/len(X_train):8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<impossible      : <no way>\n",
      "                     : <be fair>            Levenshtein 5 out of 15\n",
      "<<<<<<<<<<cours      : <run>\n",
      "                     : <beîxçqg e;t;t;t>    Levenshtein 15 out of 15\n",
      "<<allez-vous en      : <go away>\n",
      "                     : <i'm o>              Levenshtein 7 out of 15\n",
      "<<<<<<casse-toi      : <get out>\n",
      "                     : <get up>             Levenshtein 2 out of 15\n",
      "<<<<<<<<<entrez      : <come in>\n",
      "                     : <got t5ri>           Levenshtein 7 out of 15\n",
      "<je suis partie      : <i left>\n",
      "                     : <be ni>              Levenshtein 6 out of 15\n",
      "<<<<<<ça suffit      : <stop>\n",
      "                     : <r0ye2222é'<rè\"llfffa Levenshtein 20 out of 15\n",
      "<<<soyez gentil      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<viens      : <come on>\n",
      "                     : <i wo>               Levenshtein 6 out of 15\n",
      "<<<<<<<<<<merci      : <thanks>\n",
      "                     : <go  5 55555555555555 Levenshtein 20 out of 15\n",
      "<<<appellez-moi      : <call me>\n",
      "                     : <i-'o>               Levenshtein 7 out of 15\n",
      "<<<<<j'ai gagné      : <i won>\n",
      "                     : <go 'wto>            Levenshtein 5 out of 15\n",
      "<<<<<pars d'ici      : <go away>\n",
      "                     : <ri;k;qgegîx no>     Levenshtein 13 out of 15\n",
      "<<<<<<<<<<santé      : <cheers>\n",
      "                     : <cheers>             Levenshtein 0 out of 15\n",
      "<<<<appelle-moi      : <call me>\n",
      "                     : <i-'o>               Levenshtein 7 out of 15\n",
      "<<<<<<<<<<entre      : <come in>\n",
      "                     : <go oet >            Levenshtein 6 out of 15\n",
      "<<<soyez justes      : <be fair>\n",
      "                     : <be niêi;qqg ell99999 Levenshtein 16 out of 15\n",
      "<<<<<<<<<<<stop      : <stop>\n",
      "                     : <bu<u<<u<<u<<s uooh h Levenshtein 18 out of 15\n",
      "Testing average Levenshtein score     8.89, perfect accuracy     0.11\n"
     ]
    }
   ],
   "source": [
    "total_d, total_correct = check(X_test, Y_test, verbose=True)\n",
    "print(f\"Testing average Levenshtein score {total_d/len(X_test):8.2f}, perfect accuracy {total_correct/len(X_test):8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
