{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation vectorized\n",
    "\n",
    "Let's do French -> English. French has multiple phrases that map to single English phrase so can't do English->French as well. E.g.,\n",
    "\n",
    "```\n",
    "Get ready.      Prépare-toi.\n",
    "Get ready.      Préparez-vous.\n",
    "```\n",
    "\n",
    "With dropout, I get this to be about 25% accurate for exactly correct translations in 20% test set.  I consider that pretty good given the small dataset and that I'm using chars not words.  Even the imperfect ones are sometimes really close or even semantically same but lexically different. Dropout definitely seems to make a difference.  With 1000 training records, I can get to about 15% accuracy on the test set with dropout=0.5, 700 hidden, and 32 batch size. `Testing n=177 average Levenshtein score     5.76, perfect accuracy     0.14`  With 512 hidden, I can only get to about 10% accuracy on the test set.\n",
    "\n",
    "Dang!  I forgot to shuffle X,Y at each epoch.  I think this helps with the stochastic nature and might even allow a larger batch size to improve efficiency.  Hmmm... by shuffling, 700 hidden 32 batch size dropout 0.5, gives `Testing n=177 average Levenshtein score     5.76, perfect accuracy     0.13` about the same. ok, still right thing to do.\n",
    "\n",
    "RNN (vs GRU) gets `Testing n=177 average Levenshtein score     6.78, perfect accuracy     0.07` for same setup so not as good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "import editdistance # Get Levenshtein (pip install editdistance)\n",
    "import re\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, input_size, embed_sz):\n",
    "        self.E = torch.randn(embed_sz, input_size, device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "        self.input_size = input_size\n",
    "        self.embed_sz = embed_sz\n",
    "#         with torch.no_grad():\n",
    "#             self.E *= 0.01\n",
    "    def parameters(self): return [self.E]\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, int) or (x.dim()==0 or isinstance(x, torch.Tensor) and x.dim()==1 and len(x)==1):\n",
    "            batch_size = 1\n",
    "        elif isinstance(x, torch.Tensor) and x.dim()==1:\n",
    "            batch_size = x.shape[0]\n",
    "        if isinstance(x, torch.Tensor): x.dim()==1\n",
    "        \n",
    "        # column E[i] is the embedding for char index i. same as multiple E.mm(onehot(i))\n",
    "        return self.E[:,x].reshape(self.embed_sz, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_sz, nhidden):\n",
    "        self.W = torch.eye(nhidden,    nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.U = torch.randn(nhidden,  input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bx = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.W *= 0.01\n",
    "#             self.U *= 0.01\n",
    "    def parameters(self): return [self.W, self.U, self.bx]\n",
    "    def __call__(self, h, x):\n",
    "        h = self.W@h + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(RNN):\n",
    "    def __init__(self, input_sz, context_sz, nhidden):\n",
    "        super().__init__(input_sz, nhidden)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        h = self.W@h + self.C@c + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, input_sz, nhidden, include_bias=False):\n",
    "        self.Whz  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whr  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whh_ = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxh_ = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxz  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxr  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        # if include_bias these stay 0\n",
    "        self.bz   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.br   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bh_  = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.include_bias = include_bias\n",
    "    def parameters(self):\n",
    "        p = [self.Whz, self.Whr, self.Whh_, self.Uxh_, self.Uxz, self.Uxr]\n",
    "        if self.include_bias:\n",
    "            p += [self.bz, self.br, self.bh_]    \n",
    "        return p\n",
    "    def __call__(self, h, x):\n",
    "        z = torch.sigmoid(self.Whz@h    + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.Uxh_@x + self.bh_)\n",
    "#         print(h.shape, z.shape, r.shape, h_.shape)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(GRU):\n",
    "    def __init__(self, input_sz, context_sz, nhidden, include_bias=False):\n",
    "        super().__init__(input_sz, nhidden, include_bias)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        z = torch.sigmoid(self.Whz@h    + self.C@c + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.C@c + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.C@c + self.Uxh_@x + self.bh_)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.V = torch.randn(output_size,  input_size, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.by = torch.zeros(output_size, 1,          device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.V *= 0.01\n",
    "    def parameters(self): return [self.V, self.by]\n",
    "    def __call__(self, h):\n",
    "        o = self.V@h + self.by\n",
    "        o = o.T # make it input_size x output_size\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.0, fixed=False):\n",
    "        \"\"\"\n",
    "        If fixed, reuse same mask for all future uses of this layer.\n",
    "        Assumes v columns are the layer activations. If batch size is 1, then this will be a column vector.\n",
    "        Same column knockout used for each column in incoming matrix and future invocations if fixed.\n",
    "        If not fixed, different knockout mask used for each column.\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "        self.fixed = fixed\n",
    "        self.mask = None\n",
    "    def __call__(self, v):\n",
    "        return v\n",
    "        \"\"\"\n",
    "        Column(s) are activation vectors. Get a new column mask and knockout elements with\n",
    "        it for each column (unless fixed).\n",
    "        \"\"\"\n",
    "        if isinstance(v, list):\n",
    "            v = torch.tensor(v, device=device)\n",
    "\n",
    "        if self.fixed and self.mask is None:\n",
    "            mast = self.mask = (usample>self.p).int()\n",
    "\n",
    "        usample = torch.empty_like(v).uniform_(0, 1)     # get random value for each activation matrix element\n",
    "        mask = (usample>self.p).int()                    # get boolean mask as \"those with value greater than p\"\n",
    "        v = v * mask                                     # kill masked activations\n",
    "        v /= 1 - self.p                                  # scale during training by 1/(1-p) to avoid scaling by p at test time\n",
    "                                                         # after dropping p activations, (1-p) are left untouched, on average\n",
    "        return v            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., 20.],\n",
       "        [ 1., 21.],\n",
       "        [ 2., 22.],\n",
       "        [ 3., 23.],\n",
       "        [ 4., 24.],\n",
       "        [ 5., 25.],\n",
       "        [ 6., 26.],\n",
       "        [ 7., 27.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([range(8),range(20,28)], dtype=torch.float64).T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 21., 22., 23., 24., 25., 26., 27.], dtype=torch.float64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/eng-fra.txt\") as f:\n",
    "    text = f.read().strip().lower()\n",
    "\n",
    "# clean up, normalize\n",
    "text = re.sub(r\"[ \\u202f\\u209f\\u20bf\\u2009\\u3000\\xa0]+\", \" \", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"\\u200b|\\xad|‐|–\", \"-\", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"‘|’\", \"'\", text)  # there are lots of space chars in unicode\n",
    "text = text.replace(\"‽\", \"?\")\n",
    "text = text.replace(\"…\", \"\")\n",
    "text = text.replace(\"₂\", \"\")\n",
    "# text = text.replace(\"\\u202f\", \" \")\n",
    "# text = text.replace(\"\\u209f\", \" \")\n",
    "# text = text.replace(\"\\u20bf\", \" \")\n",
    "text = text.replace(\" !\", \"\")\n",
    "text = text.replace(\" .\", \"\")\n",
    "text = re.sub(r\"([.!?])\", \"\", text)\n",
    "lines = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135614"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [line for line in lines if not len(set(line).intersection({'(',')','~','€','$','%','&','/','«','»'}))]\n",
    "pairs = [line.split('\\t') for line in lines]\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9748"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 18\n",
    "pairs = [p for p in pairs if len(p[0])<=MAX_LENGTH and len(p[1])<=MAX_LENGTH]\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER = False\n",
    "if FILTER:\n",
    "    eng_prefixes = (\n",
    "        \"i am \", \"i'm \",\n",
    "        \"he is \", \"he's \",\n",
    "        \"she is \", \"she's \",\n",
    "        \"you are \", \"you're \",\n",
    "        \"we are \", \"we're \",\n",
    "        \"they are \", \"they're \"\n",
    "        )\n",
    "    filtered_pairs = []\n",
    "    for p in pairs:\n",
    "        en,fr = p\n",
    "        for pre in eng_prefixes:\n",
    "            if en.startswith(pre):\n",
    "                filtered_pairs.append(p)\n",
    "                break\n",
    "\n",
    "    pairs = filtered_pairs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[0:500] # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(p[1],p[0]) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "pairs = list(dict(pairs).items())\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set('\\n'.join(lines)))\n",
    "vocab = vocab[2:] # drop \\t and \\n\n",
    "vocab = ['<','>']+vocab # add delimiters as 0, 1\n",
    "ctoi = {c:i for i, c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<> \"\\'+,-0123456789:;abcdefghijklmnopqrstuvwxyzàâçèéêëîïòôöùúûœас'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', 'go'),\n",
       " ('cours', 'run'),\n",
       " ('courez', 'run'),\n",
       " ('ça alors', 'wow'),\n",
       " ('au feu', 'fire'),\n",
       " (\"à l'aide\", 'help'),\n",
       " ('saute', 'jump'),\n",
       " ('ça suffit', 'stop'),\n",
       " ('stop', 'stop'),\n",
       " ('arrête-toi', 'stop')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 5],\n",
       "        [1, 6],\n",
       "        [2, 7],\n",
       "        [3, 8],\n",
       "        [4, 9]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(range(5)).reshape(-1,1)\n",
    "b = torch.tensor(range(5,10)).reshape(-1,1)\n",
    "torch.cat([a,b], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap in <...> and Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(f\"{p[0]}\",f\"<{p[1]}>\") for p in pairs]  # X doesn't need <...> brackets\n",
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 46,  2, 31,  4, 20, 28, 23, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 20, 40, 39, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 48, 20,  2, 38, 40, 25, 25, 28, 39],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 39, 34, 35],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0, 20, 37, 37, 51, 39, 24,  7, 39, 34, 28]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numericalize and left pad\n",
    "X = torch.zeros(len(pairs), MAX_LENGTH, device=device, dtype=torch.long) # zero implies padding\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(fr)\n",
    "    for j in range(len(fr)):\n",
    "        X[i,j+pad] = ctoi[fr[j]]\n",
    "X[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 26, 34,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1],\n",
       "        [ 0, 42, 34, 42,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1],\n",
       "        [ 0, 25, 28, 37, 24,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1]], device='cuda:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = []\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(en) + 2 # include <...>\n",
    "    Y.append([ctoi[d] for d in en]+[ctoi['>']]*pad)  # pad with \"end of string\" symbols '>'\n",
    "Y = torch.tensor(Y, device=device)\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed_sz = 10\n",
    "nhidden = 512\n",
    "nclasses = len(vocab) # char output vocab\n",
    "batch_size = 32\n",
    "\n",
    "n = len(X)\n",
    "n = batch_size * n//batch_size\n",
    "X, Y = X[:n], Y[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "    ridx = torch.randperm(len(X))\n",
    "    X = X[ridx]\n",
    "    Y = Y[ridx]\n",
    "    return X, Y\n",
    "\n",
    "X,Y = shuffle(X,Y)\n",
    "# split\n",
    "ntrain = int(0.8 * len(X))\n",
    "X_train, X_test = X[:ntrain], X[ntrain:]\n",
    "Y_train, Y_test = Y[:ntrain], Y[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostr(x):\n",
    "    s = ''.join([vocab[v] for v in x])\n",
    "    if '>' in s:\n",
    "        i = s.index('>')\n",
    "        return s[0:i+1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transducer:\n",
    "    def __init__(self, input_sz, output_sz, input_embed_sz, output_embed_sz, nhidden, \n",
    "                 dropout=0.0,\n",
    "                 useGRU=False):\n",
    "        self.dropout = dropout\n",
    "        self.embx = Embedding(input_sz, input_embed_sz)\n",
    "        self.emby = Embedding(output_sz, output_embed_sz)\n",
    "        self.lin = Linear(nhidden, output_sz)\n",
    "        if useGRU:\n",
    "            self.encoder = GRU(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderGRU(output_embed_sz, nhidden, nhidden)\n",
    "        else:\n",
    "            self.encoder = RNN(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderRNN(output_embed_sz, nhidden, nhidden)\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.embx.parameters()+\\\n",
    "               self.emby.parameters()+\\\n",
    "               self.lin.parameters()+\\\n",
    "               self.encoder.parameters()+\\\n",
    "               self.decoder.parameters()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        encoder_h_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        decoder_h_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        \n",
    "        x_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        y_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        z_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        \n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x, device=device)\n",
    "        if isinstance(y, list):\n",
    "            y = torch.tensor(y, device=device)\n",
    "        \n",
    "        assert x.dim()==1 or x.dim()==2\n",
    "        assert y.dim()==1 or y.dim()==2\n",
    "        \n",
    "        if x.dim()==1:\n",
    "            batch_size = 1\n",
    "            x = x.reshape(1,-1)\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "        if y.dim()==1:\n",
    "            y = y.reshape(1,-1)\n",
    "            \n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(x.shape[1]):\n",
    "            embedding_step_t = self.embx(x[:,t])\n",
    "            embedding_step_t = x_dropout(embedding_step_t)\n",
    "#             print(embedding_step_t.shape, embedding_step_t)\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "            h = encoder_h_dropout(h)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        output = []\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(y.shape[1]-1): # don't predict next char at final '>'\n",
    "            embedding_step_t = self.emby(y[:,t])\n",
    "            embedding_step_t = y_dropout(embedding_step_t)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            h = decoder_h_dropout(h)\n",
    "            o = self.lin(h)\n",
    "#             print(embedding_step_t.shape, o.shape, torch.tensor([y[t+1]], device=device).shape)\n",
    "            o = z_dropout(o)\n",
    "            # From y we want to predict y[1:]. at y[t], predict y[t+1] using c as context vector\n",
    "            y_true = torch.tensor(y[:,t+1], device=device).reshape(batch_size)\n",
    "            loss += F.cross_entropy(o, y_true, reduction=\"sum\")\n",
    "            p = F.softmax(o, dim=1)\n",
    "            y_pred = torch.argmax(p, dim=1) # y_pred has prediction for each record in batch\n",
    "            correct += torch.sum(y_pred==y[:,t+1])\n",
    "            output.append(y_pred.reshape(-1,1))\n",
    "        output = torch.cat(output, dim=1) # should be batch_size by (columns(y)-1)\n",
    "        return output, loss, int(correct)\n",
    "    \n",
    "    def predict(self, x, y=None):\n",
    "        \"if y not none, compute loss, accuracy\"\n",
    "        with torch.no_grad():\n",
    "            if isinstance(x, list):\n",
    "                x = torch.tensor(x, device=device)\n",
    "\n",
    "            assert x.dim()==1 or x.dim()==2 \n",
    "\n",
    "            if x.dim()==1:\n",
    "                batch_size = 1\n",
    "                x = x.reshape(1,-1)\n",
    "            else:\n",
    "                batch_size = x.shape[0]\n",
    "\n",
    "            # ENCODER\n",
    "            h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "            for t in range(x.shape[1]):\n",
    "                embedding_step_t = self.embx(x[:,t])\n",
    "                h = self.encoder(h, embedding_step_t)\n",
    "            c = h\n",
    "\n",
    "            # DECODER\n",
    "            loss = 0.0\n",
    "            correct = 0\n",
    "            output = []\n",
    "            # y_pred is column vector starting with '<' for each record in the batch\n",
    "            y_pred = ctoi['<']\n",
    "            y_pred = torch.full(size=(batch_size,1), fill_value=y_pred, device=device, dtype=torch.long) # begin with \"start of sequence\" char\n",
    "            output.append(y_pred)\n",
    "            h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "            while len(output)<MAX_LENGTH+2: # max plus last '>' char\n",
    "                embedding_step_t = self.emby(y_pred.flatten())  # make it a list of symbols to use in embedding\n",
    "                h = self.decoder(h, c, embedding_step_t)\n",
    "                o = self.lin(h)\n",
    "                p = F.softmax(o, dim=1)\n",
    "                y_pred = torch.argmax(p, dim=1).reshape(-1,1)\n",
    "                output.append(y_pred)\n",
    "            output = torch.cat(output, dim=1) # should be batch_size by (columns(y)-1)\n",
    "        return output  \n",
    "    \n",
    "    def score(self, X_test, Y_test):\n",
    "        \"Return raw accuracy of perfect translations to total records\"\n",
    "        with torch.no_grad():\n",
    "            y_pred = trans.predict(X_test)\n",
    "            correct = 0\n",
    "            for i in range(len(X_test)):\n",
    "                correct += tostr(y_pred[i])==tostr(Y_test[i])\n",
    "    #     y_pred_real_char = torch.sum(y_pred>1)\n",
    "    #     y_real_char = torch.sum(Y_test>1)\n",
    "    #     print(torch.sum(Y_test>1))\n",
    "    #     print(y_pred)\n",
    "    #     print(Y_test)\n",
    "    #     print(y_pred==Y_test)\n",
    "        return correct/float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parrt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 TRAIN loss 41.5716 char accur 0.0085 phrase accur 0.0000    TEST accur 0.000   LR 0.000050\n",
      "Epoch   2 TRAIN loss 18.2181 char accur 0.4819 phrase accur 0.0000    TEST accur 0.000   LR 0.000367\n",
      "Epoch   3 TRAIN loss 10.6057 char accur 0.6059 phrase accur 0.0000    TEST accur 0.000   LR 0.000683\n",
      "Epoch   4 TRAIN loss  6.4077 char accur 0.6561 phrase accur 0.0000    TEST accur 0.000   LR 0.001000\n",
      "Epoch   5 TRAIN loss  4.0820 char accur 0.7007 phrase accur 0.0000    TEST accur 0.000   LR 0.000683\n",
      "Epoch   6 TRAIN loss  2.9895 char accur 0.7350 phrase accur 0.0143    TEST accur 0.000   LR 0.000367\n",
      "Epoch   7 TRAIN loss  2.5139 char accur 0.7667 phrase accur 0.0258    TEST accur 0.000   LR 0.000050\n",
      "Epoch   8 TRAIN loss  2.3453 char accur 0.7714 phrase accur 0.0344    TEST accur 0.000   LR 0.000208\n",
      "Epoch   9 TRAIN loss  2.0245 char accur 0.7865 phrase accur 0.0430    TEST accur 0.011   LR 0.000367\n",
      "Epoch  10 TRAIN loss  1.6405 char accur 0.8106 phrase accur 0.0774    TEST accur 0.057   LR 0.000525\n",
      "Epoch  11 TRAIN loss  1.2926 char accur 0.8318 phrase accur 0.0745    TEST accur 0.034   LR 0.000367\n",
      "Epoch  12 TRAIN loss  1.1004 char accur 0.8448 phrase accur 0.0974    TEST accur 0.045   LR 0.000208\n",
      "Epoch  13 TRAIN loss  0.9913 char accur 0.8609 phrase accur 0.1060    TEST accur 0.057   LR 0.000050\n",
      "Epoch  14 TRAIN loss  0.9518 char accur 0.8668 phrase accur 0.1146    TEST accur 0.057   LR 0.000129\n",
      "Epoch  15 TRAIN loss  0.8819 char accur 0.8726 phrase accur 0.1289    TEST accur 0.057   LR 0.000208\n",
      "Epoch  16 TRAIN loss  0.7848 char accur 0.8798 phrase accur 0.1719    TEST accur 0.045   LR 0.000287\n",
      "Epoch  17 TRAIN loss  0.6783 char accur 0.8934 phrase accur 0.2006    TEST accur 0.045   LR 0.000208\n",
      "Epoch  18 TRAIN loss  0.6122 char accur 0.9034 phrase accur 0.2120    TEST accur 0.045   LR 0.000129\n",
      "Epoch  19 TRAIN loss  0.5761 char accur 0.9089 phrase accur 0.2292    TEST accur 0.034   LR 0.000050\n",
      "Epoch  20 TRAIN loss  0.5597 char accur 0.9109 phrase accur 0.2436    TEST accur 0.034   LR 0.000090\n",
      "Epoch  21 TRAIN loss  0.5325 char accur 0.9128 phrase accur 0.2636    TEST accur 0.045   LR 0.000129\n",
      "Epoch  22 TRAIN loss  0.4966 char accur 0.9172 phrase accur 0.2722    TEST accur 0.068   LR 0.000169\n",
      "Epoch  23 TRAIN loss  0.4554 char accur 0.9231 phrase accur 0.2980    TEST accur 0.057   LR 0.000129\n",
      "Epoch  24 TRAIN loss  0.4265 char accur 0.9276 phrase accur 0.3152    TEST accur 0.057   LR 0.000090\n",
      "Epoch  25 TRAIN loss  0.4079 char accur 0.9299 phrase accur 0.3324    TEST accur 0.057   LR 0.000050\n",
      "Epoch  26 TRAIN loss  0.3969 char accur 0.9300 phrase accur 0.3352    TEST accur 0.057   LR 0.000070\n",
      "Epoch  27 TRAIN loss  0.3820 char accur 0.9312 phrase accur 0.3496    TEST accur 0.045   LR 0.000090\n",
      "Epoch  28 TRAIN loss  0.3639 char accur 0.9342 phrase accur 0.3754    TEST accur 0.057   LR 0.000109\n",
      "Epoch  29 TRAIN loss  0.3434 char accur 0.9375 phrase accur 0.3897    TEST accur 0.057   LR 0.000090\n",
      "Epoch  30 TRAIN loss  0.3276 char accur 0.9402 phrase accur 0.3983    TEST accur 0.057   LR 0.000070\n",
      "Epoch  31 TRAIN loss  0.3158 char accur 0.9414 phrase accur 0.4011    TEST accur 0.057   LR 0.000050\n",
      "Epoch  32 TRAIN loss  0.3073 char accur 0.9418 phrase accur 0.4097    TEST accur 0.068   LR 0.000060\n",
      "Epoch  33 TRAIN loss  0.2974 char accur 0.9427 phrase accur 0.4298    TEST accur 0.091   LR 0.000070\n",
      "Epoch  34 TRAIN loss  0.2863 char accur 0.9444 phrase accur 0.4355    TEST accur 0.091   LR 0.000080\n",
      "Epoch  35 TRAIN loss  0.2742 char accur 0.9465 phrase accur 0.4441    TEST accur 0.091   LR 0.000070\n"
     ]
    }
   ],
   "source": [
    "trans = Transducer(input_sz=len(ctoi),\n",
    "                   output_sz=len(ctoi),\n",
    "                   input_embed_sz=char_embed_sz,\n",
    "                   output_embed_sz=char_embed_sz,\n",
    "                   nhidden=nhidden,\n",
    "                   dropout=0.0,\n",
    "                   useGRU=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=0.0005, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                              mode='triangular2',\n",
    "                                              step_size_up=3,\n",
    "                                              base_lr=0.00005, max_lr=0.001,\n",
    "                                              cycle_momentum=False)\n",
    "\n",
    "history = []\n",
    "epochs = 35\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accum_accur = 0.0\n",
    "    total_compares = 0\n",
    "    X,Y = shuffle(X,Y)\n",
    "    for p in range(0, len(X_train), batch_size):  # do one epoch\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_Y = Y_train[p:p+batch_size]\n",
    "        y_pred, loss, correct = trans(batch_X, batch_Y)\n",
    "        \n",
    "#         print([tostr(y_) for y_ in y_pred])\n",
    "#         if epoch==10:\n",
    "#             print(f\"{tostr(x)}->{tostr(y)}: {tostr(y_pred)}, {correct} correct\")\n",
    "        epoch_training_accum_accur += correct\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        total_compares += batch_size * (MAX_LENGTH + 1) # For each \"<foo>\" predict and count \"foo>\" but MAX_LENGTH doesn't include <...>\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_training_accur = trans.score(X_train, Y_train)\n",
    "    epoch_test_accur = trans.score(X_test, Y_test)\n",
    "\n",
    "    epoch_training_accum_accur /= total_compares\n",
    "    epoch_training_loss /= total_compares\n",
    "    \n",
    "    print(f\"Epoch {epoch:3d} TRAIN loss {epoch_training_loss:7.4f} char accur {epoch_training_accum_accur:.4f} phrase accur {epoch_training_accur:.4f}    TEST accur {epoch_test_accur:.3f}   LR {scheduler.get_last_lr()[0]:7.6f}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<ne pleure pas : <don't cry>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<don't die>\""
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST SINGLE RECORD\n",
    "print(tostr(X_test[2]), \":\", tostr(Y_test[2]))\n",
    "y_pred = trans.predict(X_test[2], Y_test[2])\n",
    "tostr(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<watch me> == <leave me>\n",
      "<i must go> == <i must go>\n",
      "<don't die> == <don't cry>\n",
      "<i azmf> == <he's lazy>\n",
      "<i > == <go away>\n",
      "<ghotle vre> == <go ahead>\n",
      "<get up> == <calm down>\n",
      "<come ooff<re+n> == <drive on>\n",
      "<watch me> == <help me>\n",
      "<leave us> == <call us>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# TEST ALL TEST RECORDS\n",
    "y_pred = trans.predict(X_test, Y_test)\n",
    "total_correct = 0\n",
    "for i,y_ in enumerate(y_pred[0:10]):\n",
    "    total_correct += tostr(Y_test[i])==tostr(y_)\n",
    "    print(tostr(y_), \"==\", tostr(Y_test[i]))\n",
    "print(total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.498567335243553"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10227272727272728"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(X,Y,verbose=(0,1,2)):\n",
    "    \"Use Levenshtein to measure how close output predictions are to truth.\"\n",
    "    with torch.no_grad():\n",
    "        total_compares = 0\n",
    "        total_correct = 0\n",
    "        total_d = 0\n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            y_pred = trans.predict(x)\n",
    "            y_pred = y_pred[0] # only one record for now\n",
    "            total_compares += len(y) - 1 # From \"<foo>\" predict \"foo>\" but don't count last '>' for metrics\n",
    "            total_correct += tostr(y)==tostr(y_pred)\n",
    "            d = editdistance.eval(tostr(y),tostr(y_pred))\n",
    "            total_d += d\n",
    "            if verbose>0:\n",
    "                if verbose>1 or d>0:\n",
    "                    print(f\"{tostr(x):20s} : {tostr(y)}\")\n",
    "                    print(f\"{'':20s} : {tostr(y_pred):20s} Levenshtein {d} out of {len(y)}\")\n",
    "    return total_d/float(len(X)), total_correct/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training n=349 average Levenshtein score     2.88, perfect accuracy     0.50\n"
     ]
    }
   ],
   "source": [
    "avg_d, accur = check(X_train, Y_train, verbose=0)\n",
    "print(f\"Training n={len(X_train)} average Levenshtein score {avg_d:8.2f}, perfect accuracy {accur:8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<laissez-moi   : <leave me>\n",
      "                     : <watch me>           Levenshtein 5 out of 20\n",
      "<<<<<ne pleure pas   : <don't cry>\n",
      "                     : <don't die>          Levenshtein 3 out of 20\n",
      "<<il est paresseux   : <he's lazy>\n",
      "                     : <i azmf>             Levenshtein 7 out of 20\n",
      "<<<<<<<<<<<<<<pars   : <go away>\n",
      "                     : <i >                 Levenshtein 6 out of 20\n",
      "<<<<<<<<<<poursuis   : <go ahead>\n",
      "                     : <ghotle vre>         Levenshtein 8 out of 20\n",
      "<<<<<<<<<calme-toi   : <calm down>\n",
      "                     : <get up>             Levenshtein 8 out of 20\n",
      "<<<<<<<<<<<avancez   : <drive on>\n",
      "                     : <come ooff<re+n>     Levenshtein 11 out of 20\n",
      "<<<<<<<<<aidez-moi   : <help me>\n",
      "                     : <watch me>           Levenshtein 5 out of 20\n",
      "<<<<<<appelez-nous   : <call us>\n",
      "                     : <leave us>           Levenshtein 4 out of 20\n",
      "<<<<<<<<<<<sens ça   : <feel this>\n",
      "                     : <hold this>          Levenshtein 4 out of 20\n",
      "<<<<<<<<retire-toi   : <back off>\n",
      "                     : <get up>             Levenshtein 7 out of 20\n",
      "<<<<<je l'ai perdu   : <i lost it>\n",
      "                     : <tom lost>           Levenshtein 6 out of 20\n",
      "<<<<<<<<<<<<sortez   : <get out>\n",
      "                     : <hop in>             Levenshtein 6 out of 20\n",
      "<<trouve un emploi   : <get a job>\n",
      "                     : <corecwecwecwecwecwe Levenshtein 18 out of 20\n",
      "<<<<<<je vais bien   : <i am okay>\n",
      "                     : <i honee>            Levenshtein 6 out of 20\n",
      "<<<<<<<<<<grouille   : <hurry up>\n",
      "                     : <be fancke>          Levenshtein 9 out of 20\n",
      "<<<<<<<<<<<<oublie   : <forget it>\n",
      "                     : <i beg you>          Levenshtein 8 out of 20\n",
      "<<<<soyez gentille   : <be nice>\n",
      "                     : <be ifre>            Levenshtein 3 out of 20\n",
      "<<<<<<<<<<lave-toi   : <wash up>\n",
      "                     : <get up>             Levenshtein 4 out of 20\n",
      "<<<<<<<calmez-vous   : <cool down>\n",
      "                     : <hurry up>           Levenshtein 9 out of 20\n",
      "<<<<<<<<<<<<<merci   : <thanks>\n",
      "                     : < aotery>            Levenshtein 7 out of 20\n",
      "<<<<<<<<bon boulot   : <good job>\n",
      "                     : <get a alç ôofgke>   Levenshtein 13 out of 20\n",
      "<<<<amuse-toi bien   : <have fun>\n",
      "                     : <i hoer8>            Levenshtein 8 out of 20\n",
      "<<<<<<ai-je gagné    : <did i win>\n",
      "                     : <who won>            Levenshtein 6 out of 20\n",
      "<<<<<<<j'ai essayé   : <i tried>\n",
      "                     : <idhell11gg\"l\"é-+uhw Levenshtein 18 out of 20\n",
      "<<<<<<<<<<<<<<stop   : <stop>\n",
      "                     : <3o'i>               Levenshtein 4 out of 20\n",
      "<<<<<regardez-nous   : <watch us>\n",
      "                     : <leave us>           Levenshtein 5 out of 20\n",
      "<je me suis amusée   : <i had fun>\n",
      "                     : <i'm y9ou>           Levenshtein 7 out of 20\n",
      "<<<<<<<je suis bon   : <i am good>\n",
      "                     : <hang on>            Levenshtein 6 out of 20\n",
      "<allez le chercher   : <go get it>\n",
      "                     : <i mwt it>           Levenshtein 4 out of 20\n",
      "<<<<<<appelle-nous   : <call us>\n",
      "                     : <leave us>           Levenshtein 4 out of 20\n",
      "<<<<<je le promets   : <i promise>\n",
      "                     : <we,av:òt loss-art>  Levenshtein 16 out of 20\n",
      "<<<<j'en suis sûre   : <i'm sure>\n",
      "                     : <i'm azd>            Levenshtein 4 out of 20\n",
      "<<<<<<j'ai compris   : <i got it>\n",
      "                     : <got it>             Levenshtein 2 out of 20\n",
      "<<<<<<<je suis sûr   : <i am sure>\n",
      "                     : <i'm suuhfrn>        Levenshtein 6 out of 20\n",
      "<<<<<<<<arrête-toi   : <stop>\n",
      "                     : <get up>             Levenshtein 4 out of 20\n",
      "<<<<<<<dépêche-toi   : <hurry up>\n",
      "                     : <get up>             Levenshtein 5 out of 20\n",
      "<<<<<je suis mince   : <i'm thin>\n",
      "                     : <gootk>              Levenshtein 7 out of 20\n",
      "<<<<<ça fonctionne   : <it works>\n",
      "                     : <i anòt >            Levenshtein 6 out of 20\n",
      "<<<<<<il est riche   : <he's rich>\n",
      "                     : <ber\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" Levenshtein 18 out of 20\n",
      "<<<<<à la revoyure   : <goodbye>\n",
      "                     : <it's odu>           Levenshtein 8 out of 20\n",
      "<<asseyez-vous ici   : <sit here>\n",
      "                     : <i am here>          Levenshtein 4 out of 20\n",
      "<<<<<demande à tom   : <ask tom>\n",
      "                     : <stop tom>           Levenshtein 4 out of 20\n",
      "<<<<<<je l'utilise   : <i use it>\n",
      "                     : <i bumotest hou>     Levenshtein 9 out of 20\n",
      "<<<<<je vous ai vu   : <i saw you>\n",
      "                     : <i saw him>          Levenshtein 3 out of 20\n",
      "<je suis fainéante   : <i am lazy>\n",
      "                     : <i'm sad>            Levenshtein 5 out of 20\n",
      "<<<<<<<<je paierai   : <i'll pay>\n",
      "                     : <i'll thazlyb7eyyb7e Levenshtein 12 out of 20\n",
      "<<<<<<beau travail   : <good job>\n",
      "                     : <be nice>            Levenshtein 8 out of 20\n",
      "<<<allez doucement   : <go slow>\n",
      "                     : <go aly>             Levenshtein 3 out of 20\n",
      "<<<<<je suis calme   : <i am calm>\n",
      "                     : <be still>           Levenshtein 8 out of 20\n",
      "<<<<<<<<<va au lit   : <go to bed>\n",
      "                     : <go t îsò\"\"\"\">       Levenshtein 8 out of 20\n",
      "<<<<<<<<<viens ici   : <come here>\n",
      "                     : <i am here>          Levenshtein 4 out of 20\n",
      "<<<<<<<<c'est bibi   : <it's me>\n",
      "                     : <ioo'ln w111g1g1g11g Levenshtein 16 out of 20\n",
      "<<<<<<<<tenez ceci   : <hold this>\n",
      "                     : <use this>           Levenshtein 4 out of 20\n",
      "<<<<<<n'entrez pas   : <keep out>\n",
      "                     : <don't die>          Levenshtein 8 out of 20\n",
      "<<<soyez équitable   : <be fair>\n",
      "                     : <i hacke>            Levenshtein 6 out of 20\n",
      "<<<<<<tout va bien   : <i'm fine>\n",
      "                     : <i honeew >          Levenshtein 7 out of 20\n",
      "<<<<elle est venue   : <she came>\n",
      "                     : <i saway>            Levenshtein 7 out of 20\n",
      "<<<<<<j'en ai fini   : <i'm done>\n",
      "                     : <i am eeweeweeweewee Levenshtein 15 out of 20\n",
      "<<pour quoi faire    : <what for>\n",
      "                     : <am feyb5ikwelû5lhfk Levenshtein 18 out of 20\n",
      "<<<<<<<<<<<attaque   : <attack>\n",
      "                     : <fantas2 uhantce>    Levenshtein 11 out of 20\n",
      "<<<<<<<<<<il court   : <he runs>\n",
      "                     : <she runs>           Levenshtein 1 out of 20\n",
      "<<<<<<<<<il est dj   : <he's a dj>\n",
      "                     : <jaçë1ç2ë2ëëëëë1wî-- Levenshtein 19 out of 20\n",
      "<<<<<<<<<<attaquez   : <attack>\n",
      "                     : <come on>            Levenshtein 7 out of 20\n",
      "<<<<<je déteste ça   : <i hate it>\n",
      "                     : <grab this>          Levenshtein 8 out of 20\n",
      "<trouvez un emploi   : <get a job>\n",
      "                     : <corecwecwecwecwecwe Levenshtein 18 out of 20\n",
      "<<<<je suis occupé   : <i am busy>\n",
      "                     : <i goooot>           Levenshtein 7 out of 20\n",
      "<<<<<<<<<venez ici   : <come over>\n",
      "                     : <i am here>          Levenshtein 7 out of 20\n",
      "<<<<je suis restée   : <i stayed>\n",
      "                     : <i'm haddu>          Levenshtein 7 out of 20\n",
      "<<<<<<regarde-nous   : <watch us>\n",
      "                     : <leave us>           Levenshtein 5 out of 20\n",
      "<<<comment va tom    : <how's tom>\n",
      "                     : <b5âwtmwtiaòyb53âwtm Levenshtein 17 out of 20\n",
      "<<<<<<<<<vraiment    : <really>\n",
      "                     : <âooon>              Levenshtein 6 out of 20\n",
      "<<puis-je y aller    : <may i go>\n",
      "                     : <weibiïhfû5d>        Levenshtein 10 out of 20\n",
      "<<<<<<<<<je refuse   : <i refuse>\n",
      "                     : <i am law\"ty9ou>     Levenshtein 12 out of 20\n",
      "<<<<<allez-vous en   : <go away>\n",
      "                     : <heri>               Levenshtein 7 out of 20\n",
      "<<<<<<je suis repu   : <i'm full>\n",
      "                     : <g on>               Levenshtein 7 out of 20\n",
      "<<<<<<<soyez juste   : <be fair>\n",
      "                     : <iâotke>             Levenshtein 7 out of 20\n",
      "<<<<<<<appelle tom   : <call tom>\n",
      "                     : <stop tom>           Levenshtein 4 out of 20\n",
      "<j'en suis certain   : <i'm sure>\n",
      "                     : <i am wttlslet>      Levenshtein 9 out of 20\n",
      "Testing n=88 average Levenshtein score     6.97, perfect accuracy     0.10\n"
     ]
    }
   ],
   "source": [
    "avg_d, accur = check(X_test, Y_test, verbose=1)\n",
    "print(f\"Testing n={len(X_test)} average Levenshtein score {avg_d:8.2f}, perfect accuracy {accur:8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
