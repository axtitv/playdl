{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation vectorized\n",
    "\n",
    "Let's do French -> English. French has multiple phrases that map to single English phrase so can't do English->French as well. E.g.,\n",
    "\n",
    "```\n",
    "Get ready.      Prépare-toi.\n",
    "Get ready.      Préparez-vous.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "import editdistance # Get Levenshtein (pip install editdistance)\n",
    "import re\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, input_size, embed_sz):\n",
    "        self.E = torch.randn(embed_sz, input_size, device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "        self.input_size = input_size\n",
    "        self.embed_sz = embed_sz\n",
    "#         with torch.no_grad():\n",
    "#             self.E *= 0.01\n",
    "    def parameters(self): return [self.E]\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, int) or (x.dim()==0 or isinstance(x, torch.Tensor) and x.dim()==1 and len(x)==1):\n",
    "            return self.E[:,x].reshape(self.embed_sz, 1)\n",
    "        # column E[i] is the embedding for char index i. same as multiple E.mm(onehot(i))\n",
    "        return self.E[:,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_sz, nhidden):\n",
    "        self.W = torch.eye(nhidden,    nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.U = torch.randn(nhidden,  input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bx = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.first_h_shape = None # debugging\n",
    "#         with torch.no_grad():\n",
    "#             self.W *= 0.01\n",
    "#             self.U *= 0.01\n",
    "    def parameters(self): return [self.W, self.U, self.bx]\n",
    "    def __call__(self, h, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        h = self.W@h + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(RNN):\n",
    "    def __init__(self, input_sz, context_sz, nhidden):\n",
    "        super().__init__(input_sz, nhidden)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        h = self.W@h + self.C@c + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, input_sz, nhidden, include_bias=False):\n",
    "        self.Whz  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whr  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whh_ = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxh_ = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxz  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxr  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        # if include_bias these stay 0\n",
    "        self.bz   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.br   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bh_  = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.include_bias = include_bias\n",
    "        self.first_h_shape = None # debugging\n",
    "    def parameters(self):\n",
    "        p = [self.Whz, self.Whr, self.Whh_, self.Uxh_, self.Uxz, self.Uxr]\n",
    "        if self.include_bias:\n",
    "            p += [self.bz, self.br, self.bh_]    \n",
    "        return p\n",
    "    def __call__(self, h, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        z = torch.sigmoid(self.Whz@h    + self.Uxz@x)#  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.Uxr@x)#  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.Uxh_@x)# + self.bh_)\n",
    "#         print(h.shape, z.shape, r.shape, h_.shape)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(GRU):\n",
    "    def __init__(self, input_sz, context_sz, nhidden, include_bias=False):\n",
    "        super().__init__(input_sz, nhidden, include_bias)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        if self.first_h_shape is None:\n",
    "            self.first_h_shape = h.shape\n",
    "        elif self.first_h_shape != h.shape:\n",
    "            raise ValueError(f\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\")\n",
    "        z = torch.sigmoid(self.Whz@h    + self.C@c + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.C@c + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.C@c + self.Uxh_@x + self.bh_)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.V = torch.randn(output_size,  input_size, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.by = torch.zeros(output_size, 1,          device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.V *= 0.01\n",
    "    def parameters(self): return [self.V, self.by]\n",
    "    def __call__(self, h):\n",
    "        o = self.V@h + self.by\n",
    "        o = o.T # make it input_size x output_size\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.0, fixed=False):\n",
    "        \"If fixed, reuse same mask for all future uses of this layer.\"\n",
    "        self.p = p\n",
    "        self.fixed = fixed\n",
    "        self.mask = None\n",
    "    def __call__(self, v):\n",
    "        if self.fixed:\n",
    "            if self.mask is None:\n",
    "                usample = torch.empty_like(v).uniform_(0, 1) # get random value for each activation\n",
    "                self.mask = (usample>self.p).int()           # get mask as those with value greater than p\n",
    "            mask = self.mask\n",
    "        else:\n",
    "            usample = torch.empty_like(v).uniform_(0, 1) # get random value for each activation\n",
    "            mask = (usample>self.p).int()                # get mask as those with value greater than p\n",
    "        v = v * mask                                     # kill masked activations\n",
    "        v /= 1 - self.p                                  # scale during training by 1/(1-p) to avoid scaling by p at test time\n",
    "                                                         # after dropping p activations, (1-p) are left untouched, on average\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/eng-fra.txt\") as f:\n",
    "    text = f.read().strip().lower()\n",
    "\n",
    "# clean up, normalize\n",
    "text = re.sub(r\"[ \\u202f\\u209f\\u20bf\\u2009\\u3000\\xa0]+\", \" \", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"\\u200b|\\xad|‐|–\", \"-\", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"‘|’\", \"'\", text)  # there are lots of space chars in unicode\n",
    "text = text.replace(\"‽\", \"?\")\n",
    "text = text.replace(\"…\", \"\")\n",
    "text = text.replace(\"₂\", \"\")\n",
    "# text = text.replace(\"\\u202f\", \" \")\n",
    "# text = text.replace(\"\\u209f\", \" \")\n",
    "# text = text.replace(\"\\u20bf\", \" \")\n",
    "text = text.replace(\" !\", \"\")\n",
    "text = text.replace(\" .\", \"\")\n",
    "text = re.sub(r\"([.!?])\", \"\", text)\n",
    "lines = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line for line in lines if not len(set(line).intersection({'(',')','~','€','$','%','&','/','«','»'}))]\n",
    "pairs = [line.split('\\t') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 15\n",
    "pairs = [p for p in pairs if len(p[0])<=MAX_LENGTH and len(p[1])<=MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER = False\n",
    "if FILTER:\n",
    "    eng_prefixes = (\n",
    "        \"i am \", \"i'm \",\n",
    "        \"he is \", \"he's \",\n",
    "        \"she is \", \"she's \",\n",
    "        \"you are \", \"you're \",\n",
    "        \"we are \", \"we're \",\n",
    "        \"they are \", \"they're \"\n",
    "        )\n",
    "    filtered_pairs = []\n",
    "    for p in pairs:\n",
    "        en,fr = p\n",
    "        for pre in eng_prefixes:\n",
    "            if en.startswith(pre):\n",
    "                filtered_pairs.append(p)\n",
    "                break\n",
    "\n",
    "    pairs = filtered_pairs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[0:100] # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(p[1],p[0]) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "pairs = list(dict(pairs).items())\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set('\\n'.join(lines)))\n",
    "vocab = vocab[2:] # drop \\t and \\n\n",
    "vocab = ['<','>']+vocab # add delimiters as 0, 1\n",
    "ctoi = {c:i for i, c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<> \"\\'+,-0123456789:;abcdefghijklmnopqrstuvwxyzàâçèéêëîïòôöùúûœас'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', 'go'),\n",
       " ('cours', 'run'),\n",
       " ('courez', 'run'),\n",
       " ('ça alors', 'wow'),\n",
       " ('au feu', 'fire'),\n",
       " (\"à l'aide\", 'help'),\n",
       " ('saute', 'jump'),\n",
       " ('ça suffit', 'stop'),\n",
       " ('stop', 'stop'),\n",
       " ('arrête-toi', 'stop')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap in <...> and Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(f\"{p[0]}\",f\"<{p[1]}>\") for p in pairs]  # X doesn't need <...> brackets\n",
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0, 46,  2, 31,  4, 20, 28, 23, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 20, 40, 39, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0, 48, 20,  2, 38, 40, 25, 25, 28, 39],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 39, 34, 35],\n",
       "        [ 0,  0,  0,  0,  0, 20, 37, 37, 51, 39, 24,  7, 39, 34, 28]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numericalize and left pad\n",
    "X = torch.zeros(len(pairs), MAX_LENGTH, device=device, dtype=torch.long) # zero implies padding\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(fr)\n",
    "    for j in range(len(fr)):\n",
    "        X[i,j+pad] = ctoi[fr[j]]\n",
    "X[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 26, 34,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 42, 34, 42,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 25, 28, 37, 24,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = []\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(en)\n",
    "    Y.append([ctoi[d] for d in en]+[ctoi['>']]*pad)  # pad with \"end of string\" symbols '>'\n",
    "Y = torch.tensor(Y)\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridx = torch.randperm(len(pairs))\n",
    "# shuffle\n",
    "X = X[ridx]\n",
    "Y = Y[ridx]\n",
    "# split\n",
    "ntrain = int(0.8 * len(pairs))\n",
    "X_train, X_test = X[:ntrain], X[ntrain:]\n",
    "Y_train, Y_test = Y[:ntrain], Y[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 training records, 10 embedding size, 64 target classes, state is 300-vector\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "char_embed_sz = 10\n",
    "nhidden = 300\n",
    "nclasses = len(vocab) # char output vocab\n",
    "\n",
    "print(f\"{n:,d} training records, {char_embed_sz} embedding size, {nclasses} target classes, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostr(x):\n",
    "    s = ''.join([vocab[v] for v in x])\n",
    "    if '>' in s:\n",
    "        i = s.index('>')\n",
    "        return s[0:i+1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transducer:\n",
    "    def __init__(self, input_sz, output_sz, input_embed_sz, output_embed_sz, nhidden, \n",
    "                 dropout=0.0,\n",
    "                 useGRU=False):\n",
    "        self.dropout = dropout\n",
    "        self.embx = Embedding(input_sz, input_embed_sz)\n",
    "        self.emby = Embedding(output_sz, output_embed_sz)\n",
    "        self.lin = Linear(nhidden, output_sz)\n",
    "        if useGRU:\n",
    "            self.encoder = GRU(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderGRU(output_embed_sz, nhidden, nhidden)\n",
    "        else:\n",
    "            self.encoder = RNN(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderRNN(output_embed_sz, nhidden, nhidden)\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.embx.parameters()+\\\n",
    "               self.emby.parameters()+\\\n",
    "               self.lin.parameters()+\\\n",
    "               self.encoder.parameters()+\\\n",
    "               self.decoder.parameters()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        x_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        y_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        z_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "\n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(len(x)):\n",
    "            embedding_step_t = self.embx(x[t])\n",
    "#             embedding_step_t = x_dropout(embedding_step_t)\n",
    "#             print(embedding_step_t.shape, embedding_step_t)\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        output = []\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(len(y)-1): # don't predict next char at final '>'\n",
    "            embedding_step_t = self.emby(y[t])\n",
    "#             embedding_step_t = y_dropout(embedding_step_t)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            o = self.lin(h)\n",
    "#             print(embedding_step_t.shape, o.shape, torch.tensor([y[t+1]], device=device).shape)\n",
    "#             o = z_dropout(o)\n",
    "            # From y we want to predict y[1:]. at y[t], predict y[t+1] using c as context vector\n",
    "            loss += F.cross_entropy(o, torch.tensor([y[t+1]], device=device), reduction=\"sum\")\n",
    "            o = o[0]\n",
    "            p = F.softmax(o, dim=0)\n",
    "            y_pred = torch.argmax(p).item()\n",
    "            correct += y_pred==y[t+1]\n",
    "            output.append(y_pred)\n",
    "        return output, loss, int(correct)\n",
    "    \n",
    "    def predict(self, x, Y_ctoi):\n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(len(x)):\n",
    "            embedding_step_t = self.embx(x[t])\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        loss = 0.0\n",
    "        output = []\n",
    "        y_pred = Y_ctoi['<'] # begin with \"start of sequence\" char\n",
    "        output.append(y_pred)\n",
    "        h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "#         h = c\n",
    "        MAX = 20 # for safety\n",
    "        while y_pred!=Y_ctoi['>'] and len(output)<=MAX:\n",
    "            embedding_step_t = self.emby(y_pred)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            o = self.lin(h)\n",
    "            o = o[0]\n",
    "            p = F.softmax(o, dim=0)\n",
    "            y_pred = torch.argmax(p).item()\n",
    "            output.append(y_pred)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 training loss   14.065   accur  0.0605   LR 0.000001\n",
      "Epoch   2 training loss    9.682   accur  0.3839   LR 0.000167\n",
      "Epoch   3 training loss    5.915   accur  0.5704   LR 0.000334\n",
      "Epoch   4 training loss    3.233   accur  0.6657   LR 0.000500\n",
      "Epoch   5 training loss    1.601   accur  0.7708   LR 0.000334\n",
      "Epoch   6 training loss    0.994   accur  0.8373   LR 0.000167\n",
      "Epoch   7 training loss    0.794   accur  0.8750   LR 0.000001\n",
      "Epoch   8 training loss    0.775   accur  0.8770   LR 0.000084\n",
      "Epoch   9 training loss    0.661   accur  0.8938   LR 0.000167\n",
      "Epoch  10 training loss    0.491   accur  0.9167   LR 0.000251\n",
      "Epoch  11 training loss    0.324   accur  0.9435   LR 0.000167\n",
      "Epoch  12 training loss    0.249   accur  0.9613   LR 0.000084\n",
      "Epoch  13 training loss    0.219   accur  0.9673   LR 0.000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c0fee0c6f283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         print(f\"{tostr(x)}->{tostr(y)}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#         if epoch==10:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#             print(f\"{tostr(x)}->{tostr(y)}: {tostr(y_pred)}, {correct} correct\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-fc4c437ebf2d>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#             embedding_step_t = x_dropout(embedding_step_t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#             print(embedding_step_t.shape, embedding_step_t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_step_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-077a0c2815ad>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, h, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_h_shape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"hidden h vector changed shape in {self.__class__.__name__} from {self.first_h_shape} to {h.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWhz\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mh\u001b[0m    \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUxz\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#  + self.bz)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWhr\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mh\u001b[0m    \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUxr\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#  + self.br)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mh_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWhh_\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUxh_\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# + self.bh_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trans = Transducer(input_sz=len(ctoi),\n",
    "                   output_sz=len(ctoi),\n",
    "                   input_embed_sz=char_embed_sz,\n",
    "                   output_embed_sz=char_embed_sz,\n",
    "                   nhidden=nhidden,\n",
    "                   dropout=.05,\n",
    "                   useGRU=True)\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=0.0005, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                              mode='triangular2',\n",
    "                                              step_size_up=3,\n",
    "                                              base_lr=0.000001, max_lr=0.0005,\n",
    "                                              cycle_momentum=False)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total_compares = 0\n",
    "    for i in range(n):\n",
    "        x = X_train[i]\n",
    "        y = Y_train[i]\n",
    "#         print(f\"{tostr(x)}->{tostr(y)}\")\n",
    "        y_pred, loss, correct = trans(x, y)\n",
    "#         if epoch==10:\n",
    "#             print(f\"{tostr(x)}->{tostr(y)}: {tostr(y_pred)}, {correct} correct\")\n",
    "        epoch_training_accur += correct\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        total_compares += len(y) - 1  # From \"<foo>\" predict and count \"foo>\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_training_accur /= total_compares\n",
    "    epoch_training_loss /= total_compares\n",
    "    \n",
    "    print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:8.3f}   accur {epoch_training_accur:7.4f}   LR {scheduler.get_last_lr()[0]:7.6f}\")\n",
    "    scheduler.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    expy = torch.exp(y)\n",
    "    if len(y.shape)==1: # 1D case can't use axis arg\n",
    "        return expy / torch.sum(expy)\n",
    "    return expy / torch.sum(expy, dim=1)#.reshape(-1,1)\n",
    "\n",
    "def predict(self, x, Y_ctoi):\n",
    "    # ENCODER\n",
    "    h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "    for t in range(len(x)):\n",
    "        embedding_step_t = self.embx(x[t])\n",
    "        h = self.encoder(h, embedding_step_t)\n",
    "    c = h\n",
    "\n",
    "    # DECODER\n",
    "    loss = 0.0\n",
    "    output = []\n",
    "    y_pred = Y_ctoi['<'] # begin with \"start of sequence\" char\n",
    "    output.append(y_pred)\n",
    "    h = torch.zeros(nhidden, 1, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "    while y_pred!=Y_ctoi['>'] and len(output)<=20:\n",
    "        embedding_step_t = self.emby(y_pred)\n",
    "        h = self.decoder(h, c, embedding_step_t)\n",
    "        o = self.lin(h)\n",
    "        p = F.softmax(o, dim=1)\n",
    "#         p = softmax(o)\n",
    "#         print(p.sort())\n",
    "#         print(o.shape, p.shape)\n",
    "        y_pred = torch.argmax(p, dim=1).item()\n",
    "        output.append(y_pred)\n",
    "    return output\n",
    "\n",
    "def check(X,Y,verbose=False):\n",
    "    \"Use Levenshtein to measure how close output predictions are to truth.\"\n",
    "    with torch.no_grad():\n",
    "        valid_accur = 0\n",
    "        total_compares = 0\n",
    "        total_correct = 0\n",
    "        total_d = 0\n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            y_pred = predict(trans, x, ctoi)\n",
    "            total_compares += len(y) - 1 # From \"<foo>\" predict \"foo>\" but don't count last '>' for metrics\n",
    "            total_correct += tostr(y)==tostr(y_pred)\n",
    "            d = editdistance.eval(tostr(y),tostr(y_pred))\n",
    "            total_d += d\n",
    "            if verbose:\n",
    "                print(f\"{tostr(x):20s} : {tostr(y)}\")\n",
    "                print(f\"{'':20s} : {tostr(y_pred):20s} Levenshtein {d} out of {len(y)}\")\n",
    "    return total_d, total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<monte      : <hop in>\n",
      "                     : <he ue ue8wp>        Levenshtein 9 out of 15\n",
      "<<<<<<<<<<venez      : <come on>\n",
      "                     : <come on>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<courez      : <run>\n",
      "                     : <goa8wap>            Levenshtein 7 out of 15\n",
      "<<<<<<<<<<<stop      : <stop>\n",
      "                     : <i tnjfffffùsss>     Levenshtein 13 out of 15\n",
      "<<<appelez-nous      : <call us>\n",
      "                     : <call us>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<sortez      : <get out>\n",
      "                     : <get out>            Levenshtein 0 out of 15\n",
      "<<<<<<<<écoutez      : <listen>\n",
      "                     : <gòooooywe 'gbâuâuâuu Levenshtein 19 out of 15\n",
      "<<<<<j'ai perdu      : <i lost>\n",
      "                     : <i lst>              Levenshtein 1 out of 15\n",
      "<<<je vais bien      : <i'm ok>\n",
      "                     : <i'm ok>             Levenshtein 0 out of 15\n",
      "<<<<soyez calme      : <be calm>\n",
      "                     : <be calm>            Levenshtein 0 out of 15\n",
      "<<<<<<<attaquez      : <attack>\n",
      "                     : <attack>             Levenshtein 0 out of 15\n",
      "<<soyez gentils      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<au feu      : <fire>\n",
      "                     : <>                   Levenshtein 4 out of 15\n",
      "<<<<<<<<<montez      : <hop in>\n",
      "                     : <honnr\"ë,gwka<tcnn<co Levenshtein 17 out of 15\n",
      "<<<<<<casse-toi      : <get out>\n",
      "                     : <get up>             Levenshtein 2 out of 15\n",
      "<<<<<<<compris       : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<<<<soyez juste      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<merci      : <thanks>\n",
      "                     : <t>                  Levenshtein 5 out of 15\n",
      "<<<<<<<<va t'en      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<entrez      : <come in>\n",
      "                     : <come in>            Levenshtein 0 out of 15\n",
      "<<<<<impossible      : <no way>\n",
      "                     : <be fair>            Levenshtein 5 out of 15\n",
      "<<<<<sois juste      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<<<<<attendez      : <wait>\n",
      "                     : <haoo9o3w3wail>      Levenshtein 10 out of 15\n",
      "<<<<<<<<<<saute      : <jump>\n",
      "                     : <gbâlaâuâuep>        Levenshtein 9 out of 15\n",
      "<sois équitable      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<<sors      : <get out>\n",
      "                     : <get out>            Levenshtein 0 out of 15\n",
      "<<<soyez justes      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<<<arrête-toi      : <stop>\n",
      "                     : <get up>             Levenshtein 4 out of 15\n",
      "<<<appelle-nous      : <call us>\n",
      "                     : <call us>            Levenshtein 0 out of 15\n",
      "je l'ai emporté      : <i won>\n",
      "                     : <i p>                Levenshtein 3 out of 15\n",
      "<<<soyez gentil      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<vrai       : <really>\n",
      "                     : <really>             Levenshtein 0 out of 15\n",
      "<je suis tombée      : <i fell>\n",
      "                     : <i fell>             Levenshtein 0 out of 15\n",
      "<soyez gentille      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<je comprends      : <i see>\n",
      "                     : <i see>              Levenshtein 0 out of 15\n",
      "<<<<<<<<<<pigé       : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<<<<<<<<<<santé      : <cheers>\n",
      "                     : <cwoéewry\"ioéewry\"ioé Levenshtein 16 out of 15\n",
      "<<<<<<ça suffit      : <stop>\n",
      "                     : <stop>               Levenshtein 0 out of 15\n",
      "<<à la revoyure      : <goodbye>\n",
      "                     : <goodbye>            Levenshtein 0 out of 15\n",
      "<<<<<<<lève-toi      : <get up>\n",
      "                     : <get up>             Levenshtein 0 out of 15\n",
      "<<<<t'as capté       : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<<<soyez calmes      : <be calm>\n",
      "                     : <be calm>            Levenshtein 0 out of 15\n",
      "<<<fous le camp      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<allez-vous en      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<oh non      : <oh no>\n",
      "                     : <oh no>              Levenshtein 0 out of 15\n",
      "soyez gentilles      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<à votre santé      : <cheers>\n",
      "                     : <cwoéewry\"ioéewry\"ioé Levenshtein 16 out of 15\n",
      "allez doucement      : <go slow>\n",
      "                     : <go slow>            Levenshtein 0 out of 15\n",
      "<<<<fantastique      : <awesome>\n",
      "                     : <attack>             Levenshtein 6 out of 15\n",
      "<<je suis parti      : <i left>\n",
      "                     : <i left>             Levenshtein 0 out of 15\n",
      "<<<<<<<à l'aide      : <help>\n",
      "                     : <help>               Levenshtein 0 out of 15\n",
      "<<demande à tom      : <ask tom>\n",
      "                     : <tcnj7jt>            Levenshtein 7 out of 15\n",
      "<<laisse tomber      : <drop it>\n",
      "                     : <ioo9ooo9ooéwp>      Levenshtein 12 out of 15\n",
      "<<<<<<<<<<<<<va      : <go>\n",
      "                     : <>                   Levenshtein 2 out of 15\n",
      "<<<<<<disparais      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "<<<en aucun cas      : <no way>\n",
      "                     : <no way>             Levenshtein 0 out of 15\n",
      "<<<<<<j'ai pigé      : <got it>\n",
      "                     : <got it>             Levenshtein 0 out of 15\n",
      "<<<<<<<ça alors      : <wow>\n",
      "                     : <get out>            Levenshtein 6 out of 15\n",
      "<<<<<<<<ah bon       : <really>\n",
      "                     : <really>             Levenshtein 0 out of 15\n",
      "<<<<<<vraiment       : <really>\n",
      "                     : <go it>              Levenshtein 6 out of 15\n",
      "<<<appellez-moi      : <call me>\n",
      "                     : <call me>            Levenshtein 0 out of 15\n",
      "<<<<<<<<je sais      : <i know>\n",
      "                     : <i know>             Levenshtein 0 out of 15\n",
      "<<<<j'ai 19 ans      : <i'm 19>\n",
      "                     : <i'm 19>             Levenshtein 0 out of 15\n",
      "<<<<<<on essaye      : <we try>\n",
      "                     : <we try>             Levenshtein 0 out of 15\n",
      "<<<<<<<<attaque      : <attack>\n",
      "                     : <attack>             Levenshtein 0 out of 15\n",
      "<<<sois détendu      : <be cool>\n",
      "                     : <i oo;tûoywap>       Levenshtein 10 out of 15\n",
      "<attends un peu      : <hang on>\n",
      "                     : <hang on>            Levenshtein 0 out of 15\n",
      "<<<<<<<j'essaye      : <i try>\n",
      "                     : <we try>             Levenshtein 2 out of 15\n",
      "<<nous gagnâmes      : <we won>\n",
      "                     : <we won>             Levenshtein 0 out of 15\n",
      "<<<va doucement      : <go slow>\n",
      "                     : <go slow>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<cours      : <run>\n",
      "                     : <nrk\"\"1o>            Levenshtein 6 out of 15\n",
      "<<<<<pars d'ici      : <go away>\n",
      "                     : <go away>            Levenshtein 0 out of 15\n",
      "Training average Levenshtein score     2.74, perfect accuracy     0.65\n"
     ]
    }
   ],
   "source": [
    "total_d, total_correct = check(X_train, Y_train, verbose=True)\n",
    "print(f\"Training average Levenshtein score {total_d/len(X_train):8.2f}, perfect accuracy {total_correct/len(X_train):8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<ça va      : <i'm ok>\n",
      "                     : <>                   Levenshtein 6 out of 15\n",
      "<<<<sois gentil      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<laissez tomber      : <drop it>\n",
      "                     : <ioo4tûwk2iôooooooooo Levenshtein 18 out of 15\n",
      "<<<<<<<<<<<pars      : <go away>\n",
      "                     : <get out>            Levenshtein 6 out of 15\n",
      "<<<<<sois calme      : <be calm>\n",
      "                     : <be calm>            Levenshtein 0 out of 15\n",
      "<<sois gentille      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "<<<<<<<<compris      : <got it>\n",
      "                     : <go away>            Levenshtein 5 out of 15\n",
      "<je suis partie      : <i left>\n",
      "                     : <go awadadadadadadada Levenshtein 19 out of 15\n",
      "<<<<c'est exclu      : <no way>\n",
      "                     : <haoo9oéw3 k8oéw3 œ5d Levenshtein 17 out of 15\n",
      "<<<<<<<<<<entre      : <come in>\n",
      "                     : <gooewp>             Levenshtein 5 out of 15\n",
      "<<<<appelle-moi      : <call me>\n",
      "                     : <call me>            Levenshtein 0 out of 15\n",
      "<<<<<<<<<<allez      : <come on>\n",
      "                     : <com in>             Levenshtein 2 out of 15\n",
      "<<<<<<<<<<viens      : <come on>\n",
      "                     : <iwo>                Levenshtein 6 out of 15\n",
      "<<je suis tombé      : <i fell>\n",
      "                     : <ioé4clq\"\"\"сçzuuuuòòw Levenshtein 18 out of 15\n",
      "soyez équitable      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<<<<<j'ai gagné      : <i won>\n",
      "                     : <clq\"\"hgse>          Levenshtein 9 out of 15\n",
      "<<<<<<<<attends      : <wait>\n",
      "                     : <i see>              Levenshtein 5 out of 15\n",
      "<<<<<<<<<dégage      : <go away>\n",
      "                     : <we trywp>           Levenshtein 7 out of 15\n",
      "Testing average Levenshtein score     6.83, perfect accuracy     0.28\n"
     ]
    }
   ],
   "source": [
    "total_d, total_correct = check(X_test, Y_test, verbose=True)\n",
    "print(f\"Testing average Levenshtein score {total_d/len(X_test):8.2f}, perfect accuracy {total_correct/len(X_test):8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
