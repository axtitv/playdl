{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation vectorized\n",
    "\n",
    "Let's do French -> English. French has multiple phrases that map to single English phrase so can't do English->French as well. E.g.,\n",
    "\n",
    "```\n",
    "Get ready.      Prépare-toi.\n",
    "Get ready.      Préparez-vous.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "import editdistance # Get Levenshtein (pip install editdistance)\n",
    "import re\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, input_size, embed_sz):\n",
    "        self.E = torch.randn(embed_sz, input_size, device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "        self.input_size = input_size\n",
    "        self.embed_sz = embed_sz\n",
    "#         with torch.no_grad():\n",
    "#             self.E *= 0.01\n",
    "    def parameters(self): return [self.E]\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, int) or (x.dim()==0 or isinstance(x, torch.Tensor) and x.dim()==1 and len(x)==1):\n",
    "            batch_size = 1\n",
    "        elif isinstance(x, torch.Tensor) and x.dim()==1:\n",
    "            batch_size = x.shape[0]\n",
    "        else:\n",
    "            batch_size = x.shape[1]\n",
    "        # column E[i] is the embedding for char index i. same as multiple E.mm(onehot(i))\n",
    "        return self.E[:,x].reshape(self.embed_sz, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_sz, nhidden):\n",
    "        self.W = torch.eye(nhidden,    nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.U = torch.randn(nhidden,  input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bx = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.W *= 0.01\n",
    "#             self.U *= 0.01\n",
    "    def parameters(self): return [self.W, self.U, self.bx]\n",
    "    def __call__(self, h, x):\n",
    "        h = self.W@h + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(RNN):\n",
    "    def __init__(self, input_sz, context_sz, nhidden):\n",
    "        super().__init__(input_sz, nhidden)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        h = self.W@h + self.C@c + self.U@x + self.bx\n",
    "        h = torch.tanh(h)\n",
    "        return h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, input_sz, nhidden, include_bias=False):\n",
    "        self.Whz  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whr  = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Whh_ = torch.eye(nhidden,   nhidden,  device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxh_ = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxz  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.Uxr  = torch.randn(nhidden, input_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        # if include_bias these stay 0\n",
    "        self.bz   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.br   = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.bh_  = torch.zeros(nhidden, 1,        device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.include_bias = include_bias\n",
    "    def parameters(self):\n",
    "        p = [self.Whz, self.Whr, self.Whh_, self.Uxh_, self.Uxz, self.Uxr]\n",
    "        if self.include_bias:\n",
    "            p += [self.bz, self.br, self.bh_]    \n",
    "        return p\n",
    "    def __call__(self, h, x):\n",
    "        z = torch.sigmoid(self.Whz@h    + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.Uxh_@x + self.bh_)\n",
    "#         print(h.shape, z.shape, r.shape, h_.shape)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(GRU):\n",
    "    def __init__(self, input_sz, context_sz, nhidden, include_bias=False):\n",
    "        super().__init__(input_sz, nhidden, include_bias)\n",
    "        self.C = torch.eye(nhidden,    context_sz, device=device, dtype=torch.float64, requires_grad=True)\n",
    "    def parameters(self): return super().parameters()+[self.C]\n",
    "    def __call__(self, h, c, x):\n",
    "        z = torch.sigmoid(self.Whz@h    + self.C@c + self.Uxz@x  + self.bz)\n",
    "        r = torch.sigmoid(self.Whr@h    + self.C@c + self.Uxr@x  + self.br)\n",
    "        h_ = torch.tanh(self.Whh_@(r*h) + self.C@c + self.Uxh_@x + self.bh_)\n",
    "        h = torch.tanh( (1-z)*h + z*h_ )\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.V = torch.randn(output_size,  input_size, device=device, dtype=torch.float64, requires_grad=True)\n",
    "        self.by = torch.zeros(output_size, 1,          device=device, dtype=torch.float64, requires_grad=True)\n",
    "#         with torch.no_grad():\n",
    "#             self.V *= 0.01\n",
    "    def parameters(self): return [self.V, self.by]\n",
    "    def __call__(self, h):\n",
    "        o = self.V@h + self.by\n",
    "        o = o.T # make it input_size x output_size\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.0, fixed=False):\n",
    "        \"If fixed, reuse same mask for all future uses of this layer.\"\n",
    "        self.p = p\n",
    "        self.fixed = fixed\n",
    "        self.mask = None\n",
    "    def __call__(self, v):\n",
    "        if self.fixed:\n",
    "            if self.mask is None:\n",
    "                usample = torch.empty_like(v).uniform_(0, 1) # get random value for each activation\n",
    "                self.mask = (usample>self.p).int()           # get mask as those with value greater than p\n",
    "            mask = self.mask\n",
    "        else:\n",
    "            usample = torch.empty_like(v).uniform_(0, 1) # get random value for each activation\n",
    "            mask = (usample>self.p).int()                # get mask as those with value greater than p\n",
    "        v = v * mask                                     # kill masked activations\n",
    "        v /= 1 - self.p                                  # scale during training by 1/(1-p) to avoid scaling by p at test time\n",
    "                                                         # after dropping p activations, (1-p) are left untouched, on average\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/eng-fra.txt\") as f:\n",
    "    text = f.read().strip().lower()\n",
    "\n",
    "# clean up, normalize\n",
    "text = re.sub(r\"[ \\u202f\\u209f\\u20bf\\u2009\\u3000\\xa0]+\", \" \", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"\\u200b|\\xad|‐|–\", \"-\", text)  # there are lots of space chars in unicode\n",
    "text = re.sub(r\"‘|’\", \"'\", text)  # there are lots of space chars in unicode\n",
    "text = text.replace(\"‽\", \"?\")\n",
    "text = text.replace(\"…\", \"\")\n",
    "text = text.replace(\"₂\", \"\")\n",
    "# text = text.replace(\"\\u202f\", \" \")\n",
    "# text = text.replace(\"\\u209f\", \" \")\n",
    "# text = text.replace(\"\\u20bf\", \" \")\n",
    "text = text.replace(\" !\", \"\")\n",
    "text = text.replace(\" .\", \"\")\n",
    "text = re.sub(r\"([.!?])\", \"\", text)\n",
    "lines = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line for line in lines if not len(set(line).intersection({'(',')','~','€','$','%','&','/','«','»'}))]\n",
    "pairs = [line.split('\\t') for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 15\n",
    "pairs = [p for p in pairs if len(p[0])<=MAX_LENGTH and len(p[1])<=MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER = False\n",
    "if FILTER:\n",
    "    eng_prefixes = (\n",
    "        \"i am \", \"i'm \",\n",
    "        \"he is \", \"he's \",\n",
    "        \"she is \", \"she's \",\n",
    "        \"you are \", \"you're \",\n",
    "        \"we are \", \"we're \",\n",
    "        \"they are \", \"they're \"\n",
    "        )\n",
    "    filtered_pairs = []\n",
    "    for p in pairs:\n",
    "        en,fr = p\n",
    "        for pre in eng_prefixes:\n",
    "            if en.startswith(pre):\n",
    "                filtered_pairs.append(p)\n",
    "                break\n",
    "\n",
    "    pairs = filtered_pairs            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs[0:1000] # testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(p[1],p[0]) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "pairs = list(dict(pairs).items())\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set('\\n'.join(lines)))\n",
    "vocab = vocab[2:] # drop \\t and \\n\n",
    "vocab = ['<','>']+vocab # add delimiters as 0, 1\n",
    "ctoi = {c:i for i, c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<> \"\\'+,-0123456789:;abcdefghijklmnopqrstuvwxyzàâçèéêëîïòôöùúûœас'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', 'go'),\n",
       " ('cours', 'run'),\n",
       " ('courez', 'run'),\n",
       " ('ça alors', 'wow'),\n",
       " ('au feu', 'fire'),\n",
       " (\"à l'aide\", 'help'),\n",
       " ('saute', 'jump'),\n",
       " ('ça suffit', 'stop'),\n",
       " ('stop', 'stop'),\n",
       " ('arrête-toi', 'stop')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap in <...> and Numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = [(f\"{p[0]}\",f\"<{p[1]}>\") for p in pairs]  # X doesn't need <...> brackets\n",
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('va', '<go>'),\n",
       " ('cours', '<run>'),\n",
       " ('courez', '<run>'),\n",
       " ('ça alors', '<wow>'),\n",
       " ('au feu', '<fire>')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0, 46,  2, 31,  4, 20, 28, 23, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 20, 40, 39, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0, 48, 20,  2, 38, 40, 25, 25, 28, 39],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 38, 39, 34, 35],\n",
       "        [ 0,  0,  0,  0,  0, 20, 37, 37, 51, 39, 24,  7, 39, 34, 28]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numericalize and left pad\n",
    "X = torch.zeros(len(pairs), MAX_LENGTH, device=device, dtype=torch.long) # zero implies padding\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(fr)\n",
    "    for j in range(len(fr)):\n",
    "        X[i,j+pad] = ctoi[fr[j]]\n",
    "X[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 26, 34,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 37, 40, 33,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 42, 34, 42,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 0, 25, 28, 37, 24,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = []\n",
    "for i,p in enumerate(pairs):\n",
    "    fr, en = p\n",
    "    pad = MAX_LENGTH - len(en)\n",
    "    Y.append([ctoi[d] for d in en]+[ctoi['>']]*pad)  # pad with \"end of string\" symbols '>'\n",
    "Y = torch.tensor(Y)\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridx = torch.randperm(len(pairs))\n",
    "# shuffle\n",
    "X = X[ridx]\n",
    "Y = Y[ridx]\n",
    "# split\n",
    "ntrain = int(0.8 * len(pairs))\n",
    "X_train, X_test = X[:ntrain], X[ntrain:]\n",
    "Y_train, Y_test = Y[:ntrain], Y[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 training records, 10 embedding size, 64 target classes, state is 300-vector\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "char_embed_sz = 10\n",
    "nhidden = 300\n",
    "nclasses = len(vocab) # char output vocab\n",
    "\n",
    "print(f\"{n:,d} training records, {char_embed_sz} embedding size, {nclasses} target classes, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostr(x):\n",
    "    s = ''.join([vocab[v] for v in x])\n",
    "    if '>' in s:\n",
    "        i = s.index('>')\n",
    "        return s[0:i+1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transducer:\n",
    "    def __init__(self, input_sz, output_sz, input_embed_sz, output_embed_sz, nhidden, \n",
    "                 dropout=0.0,\n",
    "                 useGRU=False):\n",
    "        self.dropout = dropout\n",
    "        self.embx = Embedding(input_sz, input_embed_sz)\n",
    "        self.emby = Embedding(output_sz, output_embed_sz)\n",
    "        self.lin = Linear(nhidden, output_sz)\n",
    "        if useGRU:\n",
    "            self.encoder = GRU(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderGRU(output_embed_sz, nhidden, nhidden)\n",
    "        else:\n",
    "            self.encoder = RNN(input_embed_sz, nhidden)\n",
    "            self.decoder = DecoderRNN(output_embed_sz, nhidden, nhidden)\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.embx.parameters()+\\\n",
    "               self.emby.parameters()+\\\n",
    "               self.lin.parameters()+\\\n",
    "               self.encoder.parameters()+\\\n",
    "               self.decoder.parameters()\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        x_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        y_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        z_dropout = Dropout(p=self.dropout, fixed=True)\n",
    "        \n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x)\n",
    "        if isinstance(y, list):\n",
    "            y = torch.tensor(y)\n",
    "        \n",
    "        assert x.dim()==1 or x.dim()==2\n",
    "        assert y.dim()==1 or y.dim()==2\n",
    "        \n",
    "        if x.dim()==1:\n",
    "            batch_size = 1\n",
    "            x = x.reshape(1,-1)\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "        if y.dim()==1:\n",
    "            y = y.reshape(1,-1)\n",
    "            \n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(x.shape[1]):\n",
    "            embedding_step_t = self.embx(x[:,t])\n",
    "            embedding_step_t = x_dropout(embedding_step_t)\n",
    "#             print(embedding_step_t.shape, embedding_step_t)\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        output = []\n",
    "        loss = 0.0\n",
    "        correct = 0\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(y.shape[1]-1): # don't predict next char at final '>'\n",
    "            embedding_step_t = self.emby(y[:,t])\n",
    "            embedding_step_t = y_dropout(embedding_step_t)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            o = self.lin(h)\n",
    "#             print(embedding_step_t.shape, o.shape, torch.tensor([y[t+1]], device=device).shape)\n",
    "            o = z_dropout(o)\n",
    "            # From y we want to predict y[1:]. at y[t], predict y[t+1] using c as context vector\n",
    "            y_true = torch.tensor(y[:,t+1], device=device).reshape(batch_size)\n",
    "            loss += F.cross_entropy(o, y_true, reduction=\"sum\")\n",
    "            p = F.softmax(o, dim=1)\n",
    "            y_pred = torch.argmax(p, dim=1)#.item()\n",
    "            correct += torch.sum(y_pred==y[:,t+1])\n",
    "            output.append(y_pred)\n",
    "        return output, loss, int(correct)\n",
    "    \n",
    "    def predict(self, x, Y_ctoi):\n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x)\n",
    "\n",
    "        assert x.dim()==1 or x.dim()==2\n",
    "        \n",
    "        if x.dim()==1:\n",
    "            batch_size = 1\n",
    "            x = x.reshape(1,-1)\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "            \n",
    "        # ENCODER\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        for t in range(x.shape[1]):\n",
    "            embedding_step_t = self.embx(x[:,t])\n",
    "            h = self.encoder(h, embedding_step_t)\n",
    "        c = h\n",
    "\n",
    "        # DECODER\n",
    "        loss = 0.0\n",
    "        output = []\n",
    "        y_pred = Y_ctoi['<'] # begin with \"start of sequence\" char\n",
    "        output.append(y_pred)\n",
    "        h = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)  # reset hidden state at start of record\n",
    "        MAX = 20 # for safety\n",
    "        while y_pred!=Y_ctoi['>'] and len(output)<=MAX:\n",
    "            embedding_step_t = self.emby(y_pred)\n",
    "            h = self.decoder(h, c, embedding_step_t)\n",
    "            o = self.lin(h)\n",
    "            p = F.softmax(o, dim=1)\n",
    "            y_pred = torch.argmax(p, dim=1).item()\n",
    "            output.append(y_pred)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 training loss   12.778   accur  0.2021   LR 0.000100\n",
      "Epoch   2 training loss    6.284   accur  0.3746   LR 0.000400\n",
      "Epoch   3 training loss    2.952   accur  0.4960   LR 0.000700\n",
      "Epoch   4 training loss    1.727   accur  0.5919   LR 0.001000\n",
      "Epoch   5 training loss    1.114   accur  0.6803   LR 0.000700\n",
      "Epoch   6 training loss    0.834   accur  0.7344   LR 0.000400\n",
      "Epoch   7 training loss    0.694   accur  0.7700   LR 0.000100\n",
      "Epoch   8 training loss    0.670   accur  0.7750   LR 0.000250\n",
      "Epoch   9 training loss    0.620   accur  0.7821   LR 0.000400\n",
      "Epoch  10 training loss    0.550   accur  0.8035   LR 0.000550\n",
      "Epoch  11 training loss    0.448   accur  0.8291   LR 0.000400\n",
      "Epoch  12 training loss    0.382   accur  0.8477   LR 0.000250\n",
      "Epoch  13 training loss    0.341   accur  0.8638   LR 0.000100\n",
      "Epoch  14 training loss    0.331   accur  0.8636   LR 0.000175\n",
      "Epoch  15 training loss    0.317   accur  0.8675   LR 0.000250\n",
      "Epoch  16 training loss    0.296   accur  0.8728   LR 0.000325\n",
      "Epoch  17 training loss    0.263   accur  0.8814   LR 0.000250\n",
      "Epoch  18 training loss    0.238   accur  0.8890   LR 0.000175\n",
      "Epoch  19 training loss    0.219   accur  0.8971   LR 0.000100\n",
      "Epoch  20 training loss    0.214   accur  0.8973   LR 0.000137\n",
      "Epoch  21 training loss    0.206   accur  0.8976   LR 0.000175\n",
      "Epoch  22 training loss    0.197   accur  0.8989   LR 0.000213\n",
      "Epoch  23 training loss    0.182   accur  0.9028   LR 0.000175\n",
      "Epoch  24 training loss    0.170   accur  0.9067   LR 0.000137\n",
      "Epoch  25 training loss    0.160   accur  0.9100   LR 0.000100\n",
      "Epoch  26 training loss    0.156   accur  0.9107   LR 0.000119\n",
      "Epoch  27 training loss    0.151   accur  0.9119   LR 0.000137\n",
      "Epoch  28 training loss    0.146   accur  0.9131   LR 0.000156\n",
      "Epoch  29 training loss    0.138   accur  0.9150   LR 0.000137\n",
      "Epoch  30 training loss    0.131   accur  0.9167   LR 0.000119\n"
     ]
    }
   ],
   "source": [
    "trans = Transducer(input_sz=len(ctoi),\n",
    "                   output_sz=len(ctoi),\n",
    "                   input_embed_sz=char_embed_sz,\n",
    "                   output_embed_sz=char_embed_sz,\n",
    "                   nhidden=nhidden,\n",
    "                   dropout=0.0,\n",
    "                   useGRU=True)\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=0.0005, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                              mode='triangular2',\n",
    "                                              step_size_up=3,\n",
    "                                              base_lr=0.0001, max_lr=0.001,\n",
    "                                              cycle_momentum=False)\n",
    "\n",
    "history = []\n",
    "batch_size = 10\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs+1):\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total_compares = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        batch_X = X[p:p+batch_size]\n",
    "        batch_Y = Y[p:p+batch_size]\n",
    "        y_pred, loss, correct = trans(batch_X, batch_Y)\n",
    "#         if epoch==10:\n",
    "#             print(f\"{tostr(x)}->{tostr(y)}: {tostr(y_pred)}, {correct} correct\")\n",
    "        epoch_training_accur += correct\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "        total_compares += batch_size * MAX_LENGTH - 1 # For each \"<foo>\" predict and count \"foo>\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_training_accur /= total_compares\n",
    "    epoch_training_loss /= total_compares\n",
    "    \n",
    "    print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:8.3f}   accur {epoch_training_accur:7.4f}   LR {scheduler.get_last_lr()[0]:7.6f}\")\n",
    "    scheduler.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(X,Y,verbose=False):\n",
    "    \"Use Levenshtein to measure how close output predictions are to truth.\"\n",
    "    with torch.no_grad():\n",
    "        valid_accur = 0\n",
    "        total_compares = 0\n",
    "        total_correct = 0\n",
    "        total_d = 0\n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            y_pred = trans.predict(x, ctoi)\n",
    "            total_compares += len(y) - 1 # From \"<foo>\" predict \"foo>\" but don't count last '>' for metrics\n",
    "            total_correct += tostr(y)==tostr(y_pred)\n",
    "            d = editdistance.eval(tostr(y),tostr(y_pred))\n",
    "            total_d += d\n",
    "            if verbose:\n",
    "                print(f\"{tostr(x):20s} : {tostr(y)}\")\n",
    "                print(f\"{'':20s} : {tostr(y_pred):20s} Levenshtein {d} out of {len(y)}\")\n",
    "    return total_d, total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training average Levenshtein score     1.87, perfect accuracy     0.70\n"
     ]
    }
   ],
   "source": [
    "total_d, total_correct = check(X_train, Y_train, verbose=False)\n",
    "print(f\"Training average Levenshtein score {total_d/len(X_train):8.2f}, perfect accuracy {total_correct/len(X_train):8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<c'est fait      : <it's done>\n",
      "                     : <it's done>          Levenshtein 0 out of 15\n",
      "<<<<<<je t'aime      : <i love you>\n",
      "                     : <i love you>         Levenshtein 0 out of 15\n",
      "<<<<<<dites-moi      : <tell me>\n",
      "                     : <tell me>            Levenshtein 0 out of 15\n",
      "<<<<<tom a aidé      : <tom helped>\n",
      "                     : <tom helped>         Levenshtein 0 out of 15\n",
      "<<fais-moi rire      : <humor me>\n",
      "                     : <humor me>           Levenshtein 0 out of 15\n",
      "je dois y aller      : <i must go>\n",
      "                     : <i must go>          Levenshtein 0 out of 15\n",
      "<<<<<<<j'essaye      : <i try>\n",
      "                     : <i try>              Levenshtein 0 out of 15\n",
      "<<<<<j'entrerai      : <i'll go in>\n",
      "                     : <i'll work>          Levenshtein 4 out of 15\n",
      "<<c'est gratuit      : <it's free>\n",
      "                     : <i sad n'kied>       Levenshtein 9 out of 15\n",
      "<<<<<<lâche-moi      : <let me go>\n",
      "                     : <call me>            Levenshtein 7 out of 15\n",
      "<je les ai vues      : <i saw them>\n",
      "                     : <i saw you>          Levenshtein 4 out of 15\n",
      "<<c'est bizarre      : <that's odd>\n",
      "                     : <he's drunng>        Levenshtein 9 out of 15\n",
      "<<<<<<<tom aida      : <tom helped>\n",
      "                     : <tom hured>          Levenshtein 3 out of 15\n",
      "<<<<<je me tire      : <i'm going>\n",
      "                     : <i can read>         Levenshtein 9 out of 15\n",
      "<<<<suivez-nous      : <follow us>\n",
      "                     : <leave us>           Levenshtein 6 out of 15\n",
      "<<<<<<<<bien vu      : <well done>\n",
      "                     : <i saw him>          Levenshtein 9 out of 15\n",
      "<<<<<<vraiment       : <no kidding>\n",
      "                     : <seriously>          Levenshtein 9 out of 15\n",
      "<j'en suis sûre      : <i'm sure>\n",
      "                     : <i caleak>           Levenshtein 7 out of 15\n",
      "<<<<reste mince      : <stay thin>\n",
      "                     : <i his win>          Levenshtein 7 out of 15\n",
      "<<<<<<<<<<monte      : <hop in>\n",
      "                     : <be careful>         Levenshtein 10 out of 15\n",
      "je suis normale      : <i'm normal>\n",
      "                     : <i'm carme>          Levenshtein 4 out of 15\n",
      "j'étais occupée      : <i was busy>\n",
      "                     : <i hate it>          Levenshtein 7 out of 15\n",
      "<<<je suis soûl      : <i'm drunk>\n",
      "                     : <he's drunk>         Levenshtein 3 out of 15\n",
      "<<<est-ce cela       : <is that it>\n",
      "                     : <i he is it>         Levenshtein 6 out of 15\n",
      "<<<<<mais ouais      : <of course>\n",
      "                     : <i knew it>          Levenshtein 9 out of 15\n",
      "<<restez baissé      : <stay down>\n",
      "                     : <i broke it>         Levenshtein 10 out of 15\n",
      "<je peux sauter      : <i can jump>\n",
      "                     : <i can sing>         Levenshtein 4 out of 15\n",
      "<je suis désolé      : <i am sorry>\n",
      "                     : <i'm sorry>          Levenshtein 2 out of 15\n",
      "<<<<<<<<je pars      : <i'm going>\n",
      "                     : <go away>            Levenshtein 8 out of 15\n",
      "<<<qui a gagné       : <who won>\n",
      "                     : <i he did i win>     Levenshtein 10 out of 15\n",
      "<<<<j'ai raison      : <i am right>\n",
      "                     : <i'm good>           Levenshtein 7 out of 15\n",
      "<<ce n'est rien      : <no problem>\n",
      "                     : <he's workis>        Levenshtein 10 out of 15\n",
      "venez chez nous      : <come over>\n",
      "                     : <come over>          Levenshtein 0 out of 15\n",
      "<je suis humble      : <i'm humble>\n",
      "                     : <it's als wet>       Levenshtein 8 out of 15\n",
      "<<<préviens tom      : <warn tom>\n",
      "                     : <i love tom>         Levenshtein 6 out of 15\n",
      "<<<<<<<à l'aide      : <help>\n",
      "                     : <i help him>         Levenshtein 6 out of 15\n",
      "<<<<<jouis vite      : <come quick>\n",
      "                     : <i en up>            Levenshtein 8 out of 15\n",
      "<qui a fait ça       : <who did it>\n",
      "                     : <who lied it>        Levenshtein 2 out of 15\n",
      "<<<<attends ici      : <wait here>\n",
      "                     : <i am here>          Levenshtein 4 out of 15\n",
      "<<<<<<<<reculez      : <stand back>\n",
      "                     : <run in>             Levenshtein 8 out of 15\n",
      "<<<<<<<ralentis      : <slow down>\n",
      "                     : <be careft>          Levenshtein 9 out of 15\n",
      "je suis content      : <i'm glad>\n",
      "                     : <tom's glad>         Levenshtein 4 out of 15\n",
      "<<<il est riche      : <he's rich>\n",
      "                     : <he's wiles>         Levenshtein 4 out of 15\n",
      "<c'est plus sûr      : <it's safer>\n",
      "                     : <i am sure>          Levenshtein 6 out of 15\n",
      "<<<<<<discutons      : <let's talk>\n",
      "                     : <we'll wait>         Levenshtein 7 out of 15\n",
      "<<<<<vérifie ça      : <check this>\n",
      "                     : <i hate it>          Levenshtein 8 out of 15\n",
      "je suis reposée      : <i'm rested>\n",
      "                     : <i am sorres>        Levenshtein 7 out of 15\n",
      "<elles nagèrent      : <they swam>\n",
      "                     : <they won>           Levenshtein 3 out of 15\n",
      "<<<ils nagèrent      : <they swam>\n",
      "                     : <they won>           Levenshtein 3 out of 15\n",
      "<<<échauffe-toi      : <loosen up>\n",
      "                     : <get ready>          Levenshtein 9 out of 15\n",
      "<<<il fait nuit      : <it's night>\n",
      "                     : <i'm ined>           Levenshtein 6 out of 15\n",
      "<<<restez calme      : <stay calm>\n",
      "                     : <be still>           Levenshtein 8 out of 15\n",
      "<elle est venue      : <she came>\n",
      "                     : <tom's famoe>        Levenshtein 7 out of 15\n",
      "<<<tu commences      : <you start>\n",
      "                     : <we won>             Levenshtein 8 out of 15\n",
      "<<<je vous veux      : <i want you>\n",
      "                     : <i want it>          Levenshtein 3 out of 15\n",
      "<<<<<<je te vis      : <i saw you>\n",
      "                     : <i saw them>         Levenshtein 4 out of 15\n",
      "<<<<tom a gagné      : <tom won>\n",
      "                     : <they won>           Levenshtein 3 out of 15\n",
      "<<<<<je paierai      : <i'll pay>\n",
      "                     : <i'll check>         Levenshtein 5 out of 15\n",
      "<<je suis prête      : <i'm ready>\n",
      "                     : <it's dead>          Levenshtein 4 out of 15\n",
      "<<détendez-vous      : <just relax>\n",
      "                     : <stand back>         Levenshtein 9 out of 15\n",
      "<c'est gratuit       : <is it free>\n",
      "                     : <who died it>        Levenshtein 10 out of 15\n",
      "<<<<<<<<je paie      : <i'm buying>\n",
      "                     : <i like him>         Levenshtein 9 out of 15\n",
      "<<<<<tom partit      : <tom's left>\n",
      "                     : <tom's freft>        Levenshtein 2 out of 15\n",
      "<je suis revenu      : <i'm back>\n",
      "                     : <tom came>           Levenshtein 5 out of 15\n",
      "<<<<<<je vivrai      : <i'll live>\n",
      "                     : <i'll here>          Levenshtein 3 out of 15\n",
      "<<<<tom tricote      : <tom knits>\n",
      "                     : <i'm stick>          Levenshtein 6 out of 15\n",
      "<<<<sois gentil      : <be nice>\n",
      "                     : <be nice>            Levenshtein 0 out of 15\n",
      "nous le voulons      : <we want it>\n",
      "                     : <let's go>           Levenshtein 8 out of 15\n",
      "<<<<tom soupira      : <tom sighed>\n",
      "                     : <i fio>              Levenshtein 8 out of 15\n",
      "<<me trompé-je       : <am i wrong>\n",
      "                     : <what is>            Levenshtein 9 out of 15\n",
      "<<<<dépêche-toi      : <hurry up>\n",
      "                     : <get down>           Levenshtein 8 out of 15\n",
      "<<<je suis prêt      : <i am ready>\n",
      "                     : <it's ready>         Levenshtein 3 out of 15\n",
      "<<<<<je te veux      : <i want you>\n",
      "                     : <i want it>          Levenshtein 3 out of 15\n",
      "<<<<<<prends ça      : <take this>\n",
      "                     : <i hate it>          Levenshtein 7 out of 15\n",
      "<je suis chauve      : <i'm bald>\n",
      "                     : <i heres>            Levenshtein 7 out of 15\n",
      "<<<<j'ai du pot      : <i'm lucky>\n",
      "                     : <i don't da0>        Levenshtein 10 out of 15\n",
      "<sois équitable      : <be fair>\n",
      "                     : <be fair>            Levenshtein 0 out of 15\n",
      "<maman pleurait      : <mama cried>\n",
      "                     : <she cried>          Levenshtein 4 out of 15\n",
      "je me sens seul      : <i'm lonely>\n",
      "                     : <i'm alone>          Levenshtein 3 out of 15\n",
      "<viens chez moi      : <come over>\n",
      "                     : <come over>          Levenshtein 0 out of 15\n",
      "<<<<<<<descends      : <get down>\n",
      "                     : <wait>               Levenshtein 8 out of 15\n",
      "elles ont menti      : <they lied>\n",
      "                     : <they lied>          Levenshtein 0 out of 15\n",
      "<<<<<<joli coup      : <nice shot>\n",
      "                     : <i'm gog>            Levenshtein 6 out of 15\n",
      "<<c'est le tien      : <it's yours>\n",
      "                     : <that a boy>         Levenshtein 9 out of 15\n",
      "<<<<<<<tom boit      : <tom drinks>\n",
      "                     : <tom down>           Levenshtein 4 out of 15\n",
      "<<j'accepterais      : <i'd accept>\n",
      "                     : <i'd leave>          Levenshtein 6 out of 15\n",
      "<<<<<<<<<<<stop      : <stop>\n",
      "                     : <go away>            Levenshtein 7 out of 15\n",
      "<<<<soyez juste      : <be fair>\n",
      "                     : <i head>             Levenshtein 6 out of 15\n",
      "<<<je suis armé      : <i'm armed>\n",
      "                     : <i am hutp>          Levenshtein 7 out of 15\n",
      "puis-je rester       : <can i stay>\n",
      "                     : <am i clear>         Levenshtein 6 out of 15\n",
      "tom est heureux      : <tom's glad>\n",
      "                     : <i want it>          Levenshtein 10 out of 15\n",
      "<<<<<arrête-toi      : <stop>\n",
      "                     : <stand back>         Levenshtein 8 out of 15\n",
      "<<<embrasse-moi      : <kiss me>\n",
      "                     : <leave me>           Levenshtein 5 out of 15\n",
      "<<<<<<sauve-toi      : <run for it>\n",
      "                     : <get up>             Levenshtein 9 out of 15\n",
      "je suis occupée      : <i'm busy>\n",
      "                     : <i am buerpkeil>     Levenshtein 9 out of 15\n",
      "<<<<je me meurs      : <i'm dying>\n",
      "                     : <shut up>            Levenshtein 9 out of 15\n",
      "<je l'aime bien      : <i like him>\n",
      "                     : <i like you>         Levenshtein 3 out of 15\n",
      "<<<<laisse-nous      : <leave us>\n",
      "                     : <leave us>           Levenshtein 0 out of 15\n",
      "ils sont tombés      : <they fell>\n",
      "                     : <i promed>           Levenshtein 8 out of 15\n",
      "<<<<<<<<<recule      : <back off>\n",
      "                     : <try it us>          Levenshtein 9 out of 15\n",
      "<<<<<<je rigole      : <i'm joking>\n",
      "                     : <i'm cli>            Levenshtein 5 out of 15\n",
      "<<<<<<<<<<vrai       : <really>\n",
      "                     : <is it true>         Levenshtein 10 out of 15\n",
      "<<<<<<descendez      : <get down>\n",
      "                     : <come over>          Levenshtein 8 out of 15\n",
      "<<<<<<venez ici      : <come over>\n",
      "                     : <here he me>         Levenshtein 8 out of 15\n",
      "<<<venez à nous      : <come to us>\n",
      "                     : <come over>          Levenshtein 4 out of 15\n",
      "<<<je comprends      : <i see>\n",
      "                     : <wait>               Levenshtein 5 out of 15\n",
      "<<<<assieds-toi      : <be seated>\n",
      "                     : <shut up>            Levenshtein 8 out of 15\n",
      "<<<<<<<<écoutez      : <listen>\n",
      "                     : <get out>            Levenshtein 7 out of 15\n",
      "<<<<<<j'imagine      : <i guess so>\n",
      "                     : <i was his>          Levenshtein 7 out of 15\n",
      "<<<<<essayez-en      : <try some>\n",
      "                     : <choome oake an>     Levenshtein 12 out of 15\n",
      "<<c'est le sien      : <that's his>\n",
      "                     : <that a boy>         Levenshtein 5 out of 15\n",
      "<<<<aucune idée      : <beats me>\n",
      "                     : <i'm him>            Levenshtein 7 out of 15\n",
      "<<<<<ignore tom      : <ignore tom>\n",
      "                     : <i love tom>         Levenshtein 3 out of 15\n",
      "<<sans problème      : <no problem>\n",
      "                     : <no problem>         Levenshtein 0 out of 15\n",
      "<attends un peu      : <wait a bit>\n",
      "                     : <hang on>            Levenshtein 8 out of 15\n",
      "<<<attendez ici      : <wait here>\n",
      "                     : <here he me>         Levenshtein 6 out of 15\n",
      "<<<<<<j'obéirai      : <i'll obey>\n",
      "                     : <i'll dowtgry>       Levenshtein 5 out of 15\n",
      "<<<tu as essayé      : <you tried>\n",
      "                     : <i tried it>         Levenshtein 6 out of 15\n",
      "<<<<<écarte-toi      : <step aside>\n",
      "                     : <stand back>         Levenshtein 8 out of 15\n",
      "nous essayerons      : <we'll try>\n",
      "                     : <we'll wait>         Levenshtein 4 out of 15\n",
      "<<ils gagnèrent      : <they won>\n",
      "                     : <they won>           Levenshtein 0 out of 15\n",
      "<<<<j'ai oublié      : <i forgot>\n",
      "                     : <i bbledy>           Levenshtein 6 out of 15\n",
      "<<<<tom est ici      : <tom's here>\n",
      "                     : <here he is>         Levenshtein 8 out of 15\n",
      "<<prenez un bus      : <take a bus>\n",
      "                     : <i saw you>          Levenshtein 9 out of 15\n",
      "<<<<<<suis-nous      : <follow us>\n",
      "                     : <leave us>           Levenshtein 6 out of 15\n",
      "<<<<je les vois      : <i see them>\n",
      "                     : <i saw you>          Levenshtein 6 out of 15\n",
      "<<<j'en veux un      : <i want one>\n",
      "                     : <i saw one>          Levenshtein 3 out of 15\n",
      "c'est du boulot      : <it's work>\n",
      "                     : <good job>           Levenshtein 7 out of 15\n",
      "<il est mouillé      : <he's wet>\n",
      "                     : <i'm wet>            Levenshtein 3 out of 15\n",
      "est-ce éloigné       : <is it far>\n",
      "                     : <i he did i win>     Levenshtein 10 out of 15\n",
      "<<<<ne mens pas      : <don't lie>\n",
      "                     : <don't die>          Levenshtein 1 out of 15\n",
      "<<<<<<<<<oh non      : <oh no>\n",
      "                     : <i saw one>          Levenshtein 7 out of 15\n",
      "<<je suis parti      : <i left>\n",
      "                     : <i left>             Levenshtein 0 out of 15\n",
      "je l'ai réparée      : <i fixed it>\n",
      "                     : <i carmed>           Levenshtein 7 out of 15\n",
      "<<<<tom conduit      : <tom drives>\n",
      "                     : <we're dy>           Levenshtein 9 out of 15\n",
      "<<ne pleure pas      : <don't cry>\n",
      "                     : <don't move>         Levenshtein 4 out of 15\n",
      "<<<<stoppez tom      : <stop tom>\n",
      "                     : <call tom>           Levenshtein 4 out of 15\n",
      "<<<<c'est exclu      : <no way>\n",
      "                     : <he surunis>         Levenshtein 9 out of 15\n",
      "<<je suis tombé      : <i fell>\n",
      "                     : <i fino>             Levenshtein 3 out of 15\n",
      "<<<<j'abandonne      : <i give up>\n",
      "                     : <i was good>         Levenshtein 8 out of 15\n",
      "<<<<<<<<<<<file      : <run for it>\n",
      "                     : <i upk it>           Levenshtein 6 out of 15\n",
      "<<<je chanterai      : <i'll sing>\n",
      "                     : <i'll walk>          Levenshtein 4 out of 15\n",
      "<<<<<<ça compte      : <it matters>\n",
      "                     : <i phoê bead>        Levenshtein 9 out of 15\n",
      "<<n'attends pas      : <don't wait>\n",
      "                     : <don't die>          Levenshtein 3 out of 15\n",
      "<<c'est du joli      : <how nice>\n",
      "                     : <i'm down>           Levenshtein 7 out of 15\n",
      "<<je suis saoul      : <i'm loaded>\n",
      "                     : <i'm alon>           Levenshtein 5 out of 15\n",
      "<<je les ai vus      : <i saw them>\n",
      "                     : <i saw you>          Levenshtein 4 out of 15\n",
      "<<<sois sérieux      : <be serious>\n",
      "                     : <i mean it>          Levenshtein 8 out of 15\n",
      "<<je suis à toi      : <i'm yours>\n",
      "                     : <i said yet>         Levenshtein 9 out of 15\n",
      "<<<<<il est tôt      : <it's early>\n",
      "                     : <come soo>           Levenshtein 9 out of 15\n",
      "<<<<je suis fou      : <i'm crazy>\n",
      "                     : <i'm fire>           Levenshtein 5 out of 15\n",
      "<nous sommes là      : <we're here>\n",
      "                     : <wait here>          Levenshtein 4 out of 15\n",
      "salut, les mecs      : <hi, guys>\n",
      "                     : <we tham>            Levenshtein 7 out of 15\n",
      "<<<c'est mignon      : <it's sweet>\n",
      "                     : <i saw hitù>         Levenshtein 8 out of 15\n",
      "<choisis-en une      : <choose one>\n",
      "                     : <i have one>         Levenshtein 5 out of 15\n",
      "<<c'est affreux      : <it's awful>\n",
      "                     : <be serious>         Levenshtein 8 out of 15\n",
      "<<<il a à faire      : <he is busy>\n",
      "                     : <i chead>            Levenshtein 9 out of 15\n",
      "<<je sais nager      : <i can swim>\n",
      "                     : <i can sure>         Levenshtein 3 out of 15\n",
      "<espèce d'idiot      : <you idiot>\n",
      "                     : <get done>           Levenshtein 7 out of 15\n",
      "<<j'en suis sûr      : <i'm sure>\n",
      "                     : <i am sure>          Levenshtein 2 out of 15\n",
      "<<<je suis fort      : <i'm strong>\n",
      "                     : <i'm sp>             Levenshtein 5 out of 15\n",
      "<<<toi, conduis      : <you drive>\n",
      "                     : <i usee>             Levenshtein 7 out of 15\n",
      "<<<<<oubliez-le      : <forget him>\n",
      "                     : <follow him>         Levenshtein 4 out of 15\n",
      "<<je vous envie      : <i envy you>\n",
      "                     : <i envy him>         Levenshtein 3 out of 15\n",
      "<<tom est sourd      : <tom's deaf>\n",
      "                     : <i'm ulyg>           Levenshtein 8 out of 15\n",
      "<<<<<<sentez ça      : <feel this>\n",
      "                     : <hold this>          Levenshtein 4 out of 15\n",
      "<<<<c'est parti      : <here we go>\n",
      "                     : <tom's left>         Levenshtein 9 out of 15\n",
      "<aucun problème      : <no problem>\n",
      "                     : <no problem>         Levenshtein 0 out of 15\n",
      "<<<<<excuse-moi      : <i'm sorry>\n",
      "                     : <call me>            Levenshtein 9 out of 15\n",
      "<<<est-ce loin       : <is it far>\n",
      "                     : <am i ing>           Levenshtein 6 out of 15\n",
      "<<<<<<<<<<santé      : <bottoms up>\n",
      "                     : <cheers>             Levenshtein 9 out of 15\n",
      "<<<<j'ai essayé      : <i've tried>\n",
      "                     : <i tried it>         Levenshtein 6 out of 15\n",
      "<<<j'ai vu cela      : <i saw that>\n",
      "                     : <i did that>         Levenshtein 3 out of 15\n",
      "<<<<<<<attaquez      : <attack>\n",
      "                     : <run forget it>      Levenshtein 12 out of 15\n",
      "Testing average Levenshtein score     5.80, perfect accuracy     0.10\n"
     ]
    }
   ],
   "source": [
    "total_d, total_correct = check(X_test, Y_test, verbose=True)\n",
    "print(f\"Testing average Levenshtein score {total_d/len(X_test):8.2f}, perfect accuracy {total_correct/len(X_test):8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
