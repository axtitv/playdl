{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the language of the last name via RNN\n",
    "\n",
    "The idea is to one hot encode characters and then create dense embeddings for them based upon some classification problem, such as predicting the next letter or predicting nationality of last name (a common example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_transform(x, mean=0.0, std=0.01):\n",
    "    \"Convert x to have mean and std\"\n",
    "    return x*std + mean\n",
    "\n",
    "def randn(n1, n2,\n",
    "          device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "          dtype=torch.float,\n",
    "          mean=0.0, std=0.01, requires_grad=False):\n",
    "    x = torch.randn(n1, n2, device=device, dtype=dtype)\n",
    "    x = normal_transform(x, mean=mean, std=std)\n",
    "    x.requires_grad=requires_grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (13374, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8340</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8341</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8342</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8343</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8344</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8345</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8346</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8347</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8348</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8349</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8351</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8352</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8353</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8354</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8355</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8340  To The First Page  Russian\n",
       "8341  To The First Page  Russian\n",
       "8342  To The First Page  Russian\n",
       "8343  To The First Page  Russian\n",
       "8344  To The First Page  Russian\n",
       "8345  To The First Page  Russian\n",
       "8346  To The First Page  Russian\n",
       "8347  To The First Page  Russian\n",
       "8348  To The First Page  Russian\n",
       "8349  To The First Page  Russian\n",
       "8350  To The First Page  Russian\n",
       "8351  To The First Page  Russian\n",
       "8352  To The First Page  Russian\n",
       "8353  To The First Page  Russian\n",
       "8354  To The First Page  Russian\n",
       "8355  To The First Page  Russian"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train[badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5976</td>\n",
       "      <td>Jevolojnov,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6549</td>\n",
       "      <td>Lytkin,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name language\n",
       "5976  Jevolojnov,  Russian\n",
       "6549      Lytkin,  Russian"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = df_train['name'].str.contains(',') # might as well keep\n",
    "df_train[comma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3609</td>\n",
       "      <td>Awak'Yan</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4454</td>\n",
       "      <td>Dan'Ko</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4471</td>\n",
       "      <td>Dar'Kin</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name language\n",
       "3609  Awak'Yan  Russian\n",
       "4454    Dan'Ko  Russian\n",
       "4471   Dar'Kin  Russian"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['name'].str.contains(\"'\")][:3] # there are ok so keep quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train = df_train[~badname]\n",
    "\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[~badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxlen(strings:Sequence[str]) -> int:\n",
    "    return max([len(l) for l in strings])\n",
    "\n",
    "max_len = max(maxlen(df_train['name']), maxlen(df_test['name']))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train[['name']], df_train['language']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "X_test, y_test = df_test[['name']], df_test['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    V = set([c for cl in letters for c in cl])\n",
    "    V = sorted(list(V))\n",
    "    ctoi = {c:i for i, c in enumerate(V)}\n",
    "    return V, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " \"'\": 1,\n",
       " ',': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, ctoi = vocab(X['name'])\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 14, 14,  0,  3, 14, 14, 14, 14,  0], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.cat.codes\n",
    "y_train.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.Categorical(y_valid, categories=y_cats, ordered=True).codes\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6,  4, 14, 14,  4], dtype=int8), array([2, 2, 2, 2, 2], dtype=int8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode each letter of each name\n",
    "\n",
    "Each name becomes a matrix of size vocab_size x max_len. Each column represents a char and we pad with zeros out to max_len number of columns since tensors have to be same length in same dimension. \n",
    "\n",
    "This approach is wasteful in that it expands each word to len of longest but avoids having to pad explicitly, simplifying the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(strings:Sequence[str], V, ctoi, max_len=None) -> torch.tensor:\n",
    "    if max_len is None:\n",
    "        max_len = maxlen(strings)\n",
    "    X_onehot = torch.zeros(len(strings),len(V),max_len)\n",
    "    for i,name in enumerate(strings):\n",
    "        onehot = torch.zeros((len(V),max_len))\n",
    "        for j,c in enumerate(name):\n",
    "            onehot[ctoi[c],j] = 1\n",
    "        X_onehot[i] = onehot\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ['cat','a','at'] # always debug with a small representative example\n",
    "o = onehot(sample, *vocab(sample))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0,1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot = onehot(X_train['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_train_onehot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_onehot = onehot(X_valid['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_valid_onehot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model\n",
    "\n",
    "Switching to W, U, V notation from $W_hh$ etc... from [Goodfellow and Yoshua Bengio and Aaron Courville book](https://www.deeplearningbook.org/contents/rnn.html)\n",
    "\n",
    "We have a sequence of one-hot vectors for each word and need to predict a language for each sequence.  We need to know: vocab size (len of one hots), hidden len, and the number of target classes (langs).\n",
    "\n",
    "We must combine a name's onehots into a single vector representing word then use a simple dense linear layer to make a prediction\n",
    "\n",
    "$$\n",
    "h^{(t)} = \\text{ReLU}( W h^{(t-1)} + U x^{(t)} )\n",
    "$$\n",
    "\n",
    "where $t$ iterates through name length (or max pad length).\n",
    "\n",
    "Note this is same as concatenating old state and current input vector and applying a single $W$ matrix of size nhidden x (nhidden+|V|):\n",
    "\n",
    "$$\n",
    "h^{(t)} = \\text{ReLU}( W [h^{(t-1)};x^{(t)}] )\n",
    "$$\n",
    "\n",
    "The output is avail at every char but we only need the last one:\n",
    "\n",
    "$$\n",
    "y^{(t)} = V h^{(t)}\n",
    "$$\n",
    "\n",
    "This $V$ acts like the last dense linear layer which converts the hidden state to likelihood of each target class.\n",
    "\n",
    "*What are the embeddings?* I think those are the final $h^{(t)}$ vectors, one of which is computed per name.  What are char-vec embeddings? Maybe $U$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record-by-record (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameRNN_slow(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LastNameRNN_slow, self).__init__()\n",
    "#         print(\"Model: \",input_size, hidden_size, output_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Help avoid vanishing gradient. Start with identity, which has\n",
    "        # effect of summing char vector embeddings\n",
    "        self.W  = torch.eye(hidden_size, hidden_size).double() #randn(hidden_size, hidden_size, std=0.01).double()\n",
    "        self.U  = torch.eye(hidden_size, input_size).double()\n",
    "        self.V  = torch.eye(output_size, hidden_size).double()\n",
    "        self.W  = nn.Parameter(self.W)\n",
    "        self.U  = nn.Parameter(self.U)\n",
    "        self.V  = nn.Parameter(self.V)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        namelen = X.shape[2]\n",
    "        # record softmax vec of output_size for each record\n",
    "        o = torch.zeros((batch_size, self.output_size)).double().to(device)\n",
    "        for i in range(batch_size):\n",
    "            # Reset hidden state (history) at start of every record\n",
    "            # Use same W and U matrices for all records until SGD update step\n",
    "            h = torch.zeros((self.hidden_size, 1)).double().to(device)\n",
    "            for j in range(namelen):  # for all chars in max name length\n",
    "#                 print(h.shape, X[i].shape, X[i,:,j].shape, self.U.shape)\n",
    "                h = self.W.mm(h) + self.U.mm(X[i,:,j].reshape(-1,1))\n",
    "                h = torch.relu(h)  # better than sigmoid for vanishing gradient\n",
    "            # we now have an h vector that is the embedding for the ith record\n",
    "            # we have encoded/embedded the X[i] record into h\n",
    "            # compute an output value, one per record\n",
    "            ot = self.V.mm(h)\n",
    "#             o[i] = F.softmax(ot.reshape(-1))\n",
    "            o[i] = ot.reshape(-1)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64,\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "rnn = LastNameRNN_slow(input_size=len(V), hidden_size=10, output_size=len(y_cats)).to(device)\n",
    "y_pred = rnn(torch.tensor(X_train_onehot[:100],device=device).double())\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctrain(model:nn.Module, train_data:TensorDataset, valid_data:TensorDataset,\n",
    "           epochs=350,\n",
    "           test_size=0.20,\n",
    "           learning_rate = 0.002,\n",
    "           batch_size=32,\n",
    "           weight_decay=1.e-4,\n",
    "           loss_fn=F.cross_entropy,\n",
    "           metric=accuracy_score,\n",
    "           print_every=30):\n",
    "    \"Train a regressor\"\n",
    "    history = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for ei in range(epochs): # epochs\n",
    "        for bi, (batch_x, batch_y) in enumerate(train_loader): # mini-batch\n",
    "#             if len(batch_x)!=batch_size:\n",
    "#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\n",
    "            y_prob = model(batch_x)\n",
    "#             print(\"y pred\", y_prob, \"batch_y\", batch_y)\n",
    "            loss = loss_fn(y_prob, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad and M.grad\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss        = loss_fn(model(train_data.tensors[0]), train_data.tensors[1])\n",
    "            loss_valid  = loss_fn(model(valid_data.tensors[0]), valid_data.tensors[1])\n",
    "            y_prob = model(train_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_train = metric(y_pred.cpu(), train_data.tensors[1].cpu())\n",
    "            y_prob = model(valid_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_valid = metric(y_pred.cpu(), valid_data.tensors[1].cpu())\n",
    "\n",
    "        history.append( (loss, loss_valid) )\n",
    "        if ei % print_every == 0:\n",
    "            print(f\"Epoch {ei:3d} loss {loss:7.4f}, {loss_valid:7.4f}   {metric.__class__.__name__} {metric_train:4.3f}, {metric_valid:4.3f}\")\n",
    "\n",
    "    history = torch.tensor(history)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.5840,  1.5583   function 0.527, 0.526\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-cfca991fc007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         print_every=1)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-f9603efa00fd>\u001b[0m in \u001b[0;36mctrain\u001b[0;34m(model, train_data, valid_data, epochs, test_size, learning_rate, batch_size, weight_decay, loss_fn, metric, print_every)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# autograd computes U.grad and M.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn = LastNameRNN_slow(input_size=len(V),\n",
    "                      hidden_size=100,\n",
    "                      output_size=len(y_cats)).to(device)\n",
    "subset=1000\n",
    "train = TensorDataset(X_train_onehot[:subset].double().to(device), torch.tensor(y_train[:subset].values).long().to(device))\n",
    "valid = TensorDataset(X_valid_onehot[:subset].double().to(device), torch.tensor(y_valid[:subset]).long().to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.BCELoss(),\n",
    "                        loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=10,\n",
    "                        learning_rate=.02,\n",
    "                        weight_decay=0.00001,\n",
    "                        batch_size=32,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestep-by-step (fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LastNameRNN, self).__init__()\n",
    "#         print(\"Model: \",input_size, hidden_size, output_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # combine W and U into W then cat h and input\n",
    "        self.W  = nn.Linear(hidden_size+input_size, hidden_size)\n",
    "        self.V  = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        namelen = X.shape[2]\n",
    "        # record softmax vec of output_size for each record\n",
    "        o = torch.zeros((batch_size, self.output_size)).to(device)\n",
    "        # now that we do all char j in a batch, h is a matrix\n",
    "        h = torch.zeros((batch_size, self.hidden_size)).to(device)\n",
    "        for j in range(namelen):  # for all chars in max name length\n",
    "#                 print(h.shape, X[i].shape, X[i,:,j].shape, self.U.shape)\n",
    "            xj = X[:,:,j] # jth char for all records in batch\n",
    "#             print(\"W\", self.W.weight.shape, \"h\", h.shape, \"xj\", xj.shape)\n",
    "            combined = torch.cat((h, xj),dim=1)\n",
    "#             print(\"combined\", combined.shape)\n",
    "            h = self.W(combined)\n",
    "            h = torch.relu(h)  # better than sigmoid for vanishing gradient\n",
    "        # we now have an h vector that is the embedding for the ith record\n",
    "        # we have encoded/embedded the X[i] record into h\n",
    "        # compute an output value, one per record\n",
    "        ot = self.V(h)\n",
    "#         print(\"ot shape\", ot.shape)\n",
    "#             o[i] = F.softmax(ot.reshape(-1))\n",
    "#         o[i] = ot.reshape(-1)\n",
    "        return ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.8142,  1.8336   function 0.474, 0.462\n",
      "Epoch   1 loss  1.6149,  1.6425   function 0.474, 0.462\n",
      "Epoch   2 loss  1.4955,  1.5309   function 0.566, 0.553\n",
      "Epoch   3 loss  1.4847,  1.5471   function 0.575, 0.550\n",
      "Epoch   4 loss  1.4624,  1.5117   function 0.574, 0.557\n",
      "Epoch   5 loss  1.4868,  1.5599   function 0.570, 0.548\n",
      "Epoch   6 loss  1.5247,  1.6391   function 0.567, 0.546\n",
      "Epoch   7 loss  1.5033,  1.5834   function 0.556, 0.536\n",
      "Epoch   8 loss  1.4441,  1.5101   function 0.576, 0.550\n",
      "Epoch   9 loss  1.4737,  1.5521   function 0.559, 0.542\n",
      "Epoch  10 loss  1.4576,  1.5108   function 0.562, 0.543\n",
      "Epoch  11 loss  1.4172,  1.4763   function 0.583, 0.561\n",
      "Epoch  12 loss  1.4334,  1.5119   function 0.583, 0.562\n",
      "Epoch  13 loss  1.4731,  1.5259   function 0.558, 0.536\n",
      "Epoch  14 loss  1.4170,  1.4699   function 0.582, 0.558\n",
      "Epoch  15 loss  1.4017,  1.4611   function 0.583, 0.557\n",
      "Epoch  16 loss  1.4118,  1.4594   function 0.582, 0.560\n",
      "Epoch  17 loss  1.3959,  1.4806   function 0.582, 0.560\n",
      "Epoch  18 loss  1.4567,  1.5509   function 0.567, 0.547\n",
      "Epoch  19 loss  1.4319,  1.5351   function 0.577, 0.549\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn = LastNameRNN(input_size=len(V),\n",
    "                  hidden_size=100,\n",
    "                  output_size=len(y_cats)).to(device)\n",
    "subset=5000\n",
    "train = TensorDataset(X_train_onehot[:subset].to(device), torch.tensor(y_train[:subset].values).long().to(device))\n",
    "valid = TensorDataset(X_valid_onehot[:subset].to(device), torch.tensor(y_valid[:subset]).long().to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.BCELoss(),\n",
    "                        loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=20,\n",
    "                        learning_rate=.01,\n",
    "                        weight_decay=0.00001,\n",
    "                        batch_size=32,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For TensorDataset, if you see `TypeError: 'int' object is not callable`, it means you've passed a numpy array.\n",
    "\n",
    "If it says \"expected Long got Char\", it might mean int8 not char."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5)\n",
    "input, input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = loss(input, target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
