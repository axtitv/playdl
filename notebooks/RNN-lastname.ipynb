{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the language of the last name via RNN\n",
    "\n",
    "The idea is to one hot encode characters and then create dense embeddings for them based upon some classification problem, such as predicting the next letter or predicting nationality of last name (a common example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_transform(x, mean=0.0, std=0.01):\n",
    "    \"Convert x to have mean and std\"\n",
    "    return x*std + mean\n",
    "\n",
    "def randn(n1, n2,\n",
    "          device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "          dtype=torch.float,\n",
    "          mean=0.0, std=0.01, requires_grad=False):\n",
    "    x = torch.randn(n1, n2, device=device, dtype=dtype)\n",
    "    x = normal_transform(x, mean=mean, std=std)\n",
    "    x.requires_grad=requires_grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_test.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (6700, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8340</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8341</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8342</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8343</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8344</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8345</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8346</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8347</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8348</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8349</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8351</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8352</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8353</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8354</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8355</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8340  To The First Page  Russian\n",
       "8341  To The First Page  Russian\n",
       "8342  To The First Page  Russian\n",
       "8343  To The First Page  Russian\n",
       "8344  To The First Page  Russian\n",
       "8345  To The First Page  Russian\n",
       "8346  To The First Page  Russian\n",
       "8347  To The First Page  Russian\n",
       "8348  To The First Page  Russian\n",
       "8349  To The First Page  Russian\n",
       "8350  To The First Page  Russian\n",
       "8351  To The First Page  Russian\n",
       "8352  To The First Page  Russian\n",
       "8353  To The First Page  Russian\n",
       "8354  To The First Page  Russian\n",
       "8355  To The First Page  Russian"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train[badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5976</td>\n",
       "      <td>Jevolojnov,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6549</td>\n",
       "      <td>Lytkin,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name language\n",
       "5976  Jevolojnov,  Russian\n",
       "6549      Lytkin,  Russian"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = df_train['name'].str.contains(',') # might as well keep\n",
    "df_train[comma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3609</td>\n",
       "      <td>Awak'Yan</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4454</td>\n",
       "      <td>Dan'Ko</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4471</td>\n",
       "      <td>Dar'Kin</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name language\n",
       "3609  Awak'Yan  Russian\n",
       "4454    Dan'Ko  Russian\n",
       "4471   Dar'Kin  Russian"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['name'].str.contains(\"'\")][:3] # there are ok so keep quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train = df_train[~badname]\n",
    "\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[~badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxlen(strings:Sequence[str]) -> int:\n",
    "    return max([len(l) for l in strings])\n",
    "\n",
    "max_len = max(maxlen(df_train['name']), maxlen(df_test['name']))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train[['name']], df_train['language']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "X_test, y_test = df_test[['name']], df_test['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    V = set([c for cl in letters for c in cl])\n",
    "    V = sorted(list(V))\n",
    "    ctoi = {c:i for i, c in enumerate(V)}\n",
    "    return V, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " \"'\": 1,\n",
       " ',': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, ctoi = vocab(X['name'])\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 14,  0, 14, 14, 17,  5, 14, 14, 10], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.cat.codes\n",
    "y_train.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.Categorical(y_valid, categories=y_cats, ordered=True).codes\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0, 14,  0, 14,  4], dtype=int8), array([2, 2, 2, 2, 2], dtype=int8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode each letter of each name\n",
    "\n",
    "Each name becomes a matrix of size vocab_size x max_len. Each column represents a char and we pad with zeros out to max_len number of columns since tensors have to be same length in same dimension. \n",
    "\n",
    "This approach is wasteful in that it expands each word to len of longest but avoids having to pad explicitly, simplifying the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(strings:Sequence[str], V, ctoi, max_len=None) -> torch.tensor:\n",
    "    if max_len is None:\n",
    "        max_len = maxlen(strings)\n",
    "    X_onehot = torch.zeros(len(strings),len(V),max_len)\n",
    "    for i,name in enumerate(strings):\n",
    "        onehot = torch.zeros((len(V),max_len))\n",
    "        for j,c in enumerate(name):\n",
    "            onehot[ctoi[c],j] = 1\n",
    "        X_onehot[i] = onehot\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ['cat','a','at'] # always debug with a small representative example\n",
    "o = onehot(sample, *vocab(sample))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0,1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot = onehot(X_train['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_train_onehot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_onehot = onehot(X_valid['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_valid_onehot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model\n",
    "\n",
    "Switching to W, U, V notation from $W_hh$ etc... from [Goodfellow and Yoshua Bengio and Aaron Courville book](https://www.deeplearningbook.org/contents/rnn.html)\n",
    "\n",
    "We have a sequence of one-hot vectors for each word and need to predict a language for each sequence.  We need to know: vocab size (len of one hots), hidden len, and the number of target classes (langs).\n",
    "\n",
    "We must combine a name's onehots into a single vector representing word then use a simple dense linear layer to make a prediction\n",
    "\n",
    "$$\n",
    "h^{(t)} = \\text{ReLU}( W h^{(t-1)} + U x^{(t)} )\n",
    "$$\n",
    "\n",
    "where $t$ iterates through name length (or max pad length).\n",
    "\n",
    "Note this is same as concatenating old state and current input vector and applying a single $W$ matrix of size nhidden x (nhidden+|V|):\n",
    "\n",
    "$$\n",
    "h^{(t)} = \\text{ReLU}( W [h^{(t-1)};x^{(t)}] )\n",
    "$$\n",
    "\n",
    "The output is avail at every char but we only need the last one:\n",
    "\n",
    "$$\n",
    "y^{(t)} = V h^{(t)}\n",
    "$$\n",
    "\n",
    "This $V$ acts like the last dense linear layer which converts the hidden state to likelihood of each target class.\n",
    "\n",
    "*What are the embeddings?* I think those are the final $h^{(t)}$ vectors, one of which is computed per name.  What are char-vec embeddings? Maybe $U$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record-by-record (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameRNN_slow(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LastNameRNN_slow, self).__init__()\n",
    "#         print(\"Model: \",input_size, hidden_size, output_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Help avoid vanishing gradient. Start with identity, which has\n",
    "        # effect of summing char vector embeddings\n",
    "        self.W  = torch.eye(hidden_size, hidden_size).double() #randn(hidden_size, hidden_size, std=0.01).double()\n",
    "        self.U  = randn(hidden_size, input_size).double()\n",
    "        self.V  = randn(output_size, hidden_size).double()\n",
    "        self.W  = nn.Parameter(self.W)\n",
    "        self.U  = nn.Parameter(self.U)\n",
    "        self.V  = nn.Parameter(self.V)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        namelen = X.shape[2]\n",
    "        # record softmax vec of output_size for each record\n",
    "        o = torch.zeros((batch_size, self.output_size)).double().to(device)\n",
    "        for i in range(batch_size):\n",
    "            # Reset hidden state (history) at start of every record\n",
    "            # Use same W and U matrices for all records until SGD update step\n",
    "            h = torch.zeros((self.hidden_size, 1)).double().to(device)\n",
    "            for j in range(namelen):  # for all chars in max name length\n",
    "#                 print(h.shape, X[i].shape, X[i,:,j].shape, self.U.shape)\n",
    "                h = self.W.mm(h) + self.U.mm(X[i,:,j].reshape(-1,1))\n",
    "                h = torch.relu(h)  # better than sigmoid for vanishing gradient\n",
    "            # we now have an h vector that is the embedding for the ith record\n",
    "            # we have encoded/embedded the X[i] record into h\n",
    "            # compute an output value, one per record\n",
    "            ot = self.V.mm(h)\n",
    "#             o[i] = F.softmax(ot.reshape(-1))\n",
    "            o[i] = ot.reshape(-1)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4198e-04, -7.9313e-04, -1.4096e-03,  ...,  7.4177e-04,\n",
       "         -1.7835e-03, -5.7661e-05],\n",
       "        [ 1.1290e-04, -1.8579e-04, -1.1523e-03,  ...,  7.1333e-04,\n",
       "         -1.1144e-03, -1.4583e-04],\n",
       "        [ 1.1007e-04, -4.8042e-04, -4.9604e-04,  ...,  2.8605e-04,\n",
       "         -5.8212e-04, -7.8172e-05],\n",
       "        ...,\n",
       "        [-1.9436e-05, -4.4262e-04, -1.7933e-04,  ...,  2.7250e-04,\n",
       "         -7.7297e-04,  1.8318e-04],\n",
       "        [-2.9547e-04, -9.5819e-04, -5.7416e-04,  ...,  8.7855e-05,\n",
       "         -5.9602e-04,  2.3150e-04],\n",
       "        [ 4.3571e-04, -2.0231e-03, -1.7879e-03,  ..., -5.3949e-05,\n",
       "         -1.4019e-03, -6.8755e-05]], dtype=torch.float64, grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "rnn = LastNameRNN_slow(input_size=len(V), hidden_size=10, output_size=len(y_cats)).to(device)\n",
    "y_pred = rnn(torch.tensor(X_train_onehot[:100],device=device).double())\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctrain(model:nn.Module, train_data:TensorDataset, valid_data:TensorDataset,\n",
    "           epochs=350,\n",
    "           test_size=0.20,\n",
    "           learning_rate = 0.002,\n",
    "           batch_size=32,\n",
    "           weight_decay=1.e-4,\n",
    "           loss_fn=F.cross_entropy,\n",
    "           metric=accuracy_score,\n",
    "           print_every=30):\n",
    "    \"Train a regressor\"\n",
    "    history = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for ei in range(epochs): # epochs\n",
    "        for bi, (batch_x, batch_y) in enumerate(train_loader): # mini-batch\n",
    "#             if len(batch_x)!=batch_size:\n",
    "#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\n",
    "            y_prob = model(batch_x)\n",
    "#             print(\"y pred\", y_prob, \"batch_y\", batch_y)\n",
    "            loss = loss_fn(y_prob, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad and M.grad\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            o           = model(train_data.tensors[0])\n",
    "            loss        = loss_fn(o, train_data.tensors[1])\n",
    "            o           = model(valid_data.tensors[0])\n",
    "            loss_valid  = loss_fn(o, valid_data.tensors[1])\n",
    "            y_prob = model(train_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_train = metric(y_pred.cpu(), train_data.tensors[1].cpu())\n",
    "            y_prob = model(valid_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_valid = metric(y_pred.cpu(), valid_data.tensors[1].cpu())\n",
    "\n",
    "        history.append( (loss, loss_valid) )\n",
    "        if ei % print_every == 0:\n",
    "            print(f\"Epoch {ei:3d} loss {loss:7.4f}, {loss_valid:7.4f}   accur {metric_train:4.3f}, {metric_valid:4.3f}\")\n",
    "\n",
    "    history = torch.tensor(history)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.8853,  1.9833   accur 0.464, 0.442\n",
      "Epoch   1 loss  1.6172,  1.7353   accur 0.464, 0.444\n",
      "Epoch   2 loss  1.5026,  1.5945   accur 0.540, 0.514\n",
      "Epoch   3 loss  1.4026,  1.5531   accur 0.574, 0.552\n",
      "Epoch   4 loss  1.4189,  1.5548   accur 0.543, 0.519\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-20e606080f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         print_every=1)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-59512c10f5b2>\u001b[0m in \u001b[0;36mctrain\u001b[0;34m(model, train_data, valid_data, epochs, test_size, learning_rate, batch_size, weight_decay, loss_fn, metric, print_every)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mmetric_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ab95c6741fa0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamelen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for all chars in max name length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#                 print(h.shape, X[i].shape, X[i,:,j].shape, self.U.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# better than sigmoid for vanishing gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# we now have an h vector that is the embedding for the ith record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn = LastNameRNN_slow(input_size=len(V),\n",
    "                      hidden_size=100,\n",
    "                      output_size=len(y_cats)).to(device)\n",
    "subset=2000\n",
    "train = TensorDataset(X_train_onehot[:subset].double().to(device), torch.tensor(y_train[:subset].values).long().to(device))\n",
    "valid = TensorDataset(X_valid_onehot[:subset].double().to(device), torch.tensor(y_valid[:subset]).long().to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.BCELoss(),\n",
    "                        loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=10,\n",
    "                        learning_rate=.01,\n",
    "                        weight_decay=0.00001,\n",
    "                        batch_size=32,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestep-by-step (fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LastNameRNN, self).__init__()\n",
    "#         print(\"Model: \",input_size, hidden_size, output_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # combine W and U into W then cat h and input\n",
    "        self.W  = nn.Linear(hidden_size+input_size, hidden_size)\n",
    "        self.V  = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        namelen = X.shape[2]\n",
    "        # record softmax vec of output_size for each record\n",
    "        o = torch.zeros((batch_size, self.output_size)).to(device)\n",
    "        # now that we do all char j in a batch, h is a matrix\n",
    "        h = torch.zeros((batch_size, self.hidden_size)).to(device)\n",
    "        for j in range(namelen):  # for all chars in max name length\n",
    "#                 print(h.shape, X[i].shape, X[i,:,j].shape, self.U.shape)\n",
    "            xj = X[:,:,j] # jth char for all records in batch\n",
    "#             print(\"W\", self.W.weight.shape, \"h\", h.shape, \"xj\", xj.shape)\n",
    "            combined = torch.cat((h, xj),dim=1)\n",
    "#             print(\"combined\", combined.shape)\n",
    "            h = self.W(combined)\n",
    "            h = torch.relu(h)  # better than sigmoid for vanishing gradient\n",
    "        # we now have an h vector that is the embedding for the ith record\n",
    "        # we have encoded/embedded the X[i] record into h\n",
    "        # compute an output value, one per record\n",
    "        ot = self.V(h)\n",
    "#         print(\"ot shape\", ot.shape)\n",
    "#             o[i] = F.softmax(ot.reshape(-1))\n",
    "#         o[i] = ot.reshape(-1)\n",
    "        return ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.8038,  1.8763   accur 0.482, 0.440\n",
      "Epoch   1 loss  1.6150,  1.7229   accur 0.482, 0.440\n",
      "Epoch   2 loss  1.5552,  1.6604   accur 0.482, 0.440\n",
      "Epoch   3 loss  1.4909,  1.6065   accur 0.552, 0.513\n",
      "Epoch   4 loss  1.4479,  1.5527   accur 0.570, 0.540\n",
      "Epoch   5 loss  1.4641,  1.5770   accur 0.561, 0.526\n",
      "Epoch   6 loss  1.4388,  1.5513   accur 0.566, 0.533\n",
      "Epoch   7 loss  1.4218,  1.5326   accur 0.568, 0.537\n",
      "Epoch   8 loss  1.4114,  1.5234   accur 0.571, 0.540\n",
      "Epoch   9 loss  1.4006,  1.5126   accur 0.574, 0.541\n",
      "Epoch  10 loss  1.3893,  1.4978   accur 0.577, 0.545\n",
      "Epoch  11 loss  1.3926,  1.5065   accur 0.571, 0.541\n",
      "Epoch  12 loss  1.3931,  1.5089   accur 0.567, 0.538\n",
      "Epoch  13 loss  1.3831,  1.5041   accur 0.569, 0.537\n",
      "Epoch  14 loss  1.3695,  1.4918   accur 0.569, 0.539\n",
      "Epoch  15 loss  1.3556,  1.4788   accur 0.573, 0.539\n",
      "Epoch  16 loss  1.3462,  1.4684   accur 0.574, 0.536\n",
      "Epoch  17 loss  1.3310,  1.4572   accur 0.584, 0.552\n",
      "Epoch  18 loss  1.3299,  1.4559   accur 0.601, 0.570\n",
      "Epoch  19 loss  1.3124,  1.4578   accur 0.594, 0.566\n",
      "Epoch  20 loss  1.3055,  1.4489   accur 0.621, 0.587\n",
      "Epoch  21 loss  1.2962,  1.4551   accur 0.615, 0.587\n",
      "Epoch  22 loss  1.2887,  1.4334   accur 0.622, 0.585\n",
      "Epoch  23 loss  1.3105,  1.4789   accur 0.587, 0.549\n",
      "Epoch  24 loss  1.3361,  1.5360   accur 0.573, 0.540\n",
      "Epoch  25 loss  1.3196,  1.5263   accur 0.597, 0.560\n",
      "Epoch  26 loss  1.3587,  1.5993   accur 0.609, 0.576\n",
      "Epoch  27 loss  1.3544,  1.5070   accur 0.590, 0.564\n",
      "Epoch  28 loss  1.2455,  1.4480   accur 0.633, 0.603\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-9f5c3d53b093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#002,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         print_every=1)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-90d6f48b99f5>\u001b[0m in \u001b[0;36mctrain\u001b[0;34m(model, train_data, valid_data, epochs, test_size, learning_rate, batch_size, weight_decay, loss_fn, metric, print_every)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# autograd computes U.grad and M.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn = LastNameRNN(input_size=len(V),\n",
    "                  hidden_size=50,\n",
    "                  output_size=len(y_cats)).to(device)\n",
    "subset=5_000\n",
    "train = TensorDataset(X_train_onehot[:subset].to(device), torch.tensor(y_train[:subset].values).long().to(device))\n",
    "valid = TensorDataset(X_valid_onehot[:subset].to(device), torch.tensor(y_valid[:subset]).long().to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.BCELoss(),\n",
    "                        loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=30,\n",
    "                        learning_rate=.001,\n",
    "                        weight_decay=0.000001,#002,\n",
    "                        batch_size=64,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameRNN_split(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LastNameRNN_split, self).__init__()\n",
    "#         print(\"Model: \",input_size, hidden_size, output_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.W  = torch.eye(hidden_size, hidden_size)\n",
    "        self.U  = randn(hidden_size, input_size)\n",
    "        self.V  = randn(output_size, hidden_size)\n",
    "        self.W  = nn.Parameter(self.W)\n",
    "        self.U  = nn.Parameter(self.U)\n",
    "        self.V  = nn.Parameter(self.V)\n",
    "\n",
    "#         self.W  = nn.Linear(hidden_size+input_size, hidden_size)\n",
    "#         self.V  = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        namelen = X.shape[2]\n",
    "        # record softmax vec of output_size for each record\n",
    "        o = torch.zeros((batch_size, self.output_size)).to(device)\n",
    "        # now that we do all char j in a batch, h is a matrix\n",
    "        h = torch.zeros((self.hidden_size, batch_size)).to(device)\n",
    "        for j in range(namelen):  # for all chars in max name length\n",
    "            # xj is batchsize x |V| but U is hidden x |V| so need transpose\n",
    "            xj = X[:,:,j].T # jth char dim for all records in batch\n",
    "#             print(self.W.shape, h.shape, self.U.shape, xj.shape)\n",
    "            h = self.W.mm(h) + self.U.mm(xj)\n",
    "            h = torch.relu(h)  # better than sigmoid for vanishing gradient\n",
    "        # we now have an h vector that is the embedding for the ith record\n",
    "        # we have encoded/embedded the X[i] record into h\n",
    "        # compute an output value, one per record\n",
    "        ot = self.V.mm(h).T\n",
    "#             o[i] = F.softmax(ot.reshape(-1))\n",
    "#         print(\"ot shape\", ot.shape, h.shape)\n",
    "        return ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.5245,  1.6130   accur 0.563, 0.530\n",
      "Epoch   1 loss  1.3570,  1.4586   accur 0.611, 0.570\n",
      "Epoch   2 loss  1.2625,  1.3743   accur 0.640, 0.607\n",
      "Epoch   3 loss  1.2018,  1.3203   accur 0.655, 0.626\n",
      "Epoch   4 loss  1.1558,  1.2895   accur 0.672, 0.635\n",
      "Epoch   5 loss  1.1254,  1.2696   accur 0.680, 0.633\n",
      "Epoch   6 loss  1.0927,  1.2496   accur 0.688, 0.641\n",
      "Epoch   7 loss  1.0691,  1.2382   accur 0.691, 0.648\n",
      "Epoch   8 loss  1.0520,  1.2335   accur 0.697, 0.653\n",
      "Epoch   9 loss  1.0302,  1.2206   accur 0.698, 0.653\n",
      "Epoch  10 loss  1.0079,  1.2038   accur 0.703, 0.658\n",
      "Epoch  11 loss  0.9868,  1.1911   accur 0.710, 0.664\n",
      "Epoch  12 loss  0.9817,  1.1961   accur 0.709, 0.655\n",
      "Epoch  13 loss  0.9744,  1.1976   accur 0.710, 0.655\n",
      "Epoch  14 loss  0.9646,  1.1977   accur 0.710, 0.655\n",
      "Epoch  15 loss  0.9486,  1.1924   accur 0.715, 0.661\n",
      "Epoch  16 loss  0.9322,  1.1825   accur 0.719, 0.666\n",
      "Epoch  17 loss  0.9188,  1.1792   accur 0.722, 0.675\n",
      "Epoch  18 loss  0.8992,  1.1660   accur 0.731, 0.680\n",
      "Epoch  19 loss  0.8772,  1.1506   accur 0.738, 0.685\n",
      "Epoch  20 loss  0.8645,  1.1454   accur 0.739, 0.686\n",
      "Epoch  21 loss  0.8517,  1.1368   accur 0.742, 0.688\n",
      "Epoch  22 loss  0.8410,  1.1396   accur 0.746, 0.685\n",
      "Epoch  23 loss  0.8375,  1.1425   accur 0.747, 0.682\n",
      "Epoch  24 loss  0.8410,  1.1503   accur 0.747, 0.682\n",
      "Epoch  25 loss  0.8408,  1.1525   accur 0.746, 0.682\n",
      "Epoch  26 loss  0.8357,  1.1609   accur 0.747, 0.682\n",
      "Epoch  27 loss  0.8389,  1.1675   accur 0.746, 0.685\n",
      "Epoch  28 loss  0.8271,  1.1745   accur 0.749, 0.686\n",
      "Epoch  29 loss  0.8281,  1.1787   accur 0.747, 0.683\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn = LastNameRNN_split(input_size=len(V),\n",
    "                      hidden_size=50,\n",
    "                      output_size=len(y_cats)).to(device)\n",
    "subset=5_000\n",
    "train = TensorDataset(X_train_onehot[:subset].to(device), torch.tensor(y_train[:subset].values).long().to(device))\n",
    "valid = TensorDataset(X_valid_onehot[:subset].to(device), torch.tensor(y_valid[:subset]).long().to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.BCELoss(),\n",
    "                        loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=30,\n",
    "                        learning_rate=.001,\n",
    "                        weight_decay=0.000001,#002,\n",
    "                        batch_size=64,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting.  Combined W and U seems to get better results, even though it should be equivalent. I must have some other different like precision or other numerical diffs. Oh duh. I'm using nn.Linear, which has a bias. wait it should be worse w/o bias. hmm.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For TensorDataset, if you see `TypeError: 'int' object is not callable`, it means you've passed a numpy array.\n",
    "\n",
    "If it says \"expected Long got Char\", it might mean int8 not char."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
