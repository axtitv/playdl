{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the language of the last name via RNN\n",
    "\n",
    "The idea is to one hot encode characters and then create dense embeddings for them based upon some classification problem, such as predicting the next letter or predicting nationality of last name (a common example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_transform(x, mean=0.0, std=0.01):\n",
    "    \"Convert x to have mean and std\"\n",
    "    return x*std + mean\n",
    "\n",
    "def randn(n1, n2,\n",
    "          device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "          dtype=torch.float,\n",
    "          mean=0.0, std=0.01, requires_grad=False):\n",
    "    x = torch.randn(n1, n2, device=device, dtype=dtype)\n",
    "    x = normal_transform(x, mean=mean, std=std)\n",
    "    x.requires_grad=requires_grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (13374, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8340</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8341</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8342</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8343</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8344</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8345</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8346</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8347</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8348</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8349</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8351</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8352</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8353</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8354</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8355</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8340  To The First Page  Russian\n",
       "8341  To The First Page  Russian\n",
       "8342  To The First Page  Russian\n",
       "8343  To The First Page  Russian\n",
       "8344  To The First Page  Russian\n",
       "8345  To The First Page  Russian\n",
       "8346  To The First Page  Russian\n",
       "8347  To The First Page  Russian\n",
       "8348  To The First Page  Russian\n",
       "8349  To The First Page  Russian\n",
       "8350  To The First Page  Russian\n",
       "8351  To The First Page  Russian\n",
       "8352  To The First Page  Russian\n",
       "8353  To The First Page  Russian\n",
       "8354  To The First Page  Russian\n",
       "8355  To The First Page  Russian"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train[badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5976</td>\n",
       "      <td>Jevolojnov,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6549</td>\n",
       "      <td>Lytkin,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name language\n",
       "5976  Jevolojnov,  Russian\n",
       "6549      Lytkin,  Russian"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = df_train['name'].str.contains(',') # might as well keep\n",
    "df_train[comma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3609</td>\n",
       "      <td>Awak'Yan</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4454</td>\n",
       "      <td>Dan'Ko</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4471</td>\n",
       "      <td>Dar'Kin</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name language\n",
       "3609  Awak'Yan  Russian\n",
       "4454    Dan'Ko  Russian\n",
       "4471   Dar'Kin  Russian"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['name'].str.contains(\"'\")][:3] # there are ok so keep quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train = df_train[~badname]\n",
    "\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[~badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxlen(strings:Sequence[str]) -> int:\n",
    "    return max([len(l) for l in strings])\n",
    "\n",
    "max_len = max(maxlen(df_train['name']), maxlen(df_test['name']))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train[['name']], df_train['language']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "X_test, y_test = df_test[['name']], df_test['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    V = set([c for cl in letters for c in cl])\n",
    "    V = sorted(list(V))\n",
    "    ctoi = {c:i for i, c in enumerate(V)}\n",
    "    return V, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " \"'\": 1,\n",
       " ',': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, ctoi = vocab(X['name'])\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 14,  1, 14, 14,  4,  4, 16,  0,  6], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.cat.codes\n",
    "y_train.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.Categorical(y_valid, categories=y_cats, ordered=True).codes\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14, 14, 14, 14,  9], dtype=int8), array([2, 2, 2, 2, 2], dtype=int8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode each letter of each name\n",
    "\n",
    "Each name becomes a matrix of size vocab_size x max_len. Each column represents a char and we pad with zeros out to max_len number of columns since tensors have to be same length in same dimension. \n",
    "\n",
    "This approach is wasteful in that it expands each word to len of longest but avoids having to pad explicitly, simplifying the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(strings:Sequence[str], V, ctoi, max_len=None) -> torch.tensor:\n",
    "    if max_len is None:\n",
    "        max_len = maxlen(strings)\n",
    "    X_onehot = torch.zeros(len(strings),len(V),max_len)\n",
    "    for i,name in enumerate(strings):\n",
    "        onehot = torch.zeros((len(V),max_len))\n",
    "        for j,c in enumerate(name):\n",
    "            onehot[ctoi[c],j] = 1\n",
    "        X_onehot[i] = onehot\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ['cat','a','at'] # always debug with a small representative example\n",
    "o = onehot(sample, *vocab(sample))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0,1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot = onehot(X_train['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_train_onehot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_onehot = onehot(X_valid['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_valid_onehot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model\n",
    "\n",
    "Switching to W, U, V notation from $W_hh$ etc... from [Goodfellow and Yoshua Bengio and Aaron Courville book](https://www.deeplearningbook.org/contents/rnn.html)\n",
    "\n",
    "We have a sequence of one-hot vectors for each word and need to predict a language for each sequence.  We need to know: vocab size (len of one hots), hidden len, and the number of target classes (langs).\n",
    "\n",
    "We must combine a name's onehots into a single vector representing word then use a simple dense linear layer to make a prediction\n",
    "\n",
    "$$\n",
    "h^{(t)} = \\text{ReLU}( W h^{(t-1)} + U x^{(t)} )\n",
    "$$\n",
    "\n",
    "where $t$ iterates through name length (or max pad length).\n",
    "\n",
    "Note this is same as concatenating old state and current input vector and applying a single $W$ matrix of size nhidden x (nhidden+|V|):\n",
    "\n",
    "$$\n",
    "h^{(t)} = \\text{ReLU}( W [h^{(t-1)};x^{(t)}] )\n",
    "$$\n",
    "\n",
    "The output is avail at every char but we only need the last one:\n",
    "\n",
    "$$\n",
    "y^{(t)} = V h^{(t)}\n",
    "$$\n",
    "\n",
    "This $V$ acts like the last dense linear layer which converts the hidden state to likelihood of each target class.\n",
    "\n",
    "*What are the embeddings?* I think those are the final $h^{(t)}$ vectors, one of which is computed per name.  What are char-vec embeddings? Maybe $U$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record-by-record (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameRNN_slow(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LastNameRNN_slow, self).__init__()\n",
    "#         print(\"Model: \",input_size, hidden_size, output_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # Help avoid vanishing gradient. Start with identity, which has\n",
    "        # effect of summing char vector embeddings\n",
    "        self.W  = torch.eye(hidden_size, hidden_size).double() #randn(hidden_size, hidden_size, std=0.01).double()\n",
    "        self.U  = torch.eye(hidden_size, input_size).double()\n",
    "        self.V  = torch.eye(output_size, hidden_size).double()\n",
    "        self.W  = nn.Parameter(self.W)\n",
    "        self.U  = nn.Parameter(self.U)\n",
    "        self.V  = nn.Parameter(self.V)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        namelen = X.shape[2]\n",
    "        # record softmax vec of output_size for each record\n",
    "        o = torch.zeros((batch_size, self.output_size)).double().to(device)\n",
    "        for i in range(batch_size):\n",
    "            # Reset hidden state (history) at start of every record\n",
    "            # Use same W and U matrices for all records until SGD update step\n",
    "            h = torch.zeros((self.hidden_size, 1)).double().to(device)\n",
    "            for j in range(namelen):  # for all chars in max name length\n",
    "#                 print(h.shape, X[i].shape, X[i,:,j].shape, self.U.shape)\n",
    "                h = self.W.mm(h) + self.U.mm(X[i,:,j].reshape(-1,1))\n",
    "                h = torch.relu(h)  # better than sigmoid for vanishing gradient\n",
    "            # we now have an h vector that is the embedding for the ith record\n",
    "            # we have encoded/embedded the X[i] record into h\n",
    "            # compute an output value, one per record\n",
    "            ot = self.V.mm(h)\n",
    "#             o[i] = F.softmax(ot.reshape(-1))\n",
    "            o[i] = ot.reshape(-1)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64,\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "rnn = LastNameRNN_slow(input_size=len(V), hidden_size=10, output_size=len(y_cats)).to(device)\n",
    "y_pred = rnn(torch.tensor(X_train_onehot[:100],device=device).double())\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctrain(model:nn.Module, train_data:TensorDataset, valid_data:TensorDataset,\n",
    "           epochs=350,\n",
    "           test_size=0.20,\n",
    "           learning_rate = 0.002,\n",
    "           batch_size=32,\n",
    "           weight_decay=1.e-4,\n",
    "           loss_fn=F.cross_entropy,\n",
    "           metric=accuracy_score,\n",
    "           print_every=30):\n",
    "    \"Train a regressor\"\n",
    "    history = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for ei in range(epochs): # epochs\n",
    "        for bi, (batch_x, batch_y) in enumerate(train_loader): # mini-batch\n",
    "#             if len(batch_x)!=batch_size:\n",
    "#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\n",
    "            y_prob = model(batch_x)\n",
    "#             print(\"y pred\", y_prob, \"batch_y\", batch_y)\n",
    "            loss = loss_fn(y_prob, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad and M.grad\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss        = loss_fn(model(train_data.tensors[0]), train_data.tensors[1])\n",
    "            loss_valid  = loss_fn(model(valid_data.tensors[0]), valid_data.tensors[1])\n",
    "            y_prob = model(train_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_train = metric(y_pred.cpu(), train_data.tensors[1].cpu())\n",
    "            y_prob = model(valid_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_valid = metric(y_pred.cpu(), valid_data.tensors[1].cpu())\n",
    "\n",
    "        history.append( (loss, loss_valid) )\n",
    "        if ei % print_every == 0:\n",
    "            print(f\"Epoch {ei:3d} loss {loss:7.4f}, {loss_valid:7.4f}   {metric.__class__.__name__} {metric_train:4.3f}, {metric_valid:4.3f}\")\n",
    "\n",
    "    history = torch.tensor(history)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1587428061935/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.6709,  1.6391   function 0.524, 0.528\n",
      "Epoch   1 loss  1.5434,  1.5329   function 0.571, 0.574\n",
      "Epoch   2 loss  1.4122,  1.4999   function 0.599, 0.585\n",
      "Epoch   3 loss  1.4688,  1.5420   function 0.566, 0.581\n",
      "Epoch   4 loss  1.3831,  1.5022   function 0.587, 0.584\n",
      "Epoch   5 loss  1.4019,  1.5673   function 0.601, 0.593\n",
      "Epoch   6 loss  1.3038,  1.4536   function 0.611, 0.595\n",
      "Epoch   7 loss  1.3227,  1.4571   function 0.599, 0.585\n",
      "Epoch   8 loss  1.2411,  1.4324   function 0.596, 0.574\n",
      "Epoch   9 loss  1.1978,  1.4505   function 0.614, 0.590\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn = LastNameRNN_slow(input_size=len(V),\n",
    "                      hidden_size=100,\n",
    "                      output_size=len(y_cats)).to(device)\n",
    "subset=1000\n",
    "train = TensorDataset(X_train_onehot[:subset].double().to(device), torch.tensor(y_train[:subset].values).long().to(device))\n",
    "valid = TensorDataset(X_valid_onehot[:subset].double().to(device), torch.tensor(y_valid[:subset]).long().to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.BCELoss(),\n",
    "                        loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=10,\n",
    "                        learning_rate=.02,\n",
    "                        weight_decay=0.00001,\n",
    "                        batch_size=32,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestep-by-step (fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LastNameRNN, self).__init__()\n",
    "#         print(\"Model: \",input_size, hidden_size, output_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # combine W and U into W then cat h and input\n",
    "        self.W  = nn.Linear(hidden_size+input_size, hidden_size)\n",
    "        self.V  = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        namelen = X.shape[2]\n",
    "        # record softmax vec of output_size for each record\n",
    "        o = torch.zeros((batch_size, self.output_size)).to(device)\n",
    "        # now that we do all char j in a batch, h is a matrix\n",
    "        h = torch.zeros((batch_size, self.hidden_size)).to(device)\n",
    "        for j in range(namelen):  # for all chars in max name length\n",
    "#                 print(h.shape, X[i].shape, X[i,:,j].shape, self.U.shape)\n",
    "            xj = X[:,:,j] # jth char for all records in batch\n",
    "#             print(\"W\", self.W.weight.shape, \"h\", h.shape, \"xj\", xj.shape)\n",
    "            combined = torch.cat((h, xj),dim=1)\n",
    "#             print(\"combined\", combined.shape)\n",
    "            h = self.W(combined)\n",
    "            h = torch.relu(h)  # better than sigmoid for vanishing gradient\n",
    "        # we now have an h vector that is the embedding for the ith record\n",
    "        # we have encoded/embedded the X[i] record into h\n",
    "        # compute an output value, one per record\n",
    "        ot = self.V(h)\n",
    "#         print(\"ot shape\", ot.shape)\n",
    "#             o[i] = F.softmax(ot.reshape(-1))\n",
    "#         o[i] = ot.reshape(-1)\n",
    "        return ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.6688,  1.6402   function 0.463, 0.477\n",
      "Epoch   1 loss  1.5978,  1.5652   function 0.485, 0.496\n",
      "Epoch   2 loss  1.4323,  1.4239   function 0.569, 0.576\n",
      "Epoch   3 loss  1.4496,  1.4370   function 0.566, 0.569\n",
      "Epoch   4 loss  1.4196,  1.4131   function 0.574, 0.572\n",
      "Epoch   5 loss  1.3686,  1.3700   function 0.586, 0.586\n",
      "Epoch   6 loss  1.3540,  1.3627   function 0.590, 0.589\n",
      "Epoch   7 loss  1.3560,  1.3817   function 0.592, 0.591\n",
      "Epoch   8 loss  1.3364,  1.3643   function 0.588, 0.590\n",
      "Epoch   9 loss  1.2994,  1.3347   function 0.597, 0.595\n",
      "Epoch  10 loss  1.2825,  1.3210   function 0.598, 0.590\n",
      "Epoch  11 loss  1.2461,  1.2963   function 0.637, 0.632\n",
      "Epoch  12 loss  1.2130,  1.2725   function 0.649, 0.642\n",
      "Epoch  13 loss  1.1784,  1.2475   function 0.665, 0.655\n",
      "Epoch  14 loss  1.1328,  1.2011   function 0.677, 0.666\n",
      "Epoch  15 loss  1.1380,  1.2163   function 0.685, 0.665\n",
      "Epoch  16 loss  1.0319,  1.1267   function 0.716, 0.689\n",
      "Epoch  17 loss  1.0446,  1.1376   function 0.712, 0.692\n",
      "Epoch  18 loss  1.0581,  1.1755   function 0.705, 0.685\n",
      "Epoch  19 loss  0.9559,  1.0769   function 0.735, 0.706\n",
      "Epoch  20 loss  0.9876,  1.1000   function 0.726, 0.701\n",
      "Epoch  21 loss  0.9129,  1.0674   function 0.745, 0.719\n",
      "Epoch  22 loss  0.9999,  1.1972   function 0.729, 0.699\n",
      "Epoch  23 loss  0.9137,  1.1050   function 0.747, 0.718\n",
      "Epoch  24 loss  0.8383,  1.0243   function 0.763, 0.725\n",
      "Epoch  25 loss  0.8438,  1.0518   function 0.761, 0.724\n",
      "Epoch  26 loss  0.8139,  1.0325   function 0.768, 0.728\n",
      "Epoch  27 loss  0.8873,  1.1268   function 0.757, 0.724\n",
      "Epoch  28 loss  0.8507,  1.0946   function 0.763, 0.728\n",
      "Epoch  29 loss  0.8747,  1.0488   function 0.754, 0.713\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn = LastNameRNN(input_size=len(V),\n",
    "                  hidden_size=100,\n",
    "                  output_size=len(y_cats)).to(device)\n",
    "subset=10_000\n",
    "train = TensorDataset(X_train_onehot[:subset].to(device), torch.tensor(y_train[:subset].values).long().to(device))\n",
    "valid = TensorDataset(X_valid_onehot[:subset].to(device), torch.tensor(y_valid[:subset]).long().to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.BCELoss(),\n",
    "                        loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=30,\n",
    "                        learning_rate=.001,\n",
    "                        weight_decay=0.000001,#002,\n",
    "                        batch_size=64,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For TensorDataset, if you see `TypeError: 'int' object is not callable`, it means you've passed a numpy array.\n",
    "\n",
    "If it says \"expected Long got Char\", it might mean int8 not char."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.8099e-02, -5.1395e-01, -2.8725e+00, -1.3264e+00,  9.1947e-01],\n",
       "         [-4.9177e-01, -2.1824e-03, -5.9171e-01,  1.5105e+00,  5.9480e-01],\n",
       "         [ 1.6037e+00, -3.8224e+00,  1.4056e+00,  2.2718e+00, -1.2282e-01]]),\n",
       " torch.Size([3, 5]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5)\n",
    "input, input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 1, 0]), torch.Size([3]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3672)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = loss(input, target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
