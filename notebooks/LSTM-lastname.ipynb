{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the language of the last name via LSTM\n",
    "\n",
    "Repeat previous RNN exercise but with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctrain(model:nn.Module, train_data:TensorDataset, valid_data:TensorDataset,\n",
    "            epochs=350,\n",
    "            test_size=0.20,\n",
    "            learning_rate = 0.002,\n",
    "            batch_size=32,\n",
    "            weight_decay=1.e-4,\n",
    "            loss_fn=F.cross_entropy,\n",
    "            metric=accuracy_score,\n",
    "            print_every=30):\n",
    "    \"Train a regressor\"\n",
    "    history = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for ei in range(epochs): # epochs\n",
    "        for bi, (batch_x, batch_y) in enumerate(train_loader): # mini-batch\n",
    "#             if len(batch_x)!=batch_size:\n",
    "#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\n",
    "            y_prob = model(batch_x)\n",
    "#             print(\"y_prob\", y_prob.shape)\n",
    "#             print(\"y pred\", y_prob, \"batch_y\", batch_y)\n",
    "            loss = loss_fn(y_prob, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad and M.grad\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss        = loss_fn(model(train_data.tensors[0]), train_data.tensors[1])\n",
    "            loss_valid  = loss_fn(model(valid_data.tensors[0]), valid_data.tensors[1])\n",
    "            y_prob = model(train_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_train = metric(y_pred.cpu(), train_data.tensors[1].cpu())\n",
    "            y_prob = model(valid_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_valid = metric(y_pred.cpu(), valid_data.tensors[1].cpu())\n",
    "\n",
    "        history.append( (loss, loss_valid) )\n",
    "        if ei % print_every == 0:\n",
    "            print(f\"Epoch {ei:3d} loss {loss:7.4f}, {loss_valid:7.4f}   {metric.__class__.__name__} {metric_train:4.3f}, {metric_valid:4.3f}\")\n",
    "\n",
    "    history = torch.tensor(history)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with fake LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3426, -0.9296,  0.0198,  0.4148,  0.7911, -0.3912],\n",
       "        [-0.9974,  1.4160, -1.1375,  0.2832,  0.0569, -0.7741],\n",
       "        [-0.9809, -2.5827, -0.5269, -0.6388, -1.4506,  0.2222],\n",
       "        [-1.2773, -0.6306,  0.0073, -0.1752, -0.9184,  1.2685]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = 6\n",
    "hidden_size = 3\n",
    "n = 4\n",
    "rnn = nn.LSTM(input_size=input_features, hidden_size=hidden_size, num_layers=1)\n",
    "inputs = [torch.randn(1, input_features) for _ in range(n)] # make n vectors\n",
    "inputs = torch.cat(inputs)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3426, -0.9296,  0.0198,  0.4148,  0.7911, -0.3912]],\n",
       "\n",
       "        [[-0.9974,  1.4160, -1.1375,  0.2832,  0.0569, -0.7741]],\n",
       "\n",
       "        [[-0.9809, -2.5827, -0.5269, -0.6388, -1.4506,  0.2222]],\n",
       "\n",
       "        [[-1.2773, -0.6306,  0.0073, -0.1752, -0.9184,  1.2685]]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.reshape(len(inputs), 1, input_features)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(1, 1, hidden_size)\n",
    "c0 = torch.zeros(1, 1, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1945, -0.1479, -0.1028]],\n",
       "\n",
       "        [[-0.0536, -0.0800, -0.1554]],\n",
       "\n",
       "        [[-0.2049, -0.0533, -0.2463]],\n",
       "\n",
       "        [[-0.1536,  0.0836, -0.1160]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o, hc = rnn(inputs, (h0,c0))\n",
    "# output is shape (n, max sequence length, hidden_size)\n",
    "print(o.shape)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1536,  0.0836, -0.1160]]], grad_fn=<StackBackward>),\n",
       " tensor([[[-0.7049,  0.3499, -0.7430]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (13374, 2))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8340</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8341</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8342</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8343</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8344</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8345</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8346</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8347</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8348</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8349</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8351</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8352</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8353</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8354</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8355</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8340  To The First Page  Russian\n",
       "8341  To The First Page  Russian\n",
       "8342  To The First Page  Russian\n",
       "8343  To The First Page  Russian\n",
       "8344  To The First Page  Russian\n",
       "8345  To The First Page  Russian\n",
       "8346  To The First Page  Russian\n",
       "8347  To The First Page  Russian\n",
       "8348  To The First Page  Russian\n",
       "8349  To The First Page  Russian\n",
       "8350  To The First Page  Russian\n",
       "8351  To The First Page  Russian\n",
       "8352  To The First Page  Russian\n",
       "8353  To The First Page  Russian\n",
       "8354  To The First Page  Russian\n",
       "8355  To The First Page  Russian"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train[badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5976</td>\n",
       "      <td>Jevolojnov,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6549</td>\n",
       "      <td>Lytkin,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name language\n",
       "5976  Jevolojnov,  Russian\n",
       "6549      Lytkin,  Russian"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = df_train['name'].str.contains(',') # might as well keep\n",
    "df_train[comma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3609</td>\n",
       "      <td>Awak'Yan</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4454</td>\n",
       "      <td>Dan'Ko</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4471</td>\n",
       "      <td>Dar'Kin</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name language\n",
       "3609  Awak'Yan  Russian\n",
       "4454    Dan'Ko  Russian\n",
       "4471   Dar'Kin  Russian"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['name'].str.contains(\"'\")][:3] # there are ok so keep quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train = df_train[~badname]\n",
    "\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[~badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxlen(strings:Sequence[str]) -> int:\n",
    "    return max([len(l) for l in strings])\n",
    "\n",
    "max_len = max(maxlen(df_train['name']), maxlen(df_test['name']))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train[['name']], df_train['language']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "X_test, y_test = df_test[['name']], df_test['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    V = set([c for cl in letters for c in cl])\n",
    "    V = sorted(list(V))\n",
    "    ctoi = {c:i for i, c in enumerate(V)}\n",
    "    return V, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " \"'\": 1,\n",
       " ',': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, ctoi = vocab(X['name'])\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 14, 14,  0,  4, 14, 14,  5, 14, 14], dtype=int8)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.cat.codes\n",
    "y_train.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.Categorical(y_valid, categories=y_cats, ordered=True).codes\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7, 14,  0,  9, 10], dtype=int8), array([2, 2, 2, 2, 2], dtype=int8))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode each letter of each name\n",
    "\n",
    "Each name becomes a matrix of size vocab_size x max_len. Each column represents a char and we pad with zeros out to max_len number of columns since tensors have to be same length in same dimension. \n",
    "\n",
    "This approach is wasteful in that it expands each word to len of longest but avoids having to pad explicitly, simplifying the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(strings:Sequence[str], V, ctoi, max_len=None) -> torch.tensor:\n",
    "    if max_len is None:\n",
    "        max_len = maxlen(strings)\n",
    "    X_onehot = torch.zeros(len(strings),len(V),max_len)\n",
    "    for i,name in enumerate(strings):\n",
    "        onehot = torch.zeros((len(V),max_len))\n",
    "        for j,c in enumerate(name):\n",
    "            onehot[ctoi[c],j] = 1\n",
    "        X_onehot[i] = onehot\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.]]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ['cat','a','at'] # always debug with a small representative example\n",
    "o = onehot(sample, *vocab(sample))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0,1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot = onehot(X_train['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_train_onehot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_onehot = onehot(X_valid['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_valid_onehot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameLSTM(nn.Module):\n",
    "    def __init__(self, input_features, hidden_size, output_size):\n",
    "        super(LastNameLSTM, self).__init__()\n",
    "#         print(\"Model: \",input_features, hidden_size, output_size)\n",
    "        self.input_features = input_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # combine W and U into W then cat h and input\n",
    "        self.lstm = nn.LSTM(input_size=input_features,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=1)\n",
    "        self.V  = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        max_len = X.shape[1]\n",
    "        # LSTMs need hidden and state vectors, one per input symbol\n",
    "        # also this resets h, c for each batch, not sure that is good\n",
    "        h0 = torch.zeros(1, max_len, self.hidden_size)\n",
    "        c0 = torch.zeros(1, max_len, self.hidden_size)\n",
    "        h, c = h0, c0\n",
    "        \n",
    "        # output is shape (batch size, max_len, hidden_size)\n",
    "        o, _ = self.lstm(X, (h,c))\n",
    "#         print(\"lstm o\", o.shape)\n",
    "        # o has ALL outputs, for each step as it works through chars of name.\n",
    "        # We only need the last output, which we run into final layer\n",
    "        # for classification\n",
    "        o = o[:,-1,:]\n",
    "#         print(\"last output\", o.shape)\n",
    "        o = self.V(o)\n",
    "#         print(\"final layer\", o.shape)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous shape is now wrong for LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10686, 29, 19])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape should be (num records, max name len, input features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 19, 29])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset=10_000\n",
    "X_train_onehot, y_train = X_train_onehot[:subset], torch.tensor(y_train[:subset].values).long()\n",
    "X_valid_onehot, y_valid = X_valid_onehot[:subset], torch.tensor(y_valid[:subset]).long()\n",
    "X_train_onehot = X_train_onehot.reshape(len(X_train_onehot), max_len, len(V))\n",
    "X_valid_onehot = X_valid_onehot.reshape(len(X_valid_onehot), max_len, len(V))\n",
    "X_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.8463,  1.8553   function 0.468, 0.467\n",
      "Epoch   1 loss  1.8404,  1.8489   function 0.468, 0.467\n",
      "Epoch   2 loss  1.8302,  1.8380   function 0.468, 0.467\n",
      "Epoch   3 loss  1.8188,  1.8258   function 0.468, 0.467\n",
      "Epoch   4 loss  1.8123,  1.8192   function 0.468, 0.467\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn = LastNameLSTM(input_features=len(V),\n",
    "                   hidden_size=50,\n",
    "                   output_size=len(y_cats))\n",
    "rnn = rnn.to(device)\n",
    "\n",
    "# X input shape (max name len, num records, input features)\n",
    "train = TensorDataset(X_train_onehot.to(device), y_train.to(device))\n",
    "valid = TensorDataset(X_valid_onehot.to(device), y_valid.to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "                        loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=5,\n",
    "                        learning_rate=0.001,\n",
    "                        weight_decay=0.0,#0001,\n",
    "                        batch_size=32,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 19, 29])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
