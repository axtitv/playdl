{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the language of the last name via LSTM\n",
    "\n",
    "Repeat previous RNN exercise but with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctrain(model:nn.Module, train_data:TensorDataset, valid_data:TensorDataset,\n",
    "           epochs=350,\n",
    "           test_size=0.20,\n",
    "           learning_rate = 0.002,\n",
    "           batch_size=32,\n",
    "           weight_decay=1.e-4,\n",
    "           loss_fn=F.cross_entropy,\n",
    "           metric=accuracy_score,\n",
    "           print_every=30):\n",
    "    \"Train a regressor\"\n",
    "    history = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for ei in range(epochs): # epochs\n",
    "        for bi, (batch_x, batch_y) in enumerate(train_loader): # mini-batch\n",
    "#             if len(batch_x)!=batch_size:\n",
    "#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\n",
    "            y_prob = model(batch_x)\n",
    "#             print(\"y pred\", y_prob, \"batch_y\", batch_y)\n",
    "            loss = loss_fn(y_prob, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad and M.grad\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss        = loss_fn(model(train_data.tensors[0]), train_data.tensors[1])\n",
    "            loss_valid  = loss_fn(model(valid_data.tensors[0]), valid_data.tensors[1])\n",
    "            y_prob = model(train_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_train = metric(y_pred.cpu(), train_data.tensors[1].cpu())\n",
    "            y_prob = model(valid_data.tensors[0])\n",
    "            y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_valid = metric(y_pred.cpu(), valid_data.tensors[1].cpu())\n",
    "\n",
    "        history.append( (loss, loss_valid) )\n",
    "        if ei % print_every == 0:\n",
    "            print(f\"Epoch {ei:3d} loss {loss:7.4f}, {loss_valid:7.4f}   {metric.__class__.__name__} {metric_train:4.3f}, {metric_valid:4.3f}\")\n",
    "\n",
    "    history = torch.tensor(history)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (13374, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8340</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8341</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8342</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8343</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8344</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8345</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8346</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8347</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8348</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8349</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8350</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8351</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8352</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8353</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8354</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8355</td>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8340  To The First Page  Russian\n",
       "8341  To The First Page  Russian\n",
       "8342  To The First Page  Russian\n",
       "8343  To The First Page  Russian\n",
       "8344  To The First Page  Russian\n",
       "8345  To The First Page  Russian\n",
       "8346  To The First Page  Russian\n",
       "8347  To The First Page  Russian\n",
       "8348  To The First Page  Russian\n",
       "8349  To The First Page  Russian\n",
       "8350  To The First Page  Russian\n",
       "8351  To The First Page  Russian\n",
       "8352  To The First Page  Russian\n",
       "8353  To The First Page  Russian\n",
       "8354  To The First Page  Russian\n",
       "8355  To The First Page  Russian"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train[badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5976</td>\n",
       "      <td>Jevolojnov,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6549</td>\n",
       "      <td>Lytkin,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name language\n",
       "5976  Jevolojnov,  Russian\n",
       "6549      Lytkin,  Russian"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = df_train['name'].str.contains(',') # might as well keep\n",
    "df_train[comma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3609</td>\n",
       "      <td>Awak'Yan</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4454</td>\n",
       "      <td>Dan'Ko</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4471</td>\n",
       "      <td>Dar'Kin</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name language\n",
       "3609  Awak'Yan  Russian\n",
       "4454    Dan'Ko  Russian\n",
       "4471   Dar'Kin  Russian"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['name'].str.contains(\"'\")][:3] # there are ok so keep quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train = df_train[~badname]\n",
    "\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[~badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxlen(strings:Sequence[str]) -> int:\n",
    "    return max([len(l) for l in strings])\n",
    "\n",
    "max_len = max(maxlen(df_train['name']), maxlen(df_test['name']))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train[['name']], df_train['language']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "X_test, y_test = df_test[['name']], df_test['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    V = set([c for cl in letters for c in cl])\n",
    "    V = sorted(list(V))\n",
    "    ctoi = {c:i for i, c in enumerate(V)}\n",
    "    return V, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " \"'\": 1,\n",
       " ',': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, ctoi = vocab(X['name'])\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  4,  0, 14, 14, 14, 14,  5,  4, 14], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.cat.codes\n",
    "y_train.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.Categorical(y_valid, categories=y_cats, ordered=True).codes\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12, 14, 10,  8,  4], dtype=int8), array([2, 2, 2, 2, 2], dtype=int8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode each letter of each name\n",
    "\n",
    "Each name becomes a matrix of size vocab_size x max_len. Each column represents a char and we pad with zeros out to max_len number of columns since tensors have to be same length in same dimension. \n",
    "\n",
    "This approach is wasteful in that it expands each word to len of longest but avoids having to pad explicitly, simplifying the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(strings:Sequence[str], V, ctoi, max_len=None) -> torch.tensor:\n",
    "    if max_len is None:\n",
    "        max_len = maxlen(strings)\n",
    "    X_onehot = torch.zeros(len(strings),len(V),max_len)\n",
    "    for i,name in enumerate(strings):\n",
    "        onehot = torch.zeros((len(V),max_len))\n",
    "        for j,c in enumerate(name):\n",
    "            onehot[ctoi[c],j] = 1\n",
    "        X_onehot[i] = onehot\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ['cat','a','at'] # always debug with a small representative example\n",
    "o = onehot(sample, *vocab(sample))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0,1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot = onehot(X_train['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_train_onehot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_onehot = onehot(X_valid['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_valid_onehot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LastNameLSTM, self).__init__()\n",
    "#         print(\"Model: \",input_size, hidden_size, output_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # combine W and U into W then cat h and input\n",
    "        self.W  = nn.Linear(hidden_size+input_size, hidden_size)\n",
    "        self.V  = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        namelen = X.shape[2]\n",
    "        # record softmax vec of output_size for each record\n",
    "        o = torch.zeros((batch_size, self.output_size)).to(device)\n",
    "        # now that we do all char j in a batch, h is a matrix\n",
    "        h = torch.zeros((batch_size, self.hidden_size)).to(device)\n",
    "        for j in range(namelen):  # for all chars in max name length\n",
    "#                 print(h.shape, X[i].shape, X[i,:,j].shape, self.U.shape)\n",
    "            xj = X[:,:,j] # jth char for all records in batch\n",
    "#             print(\"W\", self.W.weight.shape, \"h\", h.shape, \"xj\", xj.shape)\n",
    "            combined = torch.cat((h, xj),dim=1)\n",
    "#             print(\"combined\", combined.shape)\n",
    "            h = self.W(combined)\n",
    "            h = torch.relu(h)  # better than sigmoid for vanishing gradient\n",
    "        # we now have an h vector that is the embedding for the ith record\n",
    "        # we have encoded/embedded the X[i] record into h\n",
    "        # compute an output value, one per record\n",
    "        ot = self.V(h)\n",
    "#         print(\"ot shape\", ot.shape)\n",
    "#             o[i] = F.softmax(ot.reshape(-1))\n",
    "#         o[i] = ot.reshape(-1)\n",
    "        return ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 loss  1.6141,  1.6637   function 0.479, 0.481\n",
      "Epoch   1 loss  1.5484,  1.6540   function 0.537, 0.516\n",
      "Epoch   2 loss  1.4791,  1.6350   function 0.525, 0.502\n",
      "Epoch   3 loss  1.3509,  1.4839   function 0.628, 0.581\n",
      "Epoch   4 loss  1.4961,  1.8364   function 0.639, 0.580\n",
      "Epoch   5 loss  1.4399,  1.6613   function 0.609, 0.567\n",
      "Epoch   6 loss  1.3239,  1.5303   function 0.640, 0.594\n",
      "Epoch   7 loss  1.3568,  1.5257   function 0.626, 0.596\n",
      "Epoch   8 loss  1.3702,  1.5336   function 0.634, 0.589\n",
      "Epoch   9 loss  1.3771,  1.6518   function 0.606, 0.560\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn = LastNameLSTM(input_size=len(V),\n",
    "                   hidden_size=100,\n",
    "                   output_size=len(y_cats)).to(device)\n",
    "subset=1000\n",
    "train = TensorDataset(X_train_onehot[:subset].double().to(device), torch.tensor(y_train[:subset].values).long().to(device))\n",
    "valid = TensorDataset(X_valid_onehot[:subset].double().to(device), torch.tensor(y_valid[:subset]).long().to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.BCELoss(),\n",
    "                        loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=10,\n",
    "                        learning_rate=.02,\n",
    "                        weight_decay=0.00001,\n",
    "                        batch_size=32,\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
