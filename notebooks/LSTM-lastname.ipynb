{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the language of the last name via LSTM\n",
    "\n",
    "Repeat previous RNN exercise but with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, yrange=(0.0, 5.00), figsize=(3.5,3)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylabel(\"Sentiment log loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    loss = history[:,0]\n",
    "    valid_loss = history[:,1]\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='val_loss')\n",
    "    # plt.xlim(0, 200)\n",
    "    plt.ylim(*yrange)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with fake LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7538,  0.3524, -0.5863, -1.4696, -1.0130, -0.2917],\n",
       "        [-0.7202,  0.8145,  0.0418, -0.8935, -0.3826, -1.3166],\n",
       "        [ 0.8349,  1.8735,  1.1179,  1.0809, -0.1076,  1.1928],\n",
       "        [-1.0861,  2.2620, -0.3764,  0.5840,  1.1595, -0.2424]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = 6\n",
    "hidden_size = 3\n",
    "n = 4\n",
    "rnn = nn.LSTM(input_size=input_features, hidden_size=hidden_size, num_layers=1)\n",
    "inputs = [torch.randn(1, input_features) for _ in range(n)] # make n vectors\n",
    "inputs = torch.cat(inputs)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7538,  0.3524, -0.5863, -1.4696, -1.0130, -0.2917]],\n",
       "\n",
       "        [[-0.7202,  0.8145,  0.0418, -0.8935, -0.3826, -1.3166]],\n",
       "\n",
       "        [[ 0.8349,  1.8735,  1.1179,  1.0809, -0.1076,  1.1928]],\n",
       "\n",
       "        [[-1.0861,  2.2620, -0.3764,  0.5840,  1.1595, -0.2424]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = inputs.reshape(len(inputs), 1, input_features)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(1, 1, hidden_size)\n",
    "c0 = torch.zeros(1, 1, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1677, -0.2301, -0.0489]],\n",
       "\n",
       "        [[ 0.4003, -0.1513, -0.0873]],\n",
       "\n",
       "        [[ 0.1614, -0.0587, -0.0262]],\n",
       "\n",
       "        [[ 0.3854, -0.1252, -0.0672]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o, hc = rnn(inputs, (h0,c0))\n",
    "# output is shape (n, max sequence length, hidden_size)\n",
    "print(o.shape)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3854, -0.1252, -0.0672]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.6842, -1.4423, -0.3420]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Let's download [training](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_train.csv.gz) and [testing](https://raw.githubusercontent.com/hunkim/PyTorchZeroToAll/master/data/names_test.csv.gz) data for last names.   This data set is a bunch of last names and the nationality or language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_train.columns = ['name','language']\n",
    "df_test = pd.read_csv(\"data/names_train.csv\", header=None)\n",
    "df_test.columns = ['name','language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13374, 2), (13374, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name language\n",
       "0   Adsit    Czech\n",
       "1  Ajdrna    Czech"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8341</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8342</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8346</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8352</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8353</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8354</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8355</th>\n",
       "      <td>To The First Page</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name language\n",
       "8340  To The First Page  Russian\n",
       "8341  To The First Page  Russian\n",
       "8342  To The First Page  Russian\n",
       "8343  To The First Page  Russian\n",
       "8344  To The First Page  Russian\n",
       "8345  To The First Page  Russian\n",
       "8346  To The First Page  Russian\n",
       "8347  To The First Page  Russian\n",
       "8348  To The First Page  Russian\n",
       "8349  To The First Page  Russian\n",
       "8350  To The First Page  Russian\n",
       "8351  To The First Page  Russian\n",
       "8352  To The First Page  Russian\n",
       "8353  To The First Page  Russian\n",
       "8354  To The First Page  Russian\n",
       "8355  To The First Page  Russian"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train[badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>Jevolojnov,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>Lytkin,</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name language\n",
       "5976  Jevolojnov,  Russian\n",
       "6549      Lytkin,  Russian"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = df_train['name'].str.contains(',') # might as well keep\n",
    "df_train[comma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>Awak'Yan</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>Dan'Ko</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>Dar'Kin</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name language\n",
       "3609  Awak'Yan  Russian\n",
       "4454    Dan'Ko  Russian\n",
       "4471   Dar'Kin  Russian"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['name'].str.contains(\"'\")][:3] # there are ok so keep quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "badname = df_train['name']=='To The First Page'\n",
    "df_train = df_train[~badname]\n",
    "\n",
    "badname = df_test['name']=='To The First Page'\n",
    "df_test = df_test[~badname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['name'] = df_train['name'].str.lower()\n",
    "df_test['name'] = df_test['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def maxlen(strings:Sequence[str]) -> int:\n",
    "    return max([len(l) for l in strings])\n",
    "\n",
    "max_len = max(maxlen(df_train['name']), maxlen(df_test['name']))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train[['name']], df_train['language']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "X_test, y_test = df_test[['name']], df_test['language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    V = set([c for cl in letters for c in cl])\n",
    "    V = sorted(list(V))\n",
    "    ctoi = {c:i for i, c in enumerate(V)}\n",
    "    return V, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " \"'\": 1,\n",
       " ',': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, ctoi = vocab(X['name'])\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode target language (class)\n",
    "\n",
    "Get categories from training only, not valid/test sets. Then apply cats to those set y's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish',\n",
       "       'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('category').cat.as_ordered()\n",
    "y_cats = y_train.cat.categories\n",
    "y_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 14, 14,  4, 14,  4,  7,  4, 14, 14], dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.cat.codes\n",
    "y_train.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.Categorical(y_valid, categories=y_cats, ordered=True).codes\n",
    "y_test = pd.Categorical(y_test, categories=y_cats, ordered=True).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  4, 17, 14, 14], dtype=int8), array([2, 2, 2, 2, 2], dtype=int8))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode each letter of each name\n",
    "\n",
    "Each name becomes a matrix of size vocab_size x max_len. Each column represents a char and we pad with zeros out to max_len number of columns since tensors have to be same length in same dimension. \n",
    "\n",
    "This approach is wasteful in that it expands each word to len of longest but avoids having to pad explicitly, simplifying the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(strings:Sequence[str], V, ctoi, max_len=None) -> torch.tensor:\n",
    "    if max_len is None:\n",
    "        max_len = maxlen(strings)\n",
    "    X_onehot = torch.zeros(len(strings),len(V),max_len)\n",
    "    for i,name in enumerate(strings):\n",
    "        onehot = torch.zeros((len(V),max_len))\n",
    "        for j,c in enumerate(name):\n",
    "            onehot[ctoi[c],j] = 1\n",
    "        X_onehot[i] = onehot\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 1., 0.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ['cat','a','at'] # always debug with a small representative example\n",
    "o = onehot(sample, *vocab(sample))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0,1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot = onehot(X_train['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_train_onehot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 19])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_onehot = onehot(X_valid['name'], V, ctoi, max_len=max_len).to(device)\n",
    "X_valid_onehot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous shape is now wrong for LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10686, 29, 19])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape should be (num records, max name len, input features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 19, 29])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset=100\n",
    "X_train_onehot, y_train = X_train_onehot[:subset], torch.tensor(y_train[:subset].values).long()\n",
    "X_valid_onehot, y_valid = X_valid_onehot[:subset], torch.tensor(y_valid[:subset]).long()\n",
    "X_train_onehot = X_train_onehot.reshape(len(X_train_onehot), max_len, len(V))\n",
    "X_valid_onehot = X_valid_onehot.reshape(len(X_valid_onehot), max_len, len(V))\n",
    "X_train_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastNameLSTM(nn.Module):\n",
    "    def __init__(self, input_features, hidden_size, output_size):\n",
    "        super(LastNameLSTM, self).__init__()\n",
    "#         print(\"Model: \",input_features, hidden_size, output_size)\n",
    "        self.input_features = input_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        # combine W and U into W then cat h and input\n",
    "        self.lstm = nn.LSTM(input_size=input_features,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        self.V  = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "#         print(\"X\", X.shape)\n",
    "        batch_size = X.shape[0]\n",
    "        max_len = X.shape[1]\n",
    "        # LSTMs need hidden and state vectors, one per input symbol\n",
    "        # also this resets h, c for each batch, not sure that is good\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "        h, c = h0, c0\n",
    "        \n",
    "        # output is shape (batch size, max_len, hidden_size)\n",
    "        o, (h,c) = self.lstm(X, (h,c))\n",
    "#         print(h.shape, c.shape) # [1, 19, 50]   [1, 19, 50]\n",
    "#         print(\"lstm o\", o.shape)\n",
    "        # o has ALL outputs, for each step as it works through chars of name.\n",
    "        # We only need the last output, which we run into final layer\n",
    "        # for classification\n",
    "        o = o[:,-1,:]\n",
    "#         print(\"last output\", o.shape)\n",
    "        o = self.V(o)\n",
    "        o = self.softmax(o)\n",
    "#         print(\"final layer\", o.shape)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctrain(model:nn.Module, train_data:TensorDataset, valid_data:TensorDataset,\n",
    "            epochs=350,\n",
    "            test_size=0.20,\n",
    "            learning_rate = 0.002,\n",
    "            batch_size=32,\n",
    "            weight_decay=1.e-4,\n",
    "            loss_fn=F.cross_entropy,\n",
    "            metric=accuracy_score,\n",
    "            print_every=30):\n",
    "    \"Train a regressor\"\n",
    "    history = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    for ei in range(epochs): # epochs\n",
    "        for bi, (batch_x, batch_y) in enumerate(train_loader): # mini-batch\n",
    "#             if len(batch_x)!=batch_size:\n",
    "#                 print(f\"\\tBatch {bi:3d} len {len(batch_x)}\")\n",
    "            y_prob = model(batch_x)\n",
    "#             print(\"y_prob\", y_prob.shape)\n",
    "#             print(\"y pred\", y_prob, \"batch_y\", batch_y)\n",
    "            loss = loss_fn(y_prob, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad and M.grad\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss        = loss_fn(model(train_data.tensors[0]), train_data.tensors[1])\n",
    "            loss_valid  = loss_fn(model(valid_data.tensors[0]), valid_data.tensors[1])\n",
    "            y_prob = model(train_data.tensors[0])\n",
    "#             print(\"y_prob\", y_prob.shape)\n",
    "#             y_prob = F.softmax(y_prob, dim=1)\n",
    "            print(\"y_prob\", y_prob)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "#             print(\"y_pred\", y_pred)\n",
    "            metric_train = metric(y_pred.cpu(), train_data.tensors[1].cpu())\n",
    "            y_prob = model(valid_data.tensors[0])\n",
    "#             y_prob = F.softmax(y_prob, dim=1)\n",
    "            y_pred = torch.argmax(y_prob, dim=1)\n",
    "            metric_valid = metric(y_pred.cpu(), valid_data.tensors[1].cpu())\n",
    "\n",
    "        history.append( (loss, loss_valid) )\n",
    "        if ei % print_every == 0:\n",
    "            print(f\"Epoch {ei:3d} loss {loss:7.4f}, {loss_valid:7.4f}   {metric.__class__.__name__} {metric_train:4.3f}, {metric_valid:4.3f}\")\n",
    "\n",
    "    history = torch.tensor(history)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_prob tensor([[-2.4338, -2.9973, -3.5424,  ..., -2.9569, -3.2120, -3.0140],\n",
      "        [-2.4431, -2.9992, -3.5515,  ..., -2.9442, -3.2024, -3.0249],\n",
      "        [-2.4312, -3.0035, -3.5243,  ..., -2.9469, -3.2141, -3.0107],\n",
      "        ...,\n",
      "        [-2.4308, -3.0035, -3.5513,  ..., -2.9626, -3.2176, -3.0197],\n",
      "        [-2.4373, -3.0391, -3.5752,  ..., -2.9706, -3.2467, -3.0332],\n",
      "        [-2.4322, -3.0071, -3.5517,  ..., -2.9586, -3.2220, -3.0213]],\n",
      "       device='cuda:0')\n",
      "Epoch   0 loss  2.2382,  2.3045   function 0.450, 0.370\n",
      "y_prob tensor([[-2.7719, -4.1620, -4.9720,  ..., -4.5988, -5.3302, -4.8071],\n",
      "        [-2.7747, -4.1637, -4.9779,  ..., -4.6013, -5.3328, -4.8115],\n",
      "        [-2.7793, -4.1724, -4.9606,  ..., -4.5936, -5.3306, -4.8051],\n",
      "        ...,\n",
      "        [-2.7723, -4.1630, -4.9727,  ..., -4.6003, -5.3319, -4.8086],\n",
      "        [-2.8115, -4.2142, -5.0405,  ..., -4.6409, -5.3857, -4.8578],\n",
      "        [-2.7745, -4.1642, -4.9753,  ..., -4.6010, -5.3322, -4.8090]],\n",
      "       device='cuda:0')\n",
      "Epoch   1 loss  1.9210,  2.1284   function 0.450, 0.370\n",
      "y_prob tensor([[-2.3054, -3.4006, -3.9860,  ..., -4.9076, -5.9250, -4.9841],\n",
      "        [-2.3098, -3.4026, -3.9940,  ..., -4.9150, -5.9324, -4.9928],\n",
      "        [-2.3108, -3.4055, -3.9616,  ..., -4.8969, -5.9207, -4.9770],\n",
      "        ...,\n",
      "        [-2.3045, -3.4011, -3.9851,  ..., -4.9081, -5.9261, -4.9845],\n",
      "        [-2.3399, -3.4447, -4.0509,  ..., -4.9673, -6.0084, -5.0569],\n",
      "        [-2.3083, -3.4016, -3.9891,  ..., -4.9099, -5.9270, -4.9860]],\n",
      "       device='cuda:0')\n",
      "Epoch   2 loss  1.8151,  2.0467   function 0.450, 0.370\n",
      "y_prob tensor([[-2.2852, -2.9586, -3.3777,  ..., -5.0571, -6.3978, -4.9820],\n",
      "        [-2.2888, -2.9601, -3.3843,  ..., -5.0667, -6.4088, -4.9924],\n",
      "        [-2.2930, -2.9589, -3.3418,  ..., -5.0411, -6.3869, -4.9691],\n",
      "        ...,\n",
      "        [-2.2843, -2.9592, -3.3766,  ..., -5.0574, -6.3985, -4.9820],\n",
      "        [-2.3190, -2.9932, -3.4361,  ..., -5.1368, -6.5139, -5.0750],\n",
      "        [-2.2881, -2.9589, -3.3804,  ..., -5.0596, -6.3999, -4.9840]],\n",
      "       device='cuda:0')\n",
      "Epoch   3 loss  1.8511,  2.1087   function 0.450, 0.370\n",
      "y_prob tensor([[-2.5578, -2.9998, -3.4887,  ..., -5.3313, -7.0594, -5.1738],\n",
      "        [-2.5609, -3.0022, -3.4944,  ..., -5.3419, -7.0733, -5.1855],\n",
      "        [-2.5706, -2.9984, -3.4470,  ..., -5.3131, -7.0414, -5.1557],\n",
      "        ...,\n",
      "        [-2.5578, -3.0005, -3.4883,  ..., -5.3318, -7.0599, -5.1737],\n",
      "        [-2.6058, -3.0464, -3.5575,  ..., -5.4343, -7.2161, -5.2909],\n",
      "        [-2.5600, -3.0005, -3.4904,  ..., -5.3339, -7.0622, -5.1764]],\n",
      "       device='cuda:0')\n",
      "Epoch   4 loss  1.8586,  2.1709   function 0.450, 0.370\n",
      "y_prob tensor([[-2.7186, -3.2227, -3.8041,  ..., -5.5098, -7.6578, -5.3247],\n",
      "        [-2.7222, -3.2260, -3.8107,  ..., -5.5210, -7.6736, -5.3371],\n",
      "        [-2.7341, -3.2199, -3.7549,  ..., -5.4893, -7.6321, -5.3018],\n",
      "        ...,\n",
      "        [-2.7190, -3.2235, -3.8041,  ..., -5.5105, -7.6583, -5.3246],\n",
      "        [-2.7827, -3.2912, -3.8944,  ..., -5.6349, -7.8558, -5.4644],\n",
      "        [-2.7207, -3.2237, -3.8058,  ..., -5.5125, -7.6613, -5.3277]],\n",
      "       device='cuda:0')\n",
      "Epoch   5 loss  1.8584,  2.2018   function 0.450, 0.370\n",
      "y_prob tensor([[-2.6102, -3.2878, -3.8774,  ..., -5.3920, -7.9023, -5.1962],\n",
      "        [-2.6133, -3.2914, -3.8845,  ..., -5.4036, -7.9197, -5.2087],\n",
      "        [-2.6279, -3.2823, -3.8170,  ..., -5.3668, -7.8669, -5.1670],\n",
      "        ...,\n",
      "        [-2.6105, -3.2885, -3.8774,  ..., -5.3927, -7.9028, -5.1960],\n",
      "        [-2.6767, -3.3690, -3.9822,  ..., -5.5316, -8.1373, -5.3511],\n",
      "        [-2.6120, -3.2887, -3.8790,  ..., -5.3946, -7.9062, -5.1991]],\n",
      "       device='cuda:0')\n",
      "Epoch   6 loss  1.8355,  2.1663   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4272, -3.2442, -3.7831,  ..., -5.1469, -7.9484, -4.9519],\n",
      "        [-2.4295, -3.2480, -3.7902,  ..., -5.1588, -7.9675, -4.9645],\n",
      "        [-2.4476, -3.2356, -3.7099,  ..., -5.1165, -7.9025, -4.9163],\n",
      "        ...,\n",
      "        [-2.4275, -3.2449, -3.7831,  ..., -5.1476, -7.9488, -4.9516],\n",
      "        [-2.4883, -3.3313, -3.8956,  ..., -5.2961, -8.2187, -5.1178],\n",
      "        [-2.4287, -3.2450, -3.7845,  ..., -5.1493, -7.9524, -4.9546]],\n",
      "       device='cuda:0')\n",
      "Epoch   7 loss  1.8177,  2.1258   function 0.450, 0.370\n",
      "y_prob tensor([[-2.3636, -3.2370, -3.7337,  ..., -4.9805, -8.0357, -4.8028],\n",
      "        [-2.3658, -3.2411, -3.7410,  ..., -4.9928, -8.0564, -4.8156],\n",
      "        [-2.3867, -3.2262, -3.6480,  ..., -4.9465, -7.9809, -4.7622],\n",
      "        ...,\n",
      "        [-2.3639, -3.2377, -3.7337,  ..., -4.9811, -8.0361, -4.8025],\n",
      "        [-2.4286, -3.3354, -3.8579,  ..., -5.1423, -8.3430, -4.9833],\n",
      "        [-2.3651, -3.2379, -3.7349,  ..., -4.9827, -8.0399, -4.8052]],\n",
      "       device='cuda:0')\n",
      "Epoch   8 loss  1.8116,  2.1216   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4142, -3.2698, -3.7533,  ..., -4.9045, -8.1809, -4.7594],\n",
      "        [-2.4169, -3.2747, -3.7613,  ..., -4.9174, -8.2034, -4.7728],\n",
      "        [-2.4395, -3.2577, -3.6552,  ..., -4.8681, -8.1187, -4.7147],\n",
      "        ...,\n",
      "        [-2.4146, -3.2706, -3.7534,  ..., -4.9052, -8.1813, -4.7590],\n",
      "        [-2.4962, -3.3877, -3.8971,  ..., -5.0857, -8.5290, -4.9620],\n",
      "        [-2.4159, -3.2709, -3.7547,  ..., -4.9068, -8.1855, -4.7618]],\n",
      "       device='cuda:0')\n",
      "Epoch   9 loss  1.8108,  2.1411   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4716, -3.2679, -3.7510,  ..., -4.8287, -8.2634, -4.7238],\n",
      "        [-2.4749, -3.2735, -3.7597,  ..., -4.8426, -8.2881, -4.7382],\n",
      "        [-2.4993, -3.2551, -3.6386,  ..., -4.7896, -8.1939, -4.6744],\n",
      "        ...,\n",
      "        [-2.4721, -3.2689, -3.7511,  ..., -4.8295, -8.2639, -4.7234],\n",
      "        [-2.5721, -3.4051, -3.9157,  ..., -5.0322, -8.6561, -4.9520],\n",
      "        [-2.4737, -3.2693, -3.7525,  ..., -4.8312, -8.2688, -4.7264]],\n",
      "       device='cuda:0')\n",
      "Epoch  10 loss  1.8144,  2.1576   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4763, -3.2115, -3.6985,  ..., -4.7218, -8.2361, -4.6564],\n",
      "        [-2.4799, -3.2176, -3.7077,  ..., -4.7367, -8.2632, -4.6717],\n",
      "        [-2.5073, -3.1982, -3.5693,  ..., -4.6794, -8.1586, -4.6014],\n",
      "        ...,\n",
      "        [-2.4767, -3.2125, -3.6986,  ..., -4.7227, -8.2367, -4.6559],\n",
      "        [-2.5885, -3.3623, -3.8807,  ..., -4.9467, -8.6751, -4.9092],\n",
      "        [-2.4786, -3.2129, -3.7002,  ..., -4.7245, -8.2422, -4.6592]],\n",
      "       device='cuda:0')\n",
      "Epoch  11 loss  1.8134,  2.1534   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4737, -3.1775, -3.6833,  ..., -4.6624, -8.2058, -4.6318],\n",
      "        [-2.4778, -3.1844, -3.6933,  ..., -4.6787, -8.2355, -4.6483],\n",
      "        [-2.5083, -3.1644, -3.5351,  ..., -4.6168, -8.1206, -4.5710],\n",
      "        ...,\n",
      "        [-2.4742, -3.1788, -3.6834,  ..., -4.6635, -8.2065, -4.6313],\n",
      "        [-2.5997, -3.3448, -3.8870,  ..., -4.9132, -8.6931, -4.9131],\n",
      "        [-2.4765, -3.1790, -3.6854,  ..., -4.6654, -8.2129, -4.6351]],\n",
      "       device='cuda:0')\n",
      "Epoch  12 loss  1.8116,  2.1458   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4932, -3.2021, -3.7377,  ..., -4.6881, -8.2385, -4.6829],\n",
      "        [-2.4985, -3.2103, -3.7493,  ..., -4.7063, -8.2712, -4.7013],\n",
      "        [-2.5306, -3.1899, -3.5672,  ..., -4.6399, -8.1466, -4.6171],\n",
      "        ...,\n",
      "        [-2.4938, -3.2036, -3.7377,  ..., -4.6894, -8.2394, -4.6823],\n",
      "        [-2.6451, -3.3975, -3.9736,  ..., -4.9766, -8.7790, -5.0033],\n",
      "        [-2.4967, -3.2040, -3.7404,  ..., -4.6918, -8.2471, -4.6869]],\n",
      "       device='cuda:0')\n",
      "Epoch  13 loss  1.8091,  2.1456   function 0.450, 0.370\n",
      "y_prob tensor([[-2.5065, -3.2379, -3.7859,  ..., -4.7393, -8.2710, -4.7466],\n",
      "        [-2.5136, -3.2480, -3.7998,  ..., -4.7602, -8.3072, -4.7674],\n",
      "        [-2.5473, -3.2301, -3.5841,  ..., -4.6897, -8.1717, -4.6778],\n",
      "        ...,\n",
      "        [-2.5073, -3.2397, -3.7859,  ..., -4.7408, -8.2722, -4.7461],\n",
      "        [-2.6952, -3.4718, -4.0567,  ..., -5.0773, -8.8704, -5.1170],\n",
      "        [-2.5110, -3.2404, -3.7895,  ..., -4.7438, -8.2812, -4.7515]],\n",
      "       device='cuda:0')\n",
      "Epoch  14 loss  1.8063,  2.1480   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4843, -3.2365, -3.7532,  ..., -4.7489, -8.2232, -4.7575],\n",
      "        [-2.4939, -3.2486, -3.7695,  ..., -4.7730, -8.2633, -4.7810],\n",
      "        [-2.5331, -3.2437, -3.4958,  ..., -4.7026, -8.1112, -4.6907],\n",
      "        ...,\n",
      "        [-2.4850, -3.2387, -3.7527,  ..., -4.7507, -8.2249, -4.7570],\n",
      "        [-2.7220, -3.5218, -4.0458,  ..., -5.1514, -8.8863, -5.1912],\n",
      "        [-2.4899, -3.2396, -3.7574,  ..., -4.7541, -8.2341, -4.7630]],\n",
      "       device='cuda:0')\n",
      "Epoch  15 loss  1.8011,  2.1434   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4419, -3.2050, -3.7171,  ..., -4.7330, -8.1640, -4.7394],\n",
      "        [-2.4578, -3.2205, -3.7404,  ..., -4.7630, -8.2102, -4.7678],\n",
      "        [-2.5073, -3.2418, -3.3827,  ..., -4.6988, -8.0416, -4.6852],\n",
      "        ...,\n",
      "        [-2.4417, -3.2071, -3.7141,  ..., -4.7345, -8.1666, -4.7387],\n",
      "        [-2.7629, -3.5652, -4.0445,  ..., -5.2256, -8.9015, -5.2601],\n",
      "        [-2.4513, -3.2097, -3.7249,  ..., -4.7404, -8.1760, -4.7465]],\n",
      "       device='cuda:0')\n",
      "Epoch  16 loss  1.7928,  2.1346   function 0.450, 0.370\n",
      "y_prob tensor([[-2.4294, -3.1917, -3.7292,  ..., -4.7478, -8.1674, -4.7501],\n",
      "        [-2.4901, -3.2322, -3.8036,  ..., -4.8116, -8.2355, -4.8079],\n",
      "        [-2.5555, -3.2911, -3.3378,  ..., -4.7584, -8.0611, -4.7442],\n",
      "        ...,\n",
      "        [-2.4227, -3.1909, -3.7141,  ..., -4.7447, -8.1692, -4.7457],\n",
      "        [-2.9412, -3.6938, -4.2098,  ..., -5.4025, -9.0385, -5.4305],\n",
      "        [-2.4774, -3.2184, -3.7736,  ..., -4.7808, -8.1893, -4.7791]],\n",
      "       device='cuda:0')\n",
      "Epoch  17 loss  1.7744,  2.1301   function 0.450, 0.370\n",
      "y_prob tensor([[-2.6095, -3.3331, -3.8433,  ..., -4.8891, -8.2508, -4.9046],\n",
      "        [-2.8046, -3.4842, -4.0436,  ..., -5.0505, -8.4084, -5.0764],\n",
      "        [-2.8939, -3.5491, -3.5340,  ..., -5.0039, -8.2624, -5.0239],\n",
      "        ...,\n",
      "        [-2.5921, -3.3235, -3.7861,  ..., -4.8779, -8.2418, -4.8890],\n",
      "        [-3.4446, -4.1053, -4.6368,  ..., -5.8012, -9.4168, -5.8825],\n",
      "        [-2.7665, -3.4543, -3.9659,  ..., -4.9986, -8.3425, -5.0268]],\n",
      "       device='cuda:0')\n",
      "Epoch  18 loss  1.7686,  2.1759   function 0.450, 0.370\n",
      "y_prob tensor([[-2.3788, -3.1616, -3.7819,  ..., -4.7449, -8.1179, -4.7179],\n",
      "        [-2.6812, -3.4725, -3.9345,  ..., -4.9712, -8.3507, -5.0248],\n",
      "        [-2.8236, -3.5936, -3.2288,  ..., -4.9612, -8.2396, -5.0185],\n",
      "        ...,\n",
      "        [-2.3431, -3.1204, -3.5970,  ..., -4.7148, -8.0591, -4.6592],\n",
      "        [-3.5671, -4.3225, -4.8110,  ..., -5.9072, -9.5863, -6.0863],\n",
      "        [-2.5555, -3.3598, -3.7429,  ..., -4.8535, -8.2071, -4.8848]],\n",
      "       device='cuda:0')\n",
      "Epoch  19 loss  1.7059,  2.1093   function 0.450, 0.370\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn = LastNameLSTM(input_features=len(V),\n",
    "                   hidden_size=50,\n",
    "                   output_size=len(y_cats))\n",
    "rnn = rnn.to(device)\n",
    "\n",
    "# X input shape (max name len, num records, input features)\n",
    "train = TensorDataset(X_train_onehot.to(device), y_train.to(device))\n",
    "valid = TensorDataset(X_valid_onehot.to(device), y_valid.to(device))\n",
    "model, history = ctrain(rnn, train, valid,\n",
    "#                         loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                        loss_fn=torch.nn.NLLLoss(),\n",
    "#                         loss_fn=F.cross_entropy,\n",
    "                        metric=accuracy_score,\n",
    "                        epochs=20,\n",
    "                        learning_rate=0.01,\n",
    "                        weight_decay=0.00001,\n",
    "                        batch_size=32,  # no minibatches\n",
    "                        print_every=1)\n",
    "\n",
    "plot_history(history, yrange=(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 19, 29])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
