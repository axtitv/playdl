{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(range(50))\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5 # time steps per sample\n",
    "step = 1\n",
    "Xy = [np.array(X[i-k:i+1], dtype=np.int) for i in range(k,len(X)-1,step)]\n",
    "Xy = np.array(Xy)\n",
    "Xy[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Xy[:,0:k], Xy[:,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from http://philipperemy.github.io/keras-stateful-lstm/\n",
    "def prepare_sequences(x_train, y_train, window_length):\n",
    "    windows = []\n",
    "    windows_y = []\n",
    "    for i, sequence in enumerate(x_train):\n",
    "        len_seq = len(sequence)\n",
    "        for window_start in range(0, len_seq - window_length + 1):\n",
    "            window_end = window_start + window_length\n",
    "            window = sequence[window_start:window_end]\n",
    "            windows.append(window)\n",
    "            windows_y.append(y_train[i])\n",
    "    return np.array(windows), np.array(windows_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  1,  2,  3],\n",
       "        [ 1,  2,  3,  4],\n",
       "        [ 1,  2,  3,  4],\n",
       "        [ 2,  3,  4,  5],\n",
       "        [ 2,  3,  4,  5],\n",
       "        [ 3,  4,  5,  6],\n",
       "        [ 3,  4,  5,  6],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 6,  7,  8,  9],\n",
       "        [ 6,  7,  8,  9],\n",
       "        [ 7,  8,  9, 10],\n",
       "        [ 7,  8,  9, 10],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [ 9, 10, 11, 12],\n",
       "        [10, 11, 12, 13],\n",
       "        [10, 11, 12, 13],\n",
       "        [11, 12, 13, 14],\n",
       "        [11, 12, 13, 14],\n",
       "        [12, 13, 14, 15],\n",
       "        [12, 13, 14, 15],\n",
       "        [13, 14, 15, 16],\n",
       "        [13, 14, 15, 16],\n",
       "        [14, 15, 16, 17],\n",
       "        [14, 15, 16, 17],\n",
       "        [15, 16, 17, 18],\n",
       "        [15, 16, 17, 18],\n",
       "        [16, 17, 18, 19],\n",
       "        [16, 17, 18, 19],\n",
       "        [17, 18, 19, 20],\n",
       "        [17, 18, 19, 20],\n",
       "        [18, 19, 20, 21],\n",
       "        [18, 19, 20, 21],\n",
       "        [19, 20, 21, 22],\n",
       "        [19, 20, 21, 22],\n",
       "        [20, 21, 22, 23],\n",
       "        [20, 21, 22, 23],\n",
       "        [21, 22, 23, 24],\n",
       "        [21, 22, 23, 24],\n",
       "        [22, 23, 24, 25],\n",
       "        [22, 23, 24, 25],\n",
       "        [23, 24, 25, 26],\n",
       "        [23, 24, 25, 26],\n",
       "        [24, 25, 26, 27],\n",
       "        [24, 25, 26, 27],\n",
       "        [25, 26, 27, 28],\n",
       "        [25, 26, 27, 28],\n",
       "        [26, 27, 28, 29],\n",
       "        [26, 27, 28, 29],\n",
       "        [27, 28, 29, 30],\n",
       "        [27, 28, 29, 30],\n",
       "        [28, 29, 30, 31],\n",
       "        [28, 29, 30, 31],\n",
       "        [29, 30, 31, 32],\n",
       "        [29, 30, 31, 32],\n",
       "        [30, 31, 32, 33],\n",
       "        [30, 31, 32, 33],\n",
       "        [31, 32, 33, 34],\n",
       "        [31, 32, 33, 34],\n",
       "        [32, 33, 34, 35],\n",
       "        [32, 33, 34, 35],\n",
       "        [33, 34, 35, 36],\n",
       "        [33, 34, 35, 36],\n",
       "        [34, 35, 36, 37],\n",
       "        [34, 35, 36, 37],\n",
       "        [35, 36, 37, 38],\n",
       "        [35, 36, 37, 38],\n",
       "        [36, 37, 38, 39],\n",
       "        [36, 37, 38, 39],\n",
       "        [37, 38, 39, 40],\n",
       "        [37, 38, 39, 40],\n",
       "        [38, 39, 40, 41],\n",
       "        [38, 39, 40, 41],\n",
       "        [39, 40, 41, 42],\n",
       "        [39, 40, 41, 42],\n",
       "        [40, 41, 42, 43],\n",
       "        [40, 41, 42, 43],\n",
       "        [41, 42, 43, 44],\n",
       "        [41, 42, 43, 44],\n",
       "        [42, 43, 44, 45],\n",
       "        [42, 43, 44, 45],\n",
       "        [43, 44, 45, 46],\n",
       "        [43, 44, 45, 46],\n",
       "        [44, 45, 46, 47]]),\n",
       " array([ 5,  5,  6,  6,  7,  7,  8,  8,  9,  9, 10, 10, 11, 11, 12, 12, 13,\n",
       "        13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21,\n",
       "        22, 22, 23, 23, 24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30,\n",
       "        30, 31, 31, 32, 32, 33, 33, 34, 34, 35, 35, 36, 36, 37, 37, 38, 38,\n",
       "        39, 39, 40, 40, 41, 41, 42, 42, 43, 43, 44, 44, 45, 45, 46, 46, 47,\n",
       "        47, 48, 48]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_sequences(X,y,window_length=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful LSTM to learn one-char to one-char mapping\n",
    "\n",
    "From https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# define the raw dataset\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "# create mapping of characters to integers (0-25) and the reverse\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 1\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(alphabet) - seq_length, 1):\n",
    "\tseq_in = alphabet[i:i + seq_length]\n",
    "\tseq_out = alphabet[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "\t#print(seq_in, '->', seq_out)\n",
    "dataX = np.array(dataX)\n",
    "dataY = np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 1), (25,))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX.shape, dataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = dataX.reshape(len(dataX), seq_length, 1)\n",
    "dataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 26)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize\n",
    "X = X / float(len(alphabet))\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 3.2735 - accuracy: 0.0400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.2487 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.2336 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.2160 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.1902 - accuracy: 0.1200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.1442 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.0636 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.9888 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.9734 - accuracy: 0.1200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.1077 - accuracy: 0.1600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.9052 - accuracy: 0.1600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.8687 - accuracy: 0.2000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.7826 - accuracy: 0.2000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.7037 - accuracy: 0.1600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.5799 - accuracy: 0.2000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.4276 - accuracy: 0.3600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.7185 - accuracy: 0.2400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.4084 - accuracy: 0.1600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 3.1794 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.8143 - accuracy: 0.1200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.3035 - accuracy: 0.2000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.2620 - accuracy: 0.2400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.4536 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.2289 - accuracy: 0.1600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.4618 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.2161 - accuracy: 0.1600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.2348 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.0627 - accuracy: 0.3600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.1104 - accuracy: 0.0800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.9534 - accuracy: 0.3600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 2.0082 - accuracy: 0.1600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.8640 - accuracy: 0.5200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.8915 - accuracy: 0.2400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.7946 - accuracy: 0.5200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.7755 - accuracy: 0.3600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.7218 - accuracy: 0.5200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.6871 - accuracy: 0.5600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.6544 - accuracy: 0.6000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.6217 - accuracy: 0.6400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5951 - accuracy: 0.6800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5627 - accuracy: 0.7200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5427 - accuracy: 0.6800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5082 - accuracy: 0.6800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4944 - accuracy: 0.7200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4540 - accuracy: 0.6800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4556 - accuracy: 0.5600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4021 - accuracy: 0.6800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4412 - accuracy: 0.5200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3660 - accuracy: 0.6800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4670 - accuracy: 0.4000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3658 - accuracy: 0.6000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.5187 - accuracy: 0.2800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3369 - accuracy: 0.6000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.4405 - accuracy: 0.3200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2879 - accuracy: 0.6800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.3295 - accuracy: 0.5600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2288 - accuracy: 0.7600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2648 - accuracy: 0.6400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1843 - accuracy: 0.8000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.2116 - accuracy: 0.6800\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1476 - accuracy: 0.8400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1775 - accuracy: 0.7200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1109 - accuracy: 0.8400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.1359 - accuracy: 0.8000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0776 - accuracy: 0.8400\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0926 - accuracy: 0.8000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0431 - accuracy: 0.9200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0478 - accuracy: 0.9200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0118 - accuracy: 0.9200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 1.0060 - accuracy: 0.9200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9831 - accuracy: 0.9200\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9705 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9526 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9378 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9227 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.9074 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8923 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8776 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8632 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8488 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8346 - accuracy: 0.9600\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8206 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.8069 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7933 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7799 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7667 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7537 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7409 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7282 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7157 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.7033 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6912 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6791 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6673 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6555 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6439 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6324 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6210 - accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6098 - accuracy: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-e6a70b3f28a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# summarize performance of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create and fit the model\n",
    "batch_size = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "for i in range(300):\n",
    "\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "\tmodel.reset_states()\n",
    "# summarize performance of the model\n",
    "scores = model.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "model.reset_states()\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "# demonstrate some model predictions\n",
    "seed = [char_to_int[alphabet[0]]]\n",
    "for i in range(0, len(alphabet)-1):\n",
    "\tx = numpy.reshape(seed, (1, len(seed), 1))\n",
    "\tx = x / float(len(alphabet))\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tprint(int_to_char[seed[0]], \"->\", int_to_char[index])\n",
    "\tseed = [index]\n",
    "model.reset_states()\n",
    "# demonstrate a random starting point\n",
    "letter = \"K\"\n",
    "seed = [char_to_int[letter]]\n",
    "print(\"New start: \", letter)\n",
    "for i in range(0, 5):\n",
    "\tx = numpy.reshape(seed, (1, len(seed), 1))\n",
    "\tx = x / float(len(alphabet))\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tprint(int_to_char[seed[0]], \"->\", int_to_char[index])\n",
    "\tseed = [index]\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_prob, y_true):\n",
    "    \"\"\"\n",
    "    y_pred is n x k for n samples and k output classes and y_true is n x 1\n",
    "    and is often softmax of final layer.\n",
    "    y_pred values must be probability that output is a specific class.\n",
    "    Binary case: When we have y_pred close to 1 and y_true is 1,\n",
    "    loss is -1*log(1)==0. If y_pred close to 0 and y_true is 1, loss is\n",
    "    -1*log(small value) = big value.\n",
    "    y_true values must be positive integers in [0,k-1].\n",
    "    \"\"\"\n",
    "    n = y_prob.shape[0]\n",
    "    # Get valid at y_true[j] for each sample with fancy indexing\n",
    "    p = y_prob[range(n),y_true]\n",
    "    return np.mean(-np.log(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    ey = np.exp(y)\n",
    "    if len(y.shape)==1:\n",
    "        return ey / np.sum(ey)\n",
    "    return ey /np.sum(ey, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02364054, 0.06426166, 0.1746813 , 0.474833  , 0.02364054,\n",
       "       0.06426166, 0.1746813 ])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0])\n",
    "softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04536842, 2.88283144, 0.43578041, 1.69857678],\n",
       "       [0.55438678, 0.4302623 , 0.50218948, 0.92517536],\n",
       "       [2.39428275, 2.58348557, 0.90331706, 0.1649929 ],\n",
       "       [2.32816417, 1.78824153, 0.84542821, 1.19726932],\n",
       "       [1.40387195, 1.8405467 , 1.79338658, 0.37704829],\n",
       "       [1.57733775, 2.97189155, 0.53064241, 1.59529061]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([1,2,3,2,3,1])\n",
    "n = len(y_true)\n",
    "k = np.max(y_true)+1\n",
    "y_pred = np.random.random(size=(n,k))*3 # mimic unnormalized final layer output\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10260772, 0.64443643, 0.05577497, 0.19718089],\n",
       "       [0.23357456, 0.20630937, 0.22169533, 0.33842074],\n",
       "       [0.39353874, 0.47550734, 0.08860726, 0.04234666],\n",
       "       [0.46892144, 0.27328429, 0.10645254, 0.15134173],\n",
       "       [0.22820841, 0.35316453, 0.33689588, 0.08173118],\n",
       "       [0.15619178, 0.62994871, 0.05483832, 0.15902119]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 2, 3, 1])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10260772, 0.64443643, 0.05577497, 0.19718089],\n",
       "       [0.23357456, 0.20630937, 0.22169533, 0.33842074],\n",
       "       [0.39353874, 0.47550734, 0.08860726, 0.04234666],\n",
       "       [0.46892144, 0.27328429, 0.10645254, 0.15134173],\n",
       "       [0.22820841, 0.35316453, 0.33689588, 0.08173118],\n",
       "       [0.15619178, 0.62994871, 0.05483832, 0.15902119]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = softmax(y_pred)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7190314157337514"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(p, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://deepnotes.io/softmax-crossentropy\n",
    "# Warning: this expects raw output not softmax; it does softmax also inside\n",
    "def deepnotes_cross_entropy(X,y):\n",
    "    \"\"\"\n",
    "    X is the output from fully connected layer (num_examples x num_classes)\n",
    "    y is labels (num_examples x 1)\n",
    "    \tNote that y is not one-hot encoded vector. \n",
    "    \tIt can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n",
    "    \"\"\"\n",
    "    n = y.shape[0]\n",
    "    p = softmax(X)\n",
    "    # We use multidimensional array indexing to extract \n",
    "    # softmax probability of the correct label for each sample.\n",
    "    # Refer to https://docs.scipy.org/doc/numpy/user/basics.indexing.html#indexing-multi-dimensional-arrays for understanding multidimensional array indexing.\n",
    "    log_likelihood = -np.log(p[range(n),y])\n",
    "    loss = np.sum(log_likelihood) / n\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7190314157337514"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepnotes_cross_entropy(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7190, dtype=torch.float64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Warning: this expects raw output not softmax; it does softmax also inside\n",
    "F.cross_entropy(torch.tensor(y_pred), torch.tensor(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(range(9)).reshape(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3, 12, 21])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a, dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
