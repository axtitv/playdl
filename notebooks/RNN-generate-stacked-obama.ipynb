{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate obama speeches using stacked RNNs\n",
    "\n",
    "With truncated back propagation, add embedding layer instead of one-hot encoding going into RNN.\n",
    "\n",
    "Lessons:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "def get_text(filename:str):\n",
    "    \"\"\"\n",
    "    Load and return the text of a text file, assuming latin-1 encoding as that\n",
    "    is what the BBC corpus uses.  Use codecs.open() function not open().\n",
    "    \"\"\"\n",
    "    with codecs.open(filename, mode='r') as f:\n",
    "        s = f.read()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvocab(strings):\n",
    "    letters = [list(l) for l in strings]\n",
    "    vocab = set([c for cl in letters for c in cl])\n",
    "    vocab = sorted(list(vocab))\n",
    "    ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "    return vocab, ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y):\n",
    "    expy = torch.exp(y)\n",
    "    if len(y.shape)==1: # 1D case can't use axis arg\n",
    "        return expy / torch.sum(expy)\n",
    "    return expy / torch.sum(expy, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4224143"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = get_text(\"data/obama-speeches.txt\").lower() # generated from obama-sentences.py\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[0:100_000] # testing\n",
    "n = len(text)\n",
    "\n",
    "bptt = 8                  # only look back this many time steps for gradients\n",
    "nhidden = 400\n",
    "char_embed_sz = 20        # there are 50+ chars, squeeze down into fewer dimensions for embedding prior to input into RNN \n",
    "nchunks = 100             # break up the input into a number of chunks (doesn't have to be small like batch size)\n",
    "chunk_size = n // nchunks # the sequences will be very long\n",
    "n = nchunks * chunk_size  # reset size so it's an even multiple of chunk size\n",
    "text = text[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [text[p:p+chunk_size] for p in range(0, n, chunk_size)]\n",
    "X = torch.empty(nchunks, chunk_size-1, device=device, dtype=torch.long) # int8 doesn't work as indices\n",
    "y = torch.empty(nchunks, chunk_size-1, device=device, dtype=torch.long)\n",
    "for i,chunk in enumerate(chunks):\n",
    "    X[i,:] = torch.tensor([ctoi[c] for c in chunk[0:-1]], device=device)\n",
    "    y[i,:] = torch.tensor([ctoi[c] for c in chunk[1:]],   device=device)\n",
    "    \n",
    "# X, y are now chunked and numericalized into big 2D matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 training records, chunk length 1000, vocab size 52, char_embed_sz 20, state is 400-vector\n"
     ]
    }
   ],
   "source": [
    "nclasses = len(ctoi)\n",
    "print(f\"{nchunks:,d} training records, chunk length {chunk_size}, vocab size {len(ctoi)}, char_embed_sz {char_embed_sz}, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 999]), 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, nchunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5b62ef64402c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;31m# make it nchunks x nclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mepoch_training_accur\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "E = torch.randn(char_embed_sz, len(ctoi),     device=device, dtype=torch.float64, requires_grad=True) # embedding\n",
    "W = torch.eye(nhidden,         nhidden,       device=device, dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,       char_embed_sz, device=device, dtype=torch.float64, requires_grad=True) # input converter\n",
    "B = torch.zeros(nhidden,       nchunks,       device=device, dtype=torch.float64, requires_grad=True)\n",
    "V = torch.randn(nhidden,       nhidden,       device=device, dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "W2 = torch.eye(nhidden,        nhidden,       device=device, dtype=torch.float64, requires_grad=True)\n",
    "U2 = torch.randn(nhidden,      nhidden,       device=device, dtype=torch.float64, requires_grad=True) # input converter\n",
    "V2 = torch.randn(nclasses,     nhidden,       device=device, dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "# if using relu, b must be 0. W must be identity so don't mess with sd. others must have low stdev\n",
    "# From [Le 2015] https://arxiv.org/abs/1504.00941\n",
    "# \"For IRNNs, in addition to the recurrent weights being initialized at identity, the non-recurrent\n",
    "#  weights are initialized with a random matrix, whose entries are sampled from a\n",
    "#  Gaussian distribution with mean of zero and standard deviation of 0.001.\"\n",
    "sd = 0.001  # weight stddev init for relu\n",
    "sd = 0.01   # weight stddev init for tanh\n",
    "with torch.no_grad():\n",
    "    E *= sd\n",
    "    U *= sd\n",
    "    V *= sd\n",
    "    \n",
    "# gradient clipping values \n",
    "gc = {1, 10, 100, 1000}\n",
    "\n",
    "parameters = [E,W,U,B,V,W2,U2,V2]\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.0005, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1)\n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "#                                               mode='triangular2',\n",
    "#                                               step_size_up=5,\n",
    "#                                               base_lr=0.0001, max_lr=0.005,\n",
    "#                                               cycle_momentum=False)\n",
    "\n",
    "history = []\n",
    "epochs = 20\n",
    "for epoch in range(1, epochs+1):\n",
    "    H = torch.zeros(nhidden, nchunks, device=device, dtype=torch.float64, requires_grad=False)\n",
    "    # 2nd layer of RNN\n",
    "    H2 = torch.zeros(nhidden, nchunks, device=device, dtype=torch.float64, requires_grad=False)\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    loss = 0\n",
    "    for t in range(chunk_size-1):  # char t in chunk predicts t+1 so one less\n",
    "        chars_step_t = X[:,t] # char_embed_sz x nchunks\n",
    "        # column E[i] is the embedding for char index i. same as multiple E.mm(onehot(i))\n",
    "        embedding_step_t = E[:,chars_step_t] # char_embed_sz x nchunks\n",
    "#         print(embedding_step_t.shape, E.shape, H.shape, W.shape, U.shape)\n",
    "        H = W.mm(H) + U.mm(embedding_step_t) + B\n",
    "        H = torch.tanh(H)\n",
    "        o = V.mm(H) # o is nhidden x nhidden\n",
    "\n",
    "        H2 = W2.mm(H2) + U2.mm(o)# + B2\n",
    "        H2 = torch.tanh(H2)\n",
    "\n",
    "        o2 = V2.mm(H2)\n",
    "        o2 = o2.T # make it nchunks x nclasses\n",
    "        p = softmax(o2)\n",
    "        correct = torch.argmax(p, dim=1)==y[:,t]\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        loss += F.cross_entropy(o2, y[:,t])\n",
    "        \n",
    "        if t % bptt == 0 and t > 0:\n",
    "#             print(f\"gradient at {t:4d}, loss {loss.item():7.4f}\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "            optimizer.step()\n",
    "            epoch_training_loss += loss.detach().item()\n",
    "            loss = 0\n",
    "            H = H.detach() # no longer consider previous computations\n",
    "            H2 = H2.detach()\n",
    "\n",
    "    epoch_training_accur /=  nchunks * (chunk_size-1)\n",
    "#     epoch_training_loss /= nchunks\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:8.2f}   accur {epoch_training_accur:7.4f}   LR {scheduler.get_last_lr()[0]:7.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(initial_chars, n, temperature=0.1):\n",
    "    \"Derived from Karpathy: https://gist.github.com/karpathy/d4dee566867f8291f086\"\n",
    "    chars = initial_chars\n",
    "    n -= len(initial_chars)\n",
    "    with torch.no_grad():\n",
    "        for i in range(n):\n",
    "            h = torch.zeros(nhidden, 1, dtype=torch.float64, device=device, requires_grad=False)  # reset hidden state at start of record\n",
    "            for j in range(len(chars)):  # for each char in a name\n",
    "                c = chars[j]\n",
    "                ci = ctoi[c]\n",
    "                embedding_step_j = E[:,ci].reshape(char_embed_sz,1) # col is embedding for c; must be column\n",
    "#                 print(embedding_step_j.shape, E.shape, h.shape, W.shape, U.shape)#, V.shape)\n",
    "                h = W@h + U@embedding_step_j + B[:,0].reshape(-1,1) # pick any bias from above\n",
    "                h = torch.tanh(h)\n",
    "#                 h = torch.relu(h)\n",
    "            o = V@h\n",
    "            o = o.reshape(nclasses)\n",
    "            p = softmax(o)\n",
    "#             wi = torch.argmax(p) # this doesn't work (just repeats 'and' a million times)\n",
    "            wi = np.random.choice(range(len(vocab)), p=p.cpu()) # don't always pick most likely; pick per distribution\n",
    "            chars.append(vocab[wi])\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join( sample(list('the job'), 300) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
