{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN from scratch in PyTorch to generate char sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use fastai human numbers data\n",
    "\n",
    "The data is from [fastai book chap 12](https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb). Looks like:\n",
    "\n",
    "```\n",
    "one \n",
    "two \n",
    "three \n",
    "...\n",
    "two hundred seven \n",
    "two hundred eight \n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import URLs\n",
    "path = untar_data(URLs.HUMAN_NUMBERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, layers, callbacks, optimizers, Sequential, losses\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "def get_text(filename:str):\n",
    "    \"\"\"\n",
    "    Load and return the text of a text file, assuming latin-1 encoding as that\n",
    "    is what the BBC corpus uses.  Use codecs.open() function not open().\n",
    "    \"\"\"\n",
    "    f = codecs.open(filename, encoding='latin-1', mode='r')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus and numericalize tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one \\ntwo \\nthree \\nfour \\nfive \\ns'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = get_text(path/'train.txt')\n",
    "text[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one . two . three . '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = re.sub(r'[ \\n]+', ' . ', text) # use '.' as separator token\n",
    "text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', '.', 'two', '.', 'three']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split(' ')\n",
    "tokens = tokens[:-1] # last token is blank '' so delete\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'eight',\n",
       " 'eighteen',\n",
       " 'eighty',\n",
       " 'eleven',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'five',\n",
       " 'forty',\n",
       " 'four']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = sorted(set(tokens))\n",
    "V[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 0, 29, 0, 26, 0, 9, 0, 7, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {w:i for i,w in enumerate(V)}\n",
    "tokens = [index[w] for w in tokens]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84159, 84159, 84160)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tokens[0:-1]\n",
    "y = tokens[1:]\n",
    "len(X), len(y), len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'eight': 1,\n",
       " 'eighteen': 2,\n",
       " 'eighty': 3,\n",
       " 'eleven': 4,\n",
       " 'fifteen': 5,\n",
       " 'fifty': 6,\n",
       " 'five': 7,\n",
       " 'forty': 8,\n",
       " 'four': 9,\n",
       " 'fourteen': 10,\n",
       " 'hundred': 11,\n",
       " 'nine': 12,\n",
       " 'nineteen': 13,\n",
       " 'ninety': 14,\n",
       " 'one': 15,\n",
       " 'seven': 16,\n",
       " 'seventeen': 17,\n",
       " 'seventy': 18,\n",
       " 'six': 19,\n",
       " 'sixteen': 20,\n",
       " 'sixty': 21,\n",
       " 'ten': 22,\n",
       " 'thirteen': 23,\n",
       " 'thirty': 24,\n",
       " 'thousand': 25,\n",
       " 'three': 26,\n",
       " 'twelve': 27,\n",
       " 'twenty': 28,\n",
       " 'two': 29}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctoi = {c:i for i, c in enumerate(V)}\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(c:int, V):\n",
    "    v = torch.zeros((len(V),))\n",
    "    v[c] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(2, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
