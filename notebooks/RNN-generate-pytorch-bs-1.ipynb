{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN from scratch in PyTorch to generate char sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "#from torch.nn.functional import softmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randn(n1, n2, dtype=torch.float32, mean=0.0, std=0.01, requires_grad=True):\n",
    "    x = torch.randn(n1, n2, dtype=dtype)\n",
    "    x = x*std + mean # Convert x to have mean and std\n",
    "    x.requires_grad=requires_grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use fastai human numbers data\n",
    "\n",
    "The data is from [fastai book chap 12](https://github.com/fastai/fastbook/blob/master/12_nlp_dive.ipynb). Looks like:\n",
    "\n",
    "```\n",
    "one \n",
    "two \n",
    "three \n",
    "...\n",
    "two hundred seven \n",
    "two hundred eight \n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import untar_data, URLs\n",
    "path = untar_data(URLs.HUMAN_NUMBERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import models, layers, callbacks, optimizers, Sequential, losses\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "def get_text(filename:str):\n",
    "    \"\"\"\n",
    "    Load and return the text of a text file, assuming latin-1 encoding as that\n",
    "    is what the BBC corpus uses.  Use codecs.open() function not open().\n",
    "    \"\"\"\n",
    "    f = codecs.open(filename, encoding='latin-1', mode='r')\n",
    "    s = f.read()\n",
    "    f.close()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus and numericalize tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one \\ntwo \\nthree \\nfour \\nfive \\ns'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = get_text(path/'train.txt')\n",
    "#text = text[:5000] # TESTING!!!\n",
    "text[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one . two . three . '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = re.sub(r'[ \\n]+', ' . ', text) # use '.' as separator token\n",
    "text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', '.', 'two', '.', 'three']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split(' ')\n",
    "tokens = tokens[:-1] # last token is blank '' so delete\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'eight',\n",
       " 'eighteen',\n",
       " 'eighty',\n",
       " 'eleven',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'five',\n",
       " 'forty',\n",
       " 'four']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(tokens))\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 0, 29, 0, 26, 0, 9, 0, 7, 0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {w:i for i,w in enumerate(vocab)}\n",
    "tokens = [index[w] for w in tokens]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84159, 84159, 84160)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tokens[0:-1]\n",
    "y = torch.tensor(tokens[1:])\n",
    "len(X), len(y), len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "ntrain = int(len(X)*.80)\n",
    "X_train, y_train = X[:ntrain], y[:ntrain]\n",
    "X_valid, y_valid = X[ntrain:], y[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'eight': 1,\n",
       " 'eighteen': 2,\n",
       " 'eighty': 3,\n",
       " 'eleven': 4,\n",
       " 'fifteen': 5,\n",
       " 'fifty': 6,\n",
       " 'five': 7,\n",
       " 'forty': 8,\n",
       " 'four': 9,\n",
       " 'fourteen': 10,\n",
       " 'hundred': 11,\n",
       " 'nine': 12,\n",
       " 'nineteen': 13,\n",
       " 'ninety': 14,\n",
       " 'one': 15,\n",
       " 'seven': 16,\n",
       " 'seventeen': 17,\n",
       " 'seventy': 18,\n",
       " 'six': 19,\n",
       " 'sixteen': 20,\n",
       " 'sixty': 21,\n",
       " 'ten': 22,\n",
       " 'thirteen': 23,\n",
       " 'thirty': 24,\n",
       " 'thousand': 25,\n",
       " 'three': 26,\n",
       " 'twelve': 27,\n",
       " 'twenty': 28,\n",
       " 'two': 29}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctoi = {c:i for i, c in enumerate(vocab)}\n",
    "ctoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(ci:int, vocab):\n",
    "    v = torch.zeros((len(vocab),1), dtype=torch.float32)\n",
    "    v[ci] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(2, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(h0, ci, n):\n",
    "    \"Derived from Karpathy: https://gist.github.com/karpathy/d4dee566867f8291f086\"\n",
    "    h = h0\n",
    "    chars = [vocab[ci]]\n",
    "    with torch.no_grad():\n",
    "        for i in range(n):\n",
    "            x = onehot(X_train[i], V)\n",
    "            h = W.mm(h) + U.mm(x)\n",
    "            h = torch.relu(h)  # squish to (-1,+1); also better than sigmoid for vanishing gradient\n",
    "            o = V.mm(h).reshape(1,-1) # unnormalized log probabilities for next char\n",
    "            p = F.softmax(o)\n",
    "#             p = np.exp(o[0].numpy())             # unnormalized probabilities\n",
    "#             p = p / np.sum(p)         # normalized probabilities\n",
    "            ci = np.random.choice(range(len(vocab)), p=p.ravel())\n",
    "            chars.append(vocab[ci])\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-d7893b474bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mseqlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# do one subsequence of entire X_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# squish to (-1,+1); also better than sigmoid for vanishing gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#         print(h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nhidden = 64\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(vocab) # predicting chars\n",
    "seqlen = 16\n",
    "W = randn(nhidden, nhidden)\n",
    "#W.requires_gradient=True\n",
    "U = randn(nhidden, nfeatures)\n",
    "V = randn(nclasses, nhidden)\n",
    "\n",
    "n = (len(X_train) // seqlen) * seqlen # make it a multiple of seqlen\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.0\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=learning_rate, weight_decay=weight_decay)\n",
    "nepochs=20\n",
    "loss = 0\n",
    "for epoch in range(nepochs+1):\n",
    "    print(f\"EPOCH {epoch}\")\n",
    "    h = randn(nhidden, 1, requires_grad=False) # reset hidden state at start of epoch\n",
    "    for p in range(0,n,seqlen): # do one epoch\n",
    "        loss = 0    \n",
    "        optimizer.zero_grad()\n",
    "        for i in range(p,p+seqlen,1):    # do one subsequence of entire X_train\n",
    "            x = onehot(X_train[i], V)\n",
    "            h = W.mm(h) + U.mm(x)\n",
    "            h = torch.relu(h)  # squish to (-1,+1); also better than sigmoid for vanishing gradient\n",
    "    #         print(h)\n",
    "            o = V.mm(h).reshape(1,-1)\n",
    "#             print(i, vocab[X_train[i]], '->', vocab[y_train[i]], \"vs\", vocab[np.argmax(F.softmax(o).detach().numpy())])\n",
    "            loss = loss + F.cross_entropy(o, torch.tensor([y_train[i]]))\n",
    "#             print(i, X_train[i], loss.item())\n",
    "#         print(f\"SEQUENCE loss={loss.item():.4f} ------------\")\n",
    "        loss.backward() # autograd computes U.grad and M.grad\n",
    "        optimizer.step()\n",
    "        h = h.detach() # truncated BPTT; tell pytorch to forget prev h computations\n",
    "            \n",
    "    print(sample(h0=h, ci=np.random.randint(0,len(vocab)), n=40))\n",
    "#     with torch.no_grad():\n",
    "#         loss = F.cross_entropy(model(train_data.tensors[0]), train_data.tensors[1])\n",
    "#     print(f\"loss={loss.item():.4f} ------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
